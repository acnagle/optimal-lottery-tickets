Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.01, model='lenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=False, wd=0.0005) 

Training a LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.684696
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.819046
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.456013
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.296115
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.304187
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.514175
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.357549
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.127115
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.184004

Test set: Average loss: 0.1860, Accuracy: 9430/10000 (94%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.158841
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.192333
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.120926
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.170185
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.218244
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.096549
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.290147
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.201133
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.163911

Test set: Average loss: 0.1330, Accuracy: 9601/10000 (96%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.163854
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.149957
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.129948
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.228963
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.085807
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.086746
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.138137
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.246579
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.096390

Test set: Average loss: 0.1090, Accuracy: 9662/10000 (97%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.058495
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.071684
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.111930
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.099588
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.073374
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.221346
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.270072
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.046236
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.091586

Test set: Average loss: 0.1007, Accuracy: 9691/10000 (97%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.159343
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.038141
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.241618
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.077772
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.111649
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.059244
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.143769
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.049708
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.087220

Test set: Average loss: 0.0941, Accuracy: 9710/10000 (97%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.059432
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.046424
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.035452
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.097422
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.071113
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.059870
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.095628
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.124743
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.147452

Test set: Average loss: 0.0838, Accuracy: 9745/10000 (97%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.122106
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.111668
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.025099
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.100459
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.038176
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.123978
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.063828
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.122735
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.086056

Test set: Average loss: 0.0800, Accuracy: 9752/10000 (98%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.069064
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.056232
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.017121
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.019468
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.098972
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.129989
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.058572
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.052674
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.123274

Test set: Average loss: 0.0775, Accuracy: 9765/10000 (98%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.026760
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.079679
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.040807
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.083650
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.060552
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.121138
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.081165
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.070686
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.042987

Test set: Average loss: 0.0726, Accuracy: 9786/10000 (98%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.089978
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.034097
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.103796
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.019473
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.020390
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.077960
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.050656
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.028747
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.053719

Test set: Average loss: 0.0742, Accuracy: 9776/10000 (98%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.061225
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.007384
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.097781
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.069242
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.023190
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.031675
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.053579
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.052692
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.042160

Test set: Average loss: 0.0711, Accuracy: 9783/10000 (98%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.113569
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.138722
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.152447
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.107521
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.032078
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.100969
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.034129
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.031884
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.138181

Test set: Average loss: 0.0700, Accuracy: 9790/10000 (98%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.030998
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.094602
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.050862
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.072722
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.077359
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.016333
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.057026
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.121260
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.041035

Test set: Average loss: 0.0670, Accuracy: 9799/10000 (98%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.081669
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.096527
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.117305
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.040829
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.021013
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.081409
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.069036
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.067879
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.024299

Test set: Average loss: 0.0661, Accuracy: 9794/10000 (98%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.047619
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.013199
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.068661
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.071369
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.039824
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.069683
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.044326
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.042030
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.037005

Test set: Average loss: 0.0655, Accuracy: 9796/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.01, model='lenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.80 minutes
Total number of parameters in model: 61470
