Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=True, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.432381
Train Epoch: 1 [12736/60000 (21%)]	Loss: 3.208446
Train Epoch: 1 [19136/60000 (32%)]	Loss: 3.822115
Train Epoch: 1 [25536/60000 (43%)]	Loss: 5.171669
Train Epoch: 1 [31936/60000 (53%)]	Loss: 5.451449
Train Epoch: 1 [38336/60000 (64%)]	Loss: 4.307271
Train Epoch: 1 [44736/60000 (75%)]	Loss: 6.487431
Train Epoch: 1 [51136/60000 (85%)]	Loss: 6.438972
Train Epoch: 1 [57536/60000 (96%)]	Loss: 6.296874

Test set: Average loss: 7.2450, Accuracy: 983/10000 (10%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 7.595529
Train Epoch: 2 [12736/60000 (21%)]	Loss: 7.323044
Train Epoch: 2 [19136/60000 (32%)]	Loss: 9.119222
Train Epoch: 2 [25536/60000 (43%)]	Loss: 8.269272
Train Epoch: 2 [31936/60000 (53%)]	Loss: 7.993060
Train Epoch: 2 [38336/60000 (64%)]	Loss: 8.755830
Train Epoch: 2 [44736/60000 (75%)]	Loss: 7.122400
Train Epoch: 2 [51136/60000 (85%)]	Loss: 7.824110
Train Epoch: 2 [57536/60000 (96%)]	Loss: 7.873956

Test set: Average loss: 8.7233, Accuracy: 746/10000 (7%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 8.778559
Train Epoch: 3 [12736/60000 (21%)]	Loss: 8.971972
Train Epoch: 3 [19136/60000 (32%)]	Loss: 9.225083
Train Epoch: 3 [25536/60000 (43%)]	Loss: 8.305823
Train Epoch: 3 [31936/60000 (53%)]	Loss: 10.507065
Train Epoch: 3 [38336/60000 (64%)]	Loss: 8.649474
Train Epoch: 3 [44736/60000 (75%)]	Loss: 9.940145
Train Epoch: 3 [51136/60000 (85%)]	Loss: 9.091111
Train Epoch: 3 [57536/60000 (96%)]	Loss: 8.777905

Test set: Average loss: 9.3123, Accuracy: 661/10000 (7%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 10.259814
Train Epoch: 4 [12736/60000 (21%)]	Loss: 8.224510
Train Epoch: 4 [19136/60000 (32%)]	Loss: 10.109028
Train Epoch: 4 [25536/60000 (43%)]	Loss: 9.409013
Train Epoch: 4 [31936/60000 (53%)]	Loss: 8.894106
Train Epoch: 4 [38336/60000 (64%)]	Loss: 9.437417
Train Epoch: 4 [44736/60000 (75%)]	Loss: 8.630395
Train Epoch: 4 [51136/60000 (85%)]	Loss: 9.716371
Train Epoch: 4 [57536/60000 (96%)]	Loss: 9.747338

Test set: Average loss: 9.5431, Accuracy: 679/10000 (7%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 8.405616
Train Epoch: 5 [12736/60000 (21%)]	Loss: 9.943640
Train Epoch: 5 [19136/60000 (32%)]	Loss: 10.893817
Train Epoch: 5 [25536/60000 (43%)]	Loss: 10.701567
Train Epoch: 5 [31936/60000 (53%)]	Loss: 9.025362
Train Epoch: 5 [38336/60000 (64%)]	Loss: 9.694009
Train Epoch: 5 [44736/60000 (75%)]	Loss: 10.634418
Train Epoch: 5 [51136/60000 (85%)]	Loss: 10.732858
Train Epoch: 5 [57536/60000 (96%)]	Loss: 9.518513

Test set: Average loss: 9.8126, Accuracy: 656/10000 (7%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 8.670723
Train Epoch: 6 [12736/60000 (21%)]	Loss: 9.560175
Train Epoch: 6 [19136/60000 (32%)]	Loss: 8.848571
Train Epoch: 6 [25536/60000 (43%)]	Loss: 10.635567
Train Epoch: 6 [31936/60000 (53%)]	Loss: 9.750999
Train Epoch: 6 [38336/60000 (64%)]	Loss: 10.417077
Train Epoch: 6 [44736/60000 (75%)]	Loss: 10.284165
Train Epoch: 6 [51136/60000 (85%)]	Loss: 10.519920
Train Epoch: 6 [57536/60000 (96%)]	Loss: 9.930676

Test set: Average loss: 10.0250, Accuracy: 639/10000 (6%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 9.966070
Train Epoch: 7 [12736/60000 (21%)]	Loss: 10.109409
Train Epoch: 7 [19136/60000 (32%)]	Loss: 9.512446
Train Epoch: 7 [25536/60000 (43%)]	Loss: 9.822390
Train Epoch: 7 [31936/60000 (53%)]	Loss: 8.862325
Train Epoch: 7 [38336/60000 (64%)]	Loss: 10.335827
Train Epoch: 7 [44736/60000 (75%)]	Loss: 9.860138
Train Epoch: 7 [51136/60000 (85%)]	Loss: 11.633239
Train Epoch: 7 [57536/60000 (96%)]	Loss: 11.281421

Test set: Average loss: 10.0876, Accuracy: 606/10000 (6%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 11.603020
Train Epoch: 8 [12736/60000 (21%)]	Loss: 10.834656
Train Epoch: 8 [19136/60000 (32%)]	Loss: 8.597677
Train Epoch: 8 [25536/60000 (43%)]	Loss: 10.365436
Train Epoch: 8 [31936/60000 (53%)]	Loss: 8.782795
Train Epoch: 8 [38336/60000 (64%)]	Loss: 9.852509
Train Epoch: 8 [44736/60000 (75%)]	Loss: 10.264326
Train Epoch: 8 [51136/60000 (85%)]	Loss: 10.147016
Train Epoch: 8 [57536/60000 (96%)]	Loss: 10.829241

Test set: Average loss: 10.1220, Accuracy: 623/10000 (6%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 9.373044
Train Epoch: 9 [12736/60000 (21%)]	Loss: 10.141107
Train Epoch: 9 [19136/60000 (32%)]	Loss: 9.671074
Train Epoch: 9 [25536/60000 (43%)]	Loss: 11.002913
Train Epoch: 9 [31936/60000 (53%)]	Loss: 9.664541
Train Epoch: 9 [38336/60000 (64%)]	Loss: 9.893424
Train Epoch: 9 [44736/60000 (75%)]	Loss: 10.911711
Train Epoch: 9 [51136/60000 (85%)]	Loss: 10.681090
Train Epoch: 9 [57536/60000 (96%)]	Loss: 10.302981

Test set: Average loss: 10.1305, Accuracy: 624/10000 (6%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 9.756716
Train Epoch: 10 [12736/60000 (21%)]	Loss: 9.567492
Train Epoch: 10 [19136/60000 (32%)]	Loss: 9.825367
Train Epoch: 10 [25536/60000 (43%)]	Loss: 10.875970
Train Epoch: 10 [31936/60000 (53%)]	Loss: 10.252117
Train Epoch: 10 [38336/60000 (64%)]	Loss: 9.753722
Train Epoch: 10 [44736/60000 (75%)]	Loss: 10.013736
Train Epoch: 10 [51136/60000 (85%)]	Loss: 10.980693
Train Epoch: 10 [57536/60000 (96%)]	Loss: 9.198421

Test set: Average loss: 10.2104, Accuracy: 610/10000 (6%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 9.648620
Train Epoch: 11 [12736/60000 (21%)]	Loss: 9.039162
Train Epoch: 11 [19136/60000 (32%)]	Loss: 9.559934
Train Epoch: 11 [25536/60000 (43%)]	Loss: 11.095435
Train Epoch: 11 [31936/60000 (53%)]	Loss: 9.630818
Train Epoch: 11 [38336/60000 (64%)]	Loss: 9.962586
Train Epoch: 11 [44736/60000 (75%)]	Loss: 12.219599
Train Epoch: 11 [51136/60000 (85%)]	Loss: 9.325487
Train Epoch: 11 [57536/60000 (96%)]	Loss: 10.573763

Test set: Average loss: 10.2667, Accuracy: 611/10000 (6%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 9.502848
Train Epoch: 12 [12736/60000 (21%)]	Loss: 10.867529
Train Epoch: 12 [19136/60000 (32%)]	Loss: 11.482336
Train Epoch: 12 [25536/60000 (43%)]	Loss: 10.348428
Train Epoch: 12 [31936/60000 (53%)]	Loss: 11.135269
Train Epoch: 12 [38336/60000 (64%)]	Loss: 11.263752
Train Epoch: 12 [44736/60000 (75%)]	Loss: 10.999310
Train Epoch: 12 [51136/60000 (85%)]	Loss: 10.618153
Train Epoch: 12 [57536/60000 (96%)]	Loss: 10.571919

Test set: Average loss: 10.3309, Accuracy: 599/10000 (6%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 9.942092
Train Epoch: 13 [12736/60000 (21%)]	Loss: 11.055860
Train Epoch: 13 [19136/60000 (32%)]	Loss: 10.281603
Train Epoch: 13 [25536/60000 (43%)]	Loss: 10.970714
Train Epoch: 13 [31936/60000 (53%)]	Loss: 10.307945
Train Epoch: 13 [38336/60000 (64%)]	Loss: 10.749651
Train Epoch: 13 [44736/60000 (75%)]	Loss: 9.925451
Train Epoch: 13 [51136/60000 (85%)]	Loss: 10.465237
Train Epoch: 13 [57536/60000 (96%)]	Loss: 10.047256

Test set: Average loss: 10.1835, Accuracy: 624/10000 (6%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 10.474676
Train Epoch: 14 [12736/60000 (21%)]	Loss: 10.687551
Train Epoch: 14 [19136/60000 (32%)]	Loss: 10.867314
Train Epoch: 14 [25536/60000 (43%)]	Loss: 11.119148
Train Epoch: 14 [31936/60000 (53%)]	Loss: 11.253847
Train Epoch: 14 [38336/60000 (64%)]	Loss: 11.302726
Train Epoch: 14 [44736/60000 (75%)]	Loss: 10.931083
Train Epoch: 14 [51136/60000 (85%)]	Loss: 10.692458
Train Epoch: 14 [57536/60000 (96%)]	Loss: 10.151362

Test set: Average loss: 10.3410, Accuracy: 610/10000 (6%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 10.723672
Train Epoch: 15 [12736/60000 (21%)]	Loss: 8.683414
Train Epoch: 15 [19136/60000 (32%)]	Loss: 9.194526
Train Epoch: 15 [25536/60000 (43%)]	Loss: 9.715315
Train Epoch: 15 [31936/60000 (53%)]	Loss: 10.736934
Train Epoch: 15 [38336/60000 (64%)]	Loss: 9.692184
Train Epoch: 15 [44736/60000 (75%)]	Loss: 8.881726
Train Epoch: 15 [51136/60000 (85%)]	Loss: 10.141190
Train Epoch: 15 [57536/60000 (96%)]	Loss: 10.912457

Test set: Average loss: 10.3204, Accuracy: 611/10000 (6%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 10.955630
Train Epoch: 16 [12736/60000 (21%)]	Loss: 9.809108
Train Epoch: 16 [19136/60000 (32%)]	Loss: 11.155603
Train Epoch: 16 [25536/60000 (43%)]	Loss: 10.050083
Train Epoch: 16 [31936/60000 (53%)]	Loss: 9.480576
Train Epoch: 16 [38336/60000 (64%)]	Loss: 10.848844
Train Epoch: 16 [44736/60000 (75%)]	Loss: 12.216229
Train Epoch: 16 [51136/60000 (85%)]	Loss: 10.804905
Train Epoch: 16 [57536/60000 (96%)]	Loss: 10.054554

Test set: Average loss: 10.2772, Accuracy: 603/10000 (6%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 9.766242
Train Epoch: 17 [12736/60000 (21%)]	Loss: 10.674938
Train Epoch: 17 [19136/60000 (32%)]	Loss: 11.270114
Train Epoch: 17 [25536/60000 (43%)]	Loss: 10.020168
Train Epoch: 17 [31936/60000 (53%)]	Loss: 11.332076
Train Epoch: 17 [38336/60000 (64%)]	Loss: 9.737055
Train Epoch: 17 [44736/60000 (75%)]	Loss: 10.721389
Train Epoch: 17 [51136/60000 (85%)]	Loss: 9.239633
Train Epoch: 17 [57536/60000 (96%)]	Loss: 10.376372

Test set: Average loss: 10.2908, Accuracy: 622/10000 (6%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 9.429799
Train Epoch: 18 [12736/60000 (21%)]	Loss: 11.021130
Train Epoch: 18 [19136/60000 (32%)]	Loss: 10.690712
Train Epoch: 18 [25536/60000 (43%)]	Loss: 9.656618
Train Epoch: 18 [31936/60000 (53%)]	Loss: 9.892982
Train Epoch: 18 [38336/60000 (64%)]	Loss: 8.858037
Train Epoch: 18 [44736/60000 (75%)]	Loss: 9.209693
Train Epoch: 18 [51136/60000 (85%)]	Loss: 10.681296
Train Epoch: 18 [57536/60000 (96%)]	Loss: 10.045224

Test set: Average loss: 10.3011, Accuracy: 678/10000 (7%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 11.204415
Train Epoch: 19 [12736/60000 (21%)]	Loss: 11.928757
Train Epoch: 19 [19136/60000 (32%)]	Loss: 9.942257
Train Epoch: 19 [25536/60000 (43%)]	Loss: 9.831053
Train Epoch: 19 [31936/60000 (53%)]	Loss: 9.690005
Train Epoch: 19 [38336/60000 (64%)]	Loss: 10.397885
Train Epoch: 19 [44736/60000 (75%)]	Loss: 9.473983
Train Epoch: 19 [51136/60000 (85%)]	Loss: 9.184536
Train Epoch: 19 [57536/60000 (96%)]	Loss: 11.492199

Test set: Average loss: 10.2705, Accuracy: 607/10000 (6%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.98 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1971505
