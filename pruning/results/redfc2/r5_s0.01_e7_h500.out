Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=7, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 6.319695
Train Epoch: 1 [12736/60000 (21%)]	Loss: 7.282774
Train Epoch: 1 [19136/60000 (32%)]	Loss: 11.757396
Train Epoch: 1 [25536/60000 (43%)]	Loss: 11.550618
Train Epoch: 1 [31936/60000 (53%)]	Loss: 12.442515
Train Epoch: 1 [38336/60000 (64%)]	Loss: 10.038383
Train Epoch: 1 [44736/60000 (75%)]	Loss: 14.018641
Train Epoch: 1 [51136/60000 (85%)]	Loss: 13.866883
Train Epoch: 1 [57536/60000 (96%)]	Loss: 13.986225

Test set: Average loss: 14.9508, Accuracy: 1055/10000 (11%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 14.060108
Train Epoch: 2 [12736/60000 (21%)]	Loss: 15.300808
Train Epoch: 2 [19136/60000 (32%)]	Loss: 16.595943
Train Epoch: 2 [25536/60000 (43%)]	Loss: 17.436167
Train Epoch: 2 [31936/60000 (53%)]	Loss: 16.732737
Train Epoch: 2 [38336/60000 (64%)]	Loss: 16.674519
Train Epoch: 2 [44736/60000 (75%)]	Loss: 15.089711
Train Epoch: 2 [51136/60000 (85%)]	Loss: 16.459641
Train Epoch: 2 [57536/60000 (96%)]	Loss: 16.776896

Test set: Average loss: 16.8081, Accuracy: 933/10000 (9%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 16.972050
Train Epoch: 3 [12736/60000 (21%)]	Loss: 17.958298
Train Epoch: 3 [19136/60000 (32%)]	Loss: 17.353271
Train Epoch: 3 [25536/60000 (43%)]	Loss: 16.650681
Train Epoch: 3 [31936/60000 (53%)]	Loss: 17.282467
Train Epoch: 3 [38336/60000 (64%)]	Loss: 17.076038
Train Epoch: 3 [44736/60000 (75%)]	Loss: 16.953669
Train Epoch: 3 [51136/60000 (85%)]	Loss: 17.741360
Train Epoch: 3 [57536/60000 (96%)]	Loss: 15.830476

Test set: Average loss: 16.9672, Accuracy: 958/10000 (10%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 16.760357
Train Epoch: 4 [12736/60000 (21%)]	Loss: 17.405043
Train Epoch: 4 [19136/60000 (32%)]	Loss: 15.871392
Train Epoch: 4 [25536/60000 (43%)]	Loss: 19.489372
Train Epoch: 4 [31936/60000 (53%)]	Loss: 15.444844
Train Epoch: 4 [38336/60000 (64%)]	Loss: 15.016977
Train Epoch: 4 [44736/60000 (75%)]	Loss: 16.789019
Train Epoch: 4 [51136/60000 (85%)]	Loss: 15.261141
Train Epoch: 4 [57536/60000 (96%)]	Loss: 16.288658

Test set: Average loss: 17.5727, Accuracy: 961/10000 (10%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 16.220181
Train Epoch: 5 [12736/60000 (21%)]	Loss: 17.731539
Train Epoch: 5 [19136/60000 (32%)]	Loss: 17.919718
Train Epoch: 5 [25536/60000 (43%)]	Loss: 17.440865
Train Epoch: 5 [31936/60000 (53%)]	Loss: 14.469310
Train Epoch: 5 [38336/60000 (64%)]	Loss: 16.107077
Train Epoch: 5 [44736/60000 (75%)]	Loss: 20.626530
Train Epoch: 5 [51136/60000 (85%)]	Loss: 19.781540
Train Epoch: 5 [57536/60000 (96%)]	Loss: 16.999094

Test set: Average loss: 17.3011, Accuracy: 945/10000 (9%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 15.968537
Train Epoch: 6 [12736/60000 (21%)]	Loss: 14.464365
Train Epoch: 6 [19136/60000 (32%)]	Loss: 16.340897
Train Epoch: 6 [25536/60000 (43%)]	Loss: 17.084686
Train Epoch: 6 [31936/60000 (53%)]	Loss: 16.993567
Train Epoch: 6 [38336/60000 (64%)]	Loss: 19.573692
Train Epoch: 6 [44736/60000 (75%)]	Loss: 18.082785
Train Epoch: 6 [51136/60000 (85%)]	Loss: 18.224436
Train Epoch: 6 [57536/60000 (96%)]	Loss: 18.793236

Test set: Average loss: 17.1655, Accuracy: 937/10000 (9%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 16.985413
Train Epoch: 7 [12736/60000 (21%)]	Loss: 17.300781
Train Epoch: 7 [19136/60000 (32%)]	Loss: 15.367873
Train Epoch: 7 [25536/60000 (43%)]	Loss: 15.753448
Train Epoch: 7 [31936/60000 (53%)]	Loss: 13.631454
Train Epoch: 7 [38336/60000 (64%)]	Loss: 18.162693
Train Epoch: 7 [44736/60000 (75%)]	Loss: 17.060490
Train Epoch: 7 [51136/60000 (85%)]	Loss: 16.291681
Train Epoch: 7 [57536/60000 (96%)]	Loss: 16.044741

Test set: Average loss: 17.6235, Accuracy: 952/10000 (10%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=7, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005)


Total time spent pruning/training: 0.75 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1971505
