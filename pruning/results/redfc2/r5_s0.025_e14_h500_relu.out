Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=True, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.551369
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.987207
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.831800
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.670769
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.599564
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.678785
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.786752
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.504479
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.486332

Test set: Average loss: 0.7313, Accuracy: 7783/10000 (78%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.377831
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.029583
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.949886
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.943605
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.986218
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.028380
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.981227
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.535624
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.317869

Test set: Average loss: 1.5429, Accuracy: 5888/10000 (59%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.589182
Train Epoch: 3 [12736/60000 (21%)]	Loss: 2.823124
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.911744
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.744507
Train Epoch: 3 [31936/60000 (53%)]	Loss: 3.094137
Train Epoch: 3 [38336/60000 (64%)]	Loss: 3.047247
Train Epoch: 3 [44736/60000 (75%)]	Loss: 2.830732
Train Epoch: 3 [51136/60000 (85%)]	Loss: 3.321826
Train Epoch: 3 [57536/60000 (96%)]	Loss: 2.937906

Test set: Average loss: 3.5196, Accuracy: 2872/10000 (29%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 4.093206
Train Epoch: 4 [12736/60000 (21%)]	Loss: 3.359251
Train Epoch: 4 [19136/60000 (32%)]	Loss: 3.830901
Train Epoch: 4 [25536/60000 (43%)]	Loss: 4.419303
Train Epoch: 4 [31936/60000 (53%)]	Loss: 4.020329
Train Epoch: 4 [38336/60000 (64%)]	Loss: 4.254639
Train Epoch: 4 [44736/60000 (75%)]	Loss: 4.159297
Train Epoch: 4 [51136/60000 (85%)]	Loss: 4.223429
Train Epoch: 4 [57536/60000 (96%)]	Loss: 5.385989

Test set: Average loss: 4.8793, Accuracy: 1780/10000 (18%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 5.203691
Train Epoch: 5 [12736/60000 (21%)]	Loss: 4.754013
Train Epoch: 5 [19136/60000 (32%)]	Loss: 5.922719
Train Epoch: 5 [25536/60000 (43%)]	Loss: 5.570000
Train Epoch: 5 [31936/60000 (53%)]	Loss: 5.491612
Train Epoch: 5 [38336/60000 (64%)]	Loss: 5.522229
Train Epoch: 5 [44736/60000 (75%)]	Loss: 5.748668
Train Epoch: 5 [51136/60000 (85%)]	Loss: 6.036016
Train Epoch: 5 [57536/60000 (96%)]	Loss: 5.545657

Test set: Average loss: 5.6609, Accuracy: 1315/10000 (13%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 5.308977
Train Epoch: 6 [12736/60000 (21%)]	Loss: 5.826097
Train Epoch: 6 [19136/60000 (32%)]	Loss: 5.405510
Train Epoch: 6 [25536/60000 (43%)]	Loss: 6.252176
Train Epoch: 6 [31936/60000 (53%)]	Loss: 5.843993
Train Epoch: 6 [38336/60000 (64%)]	Loss: 6.129497
Train Epoch: 6 [44736/60000 (75%)]	Loss: 6.666656
Train Epoch: 6 [51136/60000 (85%)]	Loss: 6.413588
Train Epoch: 6 [57536/60000 (96%)]	Loss: 6.001431

Test set: Average loss: 6.1093, Accuracy: 1069/10000 (11%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 5.860826
Train Epoch: 7 [12736/60000 (21%)]	Loss: 6.224354
Train Epoch: 7 [19136/60000 (32%)]	Loss: 6.079238
Train Epoch: 7 [25536/60000 (43%)]	Loss: 5.520754
Train Epoch: 7 [31936/60000 (53%)]	Loss: 5.627962
Train Epoch: 7 [38336/60000 (64%)]	Loss: 6.185885
Train Epoch: 7 [44736/60000 (75%)]	Loss: 6.022003
Train Epoch: 7 [51136/60000 (85%)]	Loss: 7.024503
Train Epoch: 7 [57536/60000 (96%)]	Loss: 7.142078

Test set: Average loss: 6.6115, Accuracy: 989/10000 (10%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 7.007097
Train Epoch: 8 [12736/60000 (21%)]	Loss: 7.162621
Train Epoch: 8 [19136/60000 (32%)]	Loss: 5.652919
Train Epoch: 8 [25536/60000 (43%)]	Loss: 6.735804
Train Epoch: 8 [31936/60000 (53%)]	Loss: 6.124200
Train Epoch: 8 [38336/60000 (64%)]	Loss: 6.306756
Train Epoch: 8 [44736/60000 (75%)]	Loss: 7.349260
Train Epoch: 8 [51136/60000 (85%)]	Loss: 6.359210
Train Epoch: 8 [57536/60000 (96%)]	Loss: 7.182824

Test set: Average loss: 6.6808, Accuracy: 1065/10000 (11%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 6.198589
Train Epoch: 9 [12736/60000 (21%)]	Loss: 6.645020
Train Epoch: 9 [19136/60000 (32%)]	Loss: 6.603886
Train Epoch: 9 [25536/60000 (43%)]	Loss: 7.681910
Train Epoch: 9 [31936/60000 (53%)]	Loss: 6.385174
Train Epoch: 9 [38336/60000 (64%)]	Loss: 7.456511
Train Epoch: 9 [44736/60000 (75%)]	Loss: 7.468551
Train Epoch: 9 [51136/60000 (85%)]	Loss: 7.585990
Train Epoch: 9 [57536/60000 (96%)]	Loss: 7.046322

Test set: Average loss: 6.8662, Accuracy: 1070/10000 (11%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 6.609726
Train Epoch: 10 [12736/60000 (21%)]	Loss: 6.688076
Train Epoch: 10 [19136/60000 (32%)]	Loss: 6.824839
Train Epoch: 10 [25536/60000 (43%)]	Loss: 7.538515
Train Epoch: 10 [31936/60000 (53%)]	Loss: 6.874895
Train Epoch: 10 [38336/60000 (64%)]	Loss: 6.828151
Train Epoch: 10 [44736/60000 (75%)]	Loss: 6.754612
Train Epoch: 10 [51136/60000 (85%)]	Loss: 7.417873
Train Epoch: 10 [57536/60000 (96%)]	Loss: 6.490486

Test set: Average loss: 7.0050, Accuracy: 999/10000 (10%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 6.740590
Train Epoch: 11 [12736/60000 (21%)]	Loss: 5.949288
Train Epoch: 11 [19136/60000 (32%)]	Loss: 6.778264
Train Epoch: 11 [25536/60000 (43%)]	Loss: 7.524561
Train Epoch: 11 [31936/60000 (53%)]	Loss: 6.465594
Train Epoch: 11 [38336/60000 (64%)]	Loss: 6.929720
Train Epoch: 11 [44736/60000 (75%)]	Loss: 8.659687
Train Epoch: 11 [51136/60000 (85%)]	Loss: 6.424923
Train Epoch: 11 [57536/60000 (96%)]	Loss: 6.999798

Test set: Average loss: 7.1187, Accuracy: 1020/10000 (10%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 6.514597
Train Epoch: 12 [12736/60000 (21%)]	Loss: 7.666848
Train Epoch: 12 [19136/60000 (32%)]	Loss: 7.406394
Train Epoch: 12 [25536/60000 (43%)]	Loss: 6.947687
Train Epoch: 12 [31936/60000 (53%)]	Loss: 8.058346
Train Epoch: 12 [38336/60000 (64%)]	Loss: 7.809917
Train Epoch: 12 [44736/60000 (75%)]	Loss: 7.911432
Train Epoch: 12 [51136/60000 (85%)]	Loss: 7.413693
Train Epoch: 12 [57536/60000 (96%)]	Loss: 6.478953

Test set: Average loss: 7.0943, Accuracy: 892/10000 (9%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 6.557807
Train Epoch: 13 [12736/60000 (21%)]	Loss: 7.716040
Train Epoch: 13 [19136/60000 (32%)]	Loss: 7.237371
Train Epoch: 13 [25536/60000 (43%)]	Loss: 7.233303
Train Epoch: 13 [31936/60000 (53%)]	Loss: 6.404918
Train Epoch: 13 [38336/60000 (64%)]	Loss: 7.276011
Train Epoch: 13 [44736/60000 (75%)]	Loss: 7.028242
Train Epoch: 13 [51136/60000 (85%)]	Loss: 7.371813
Train Epoch: 13 [57536/60000 (96%)]	Loss: 6.547842

Test set: Average loss: 7.3202, Accuracy: 877/10000 (9%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 7.403771
Train Epoch: 14 [12736/60000 (21%)]	Loss: 7.780675
Train Epoch: 14 [19136/60000 (32%)]	Loss: 7.903512
Train Epoch: 14 [25536/60000 (43%)]	Loss: 8.298050
Train Epoch: 14 [31936/60000 (53%)]	Loss: 7.725369
Train Epoch: 14 [38336/60000 (64%)]	Loss: 8.682199
Train Epoch: 14 [44736/60000 (75%)]	Loss: 8.509570
Train Epoch: 14 [51136/60000 (85%)]	Loss: 7.676693
Train Epoch: 14 [57536/60000 (96%)]	Loss: 7.544835

Test set: Average loss: 7.7779, Accuracy: 889/10000 (9%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.53 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1941634
