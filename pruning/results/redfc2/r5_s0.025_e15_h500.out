Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.659309
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.421875
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.776607
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.598150
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.630796
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.568500
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.402976
Train Epoch: 1 [51136/60000 (85%)]	Loss: 3.034821
Train Epoch: 1 [57536/60000 (96%)]	Loss: 3.336103

Test set: Average loss: 4.6209, Accuracy: 4382/10000 (44%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 3.978671
Train Epoch: 2 [12736/60000 (21%)]	Loss: 4.508041
Train Epoch: 2 [19136/60000 (32%)]	Loss: 6.145103
Train Epoch: 2 [25536/60000 (43%)]	Loss: 6.791266
Train Epoch: 2 [31936/60000 (53%)]	Loss: 7.719559
Train Epoch: 2 [38336/60000 (64%)]	Loss: 7.507386
Train Epoch: 2 [44736/60000 (75%)]	Loss: 7.129437
Train Epoch: 2 [51136/60000 (85%)]	Loss: 7.783483
Train Epoch: 2 [57536/60000 (96%)]	Loss: 9.495235

Test set: Average loss: 7.9992, Accuracy: 2395/10000 (24%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 7.812176
Train Epoch: 3 [12736/60000 (21%)]	Loss: 11.230598
Train Epoch: 3 [19136/60000 (32%)]	Loss: 10.861160
Train Epoch: 3 [25536/60000 (43%)]	Loss: 8.332467
Train Epoch: 3 [31936/60000 (53%)]	Loss: 10.659159
Train Epoch: 3 [38336/60000 (64%)]	Loss: 11.172399
Train Epoch: 3 [44736/60000 (75%)]	Loss: 10.424384
Train Epoch: 3 [51136/60000 (85%)]	Loss: 11.617658
Train Epoch: 3 [57536/60000 (96%)]	Loss: 10.603586

Test set: Average loss: 11.0291, Accuracy: 1629/10000 (16%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 10.561482
Train Epoch: 4 [12736/60000 (21%)]	Loss: 12.772606
Train Epoch: 4 [19136/60000 (32%)]	Loss: 10.655530
Train Epoch: 4 [25536/60000 (43%)]	Loss: 14.147376
Train Epoch: 4 [31936/60000 (53%)]	Loss: 9.740920
Train Epoch: 4 [38336/60000 (64%)]	Loss: 10.156859
Train Epoch: 4 [44736/60000 (75%)]	Loss: 11.108797
Train Epoch: 4 [51136/60000 (85%)]	Loss: 10.093529
Train Epoch: 4 [57536/60000 (96%)]	Loss: 12.150535

Test set: Average loss: 12.2772, Accuracy: 1466/10000 (15%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 12.907273
Train Epoch: 5 [12736/60000 (21%)]	Loss: 13.016619
Train Epoch: 5 [19136/60000 (32%)]	Loss: 13.293850
Train Epoch: 5 [25536/60000 (43%)]	Loss: 12.191677
Train Epoch: 5 [31936/60000 (53%)]	Loss: 11.711645
Train Epoch: 5 [38336/60000 (64%)]	Loss: 12.105521
Train Epoch: 5 [44736/60000 (75%)]	Loss: 15.722651
Train Epoch: 5 [51136/60000 (85%)]	Loss: 15.823748
Train Epoch: 5 [57536/60000 (96%)]	Loss: 12.449483

Test set: Average loss: 13.1900, Accuracy: 1280/10000 (13%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 12.217125
Train Epoch: 6 [12736/60000 (21%)]	Loss: 11.227224
Train Epoch: 6 [19136/60000 (32%)]	Loss: 12.495699
Train Epoch: 6 [25536/60000 (43%)]	Loss: 12.963301
Train Epoch: 6 [31936/60000 (53%)]	Loss: 13.532371
Train Epoch: 6 [38336/60000 (64%)]	Loss: 15.408154
Train Epoch: 6 [44736/60000 (75%)]	Loss: 13.967803
Train Epoch: 6 [51136/60000 (85%)]	Loss: 13.378350
Train Epoch: 6 [57536/60000 (96%)]	Loss: 14.772747

Test set: Average loss: 13.0128, Accuracy: 1284/10000 (13%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 13.227556
Train Epoch: 7 [12736/60000 (21%)]	Loss: 12.499003
Train Epoch: 7 [19136/60000 (32%)]	Loss: 12.340887
Train Epoch: 7 [25536/60000 (43%)]	Loss: 11.541799
Train Epoch: 7 [31936/60000 (53%)]	Loss: 10.873753
Train Epoch: 7 [38336/60000 (64%)]	Loss: 13.865198
Train Epoch: 7 [44736/60000 (75%)]	Loss: 12.994848
Train Epoch: 7 [51136/60000 (85%)]	Loss: 12.876958
Train Epoch: 7 [57536/60000 (96%)]	Loss: 11.784179

Test set: Average loss: 13.4669, Accuracy: 1239/10000 (12%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 13.084834
Train Epoch: 8 [12736/60000 (21%)]	Loss: 13.895020
Train Epoch: 8 [19136/60000 (32%)]	Loss: 12.236594
Train Epoch: 8 [25536/60000 (43%)]	Loss: 13.213711
Train Epoch: 8 [31936/60000 (53%)]	Loss: 13.690745
Train Epoch: 8 [38336/60000 (64%)]	Loss: 12.859476
Train Epoch: 8 [44736/60000 (75%)]	Loss: 13.566609
Train Epoch: 8 [51136/60000 (85%)]	Loss: 12.735332
Train Epoch: 8 [57536/60000 (96%)]	Loss: 12.266920

Test set: Average loss: 13.1100, Accuracy: 1178/10000 (12%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 11.843186
Train Epoch: 9 [12736/60000 (21%)]	Loss: 12.201037
Train Epoch: 9 [19136/60000 (32%)]	Loss: 12.787588
Train Epoch: 9 [25536/60000 (43%)]	Loss: 13.522890
Train Epoch: 9 [31936/60000 (53%)]	Loss: 12.926893
Train Epoch: 9 [38336/60000 (64%)]	Loss: 14.690351
Train Epoch: 9 [44736/60000 (75%)]	Loss: 15.449958
Train Epoch: 9 [51136/60000 (85%)]	Loss: 15.566121
Train Epoch: 9 [57536/60000 (96%)]	Loss: 12.637695

Test set: Average loss: 14.2756, Accuracy: 1151/10000 (12%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 14.155390
Train Epoch: 10 [12736/60000 (21%)]	Loss: 12.401796
Train Epoch: 10 [19136/60000 (32%)]	Loss: 14.763103
Train Epoch: 10 [25536/60000 (43%)]	Loss: 13.150675
Train Epoch: 10 [31936/60000 (53%)]	Loss: 15.210273
Train Epoch: 10 [38336/60000 (64%)]	Loss: 15.395788
Train Epoch: 10 [44736/60000 (75%)]	Loss: 12.626055
Train Epoch: 10 [51136/60000 (85%)]	Loss: 15.303902
Train Epoch: 10 [57536/60000 (96%)]	Loss: 14.662870

Test set: Average loss: 13.7488, Accuracy: 1167/10000 (12%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 12.477379
Train Epoch: 11 [12736/60000 (21%)]	Loss: 11.589748
Train Epoch: 11 [19136/60000 (32%)]	Loss: 10.619699
Train Epoch: 11 [25536/60000 (43%)]	Loss: 13.359964
Train Epoch: 11 [31936/60000 (53%)]	Loss: 12.537285
Train Epoch: 11 [38336/60000 (64%)]	Loss: 13.722908
Train Epoch: 11 [44736/60000 (75%)]	Loss: 14.466928
Train Epoch: 11 [51136/60000 (85%)]	Loss: 11.497185
Train Epoch: 11 [57536/60000 (96%)]	Loss: 13.338841

Test set: Average loss: 13.7581, Accuracy: 1113/10000 (11%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 14.191596
Train Epoch: 12 [12736/60000 (21%)]	Loss: 14.573645
Train Epoch: 12 [19136/60000 (32%)]	Loss: 12.986807
Train Epoch: 12 [25536/60000 (43%)]	Loss: 11.835458
Train Epoch: 12 [31936/60000 (53%)]	Loss: 13.908084
Train Epoch: 12 [38336/60000 (64%)]	Loss: 14.799686
Train Epoch: 12 [44736/60000 (75%)]	Loss: 14.542956
Train Epoch: 12 [51136/60000 (85%)]	Loss: 14.275103
Train Epoch: 12 [57536/60000 (96%)]	Loss: 13.439536

Test set: Average loss: 13.5523, Accuracy: 1085/10000 (11%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 14.212909
Train Epoch: 13 [12736/60000 (21%)]	Loss: 15.242853
Train Epoch: 13 [19136/60000 (32%)]	Loss: 13.655435
Train Epoch: 13 [25536/60000 (43%)]	Loss: 14.014343
Train Epoch: 13 [31936/60000 (53%)]	Loss: 15.135208
Train Epoch: 13 [38336/60000 (64%)]	Loss: 13.945211
Train Epoch: 13 [44736/60000 (75%)]	Loss: 11.471692
Train Epoch: 13 [51136/60000 (85%)]	Loss: 15.539710
Train Epoch: 13 [57536/60000 (96%)]	Loss: 14.123319

Test set: Average loss: 13.7764, Accuracy: 1126/10000 (11%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 10.886890
Train Epoch: 14 [12736/60000 (21%)]	Loss: 13.587469
Train Epoch: 14 [19136/60000 (32%)]	Loss: 16.545765
Train Epoch: 14 [25536/60000 (43%)]	Loss: 11.982002
Train Epoch: 14 [31936/60000 (53%)]	Loss: 13.889482
Train Epoch: 14 [38336/60000 (64%)]	Loss: 17.339081
Train Epoch: 14 [44736/60000 (75%)]	Loss: 12.962326
Train Epoch: 14 [51136/60000 (85%)]	Loss: 15.212759
Train Epoch: 14 [57536/60000 (96%)]	Loss: 14.032441

Test set: Average loss: 13.6768, Accuracy: 1172/10000 (12%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 13.194103
Train Epoch: 15 [12736/60000 (21%)]	Loss: 13.418797
Train Epoch: 15 [19136/60000 (32%)]	Loss: 13.644482
Train Epoch: 15 [25536/60000 (43%)]	Loss: 12.946096
Train Epoch: 15 [31936/60000 (53%)]	Loss: 14.612904
Train Epoch: 15 [38336/60000 (64%)]	Loss: 15.083803
Train Epoch: 15 [44736/60000 (75%)]	Loss: 11.162324
Train Epoch: 15 [51136/60000 (85%)]	Loss: 12.853799
Train Epoch: 15 [57536/60000 (96%)]	Loss: 14.559557

Test set: Average loss: 14.0948, Accuracy: 1124/10000 (11%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.63 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1941634
