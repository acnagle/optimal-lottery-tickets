Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.147642
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.262311
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.183369
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.792807
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.409176
Train Epoch: 1 [38336/60000 (64%)]	Loss: 4.080945
Train Epoch: 1 [44736/60000 (75%)]	Loss: 5.067652
Train Epoch: 1 [51136/60000 (85%)]	Loss: 5.304578
Train Epoch: 1 [57536/60000 (96%)]	Loss: 6.211132

Test set: Average loss: 6.7495, Accuracy: 3214/10000 (32%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 6.402363
Train Epoch: 2 [12736/60000 (21%)]	Loss: 8.000204
Train Epoch: 2 [19136/60000 (32%)]	Loss: 9.655826
Train Epoch: 2 [25536/60000 (43%)]	Loss: 11.155149
Train Epoch: 2 [31936/60000 (53%)]	Loss: 11.527912
Train Epoch: 2 [38336/60000 (64%)]	Loss: 11.102521
Train Epoch: 2 [44736/60000 (75%)]	Loss: 10.721497
Train Epoch: 2 [51136/60000 (85%)]	Loss: 11.279961
Train Epoch: 2 [57536/60000 (96%)]	Loss: 12.181943

Test set: Average loss: 11.3518, Accuracy: 1390/10000 (14%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 11.423971
Train Epoch: 3 [12736/60000 (21%)]	Loss: 13.899549
Train Epoch: 3 [19136/60000 (32%)]	Loss: 13.800466
Train Epoch: 3 [25536/60000 (43%)]	Loss: 11.975234
Train Epoch: 3 [31936/60000 (53%)]	Loss: 12.881572
Train Epoch: 3 [38336/60000 (64%)]	Loss: 13.618943
Train Epoch: 3 [44736/60000 (75%)]	Loss: 13.580850
Train Epoch: 3 [51136/60000 (85%)]	Loss: 13.572965
Train Epoch: 3 [57536/60000 (96%)]	Loss: 12.543926

Test set: Average loss: 12.8444, Accuracy: 1329/10000 (13%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 13.080934
Train Epoch: 4 [12736/60000 (21%)]	Loss: 13.819052
Train Epoch: 4 [19136/60000 (32%)]	Loss: 12.104850
Train Epoch: 4 [25536/60000 (43%)]	Loss: 15.987785
Train Epoch: 4 [31936/60000 (53%)]	Loss: 11.797283
Train Epoch: 4 [38336/60000 (64%)]	Loss: 12.114996
Train Epoch: 4 [44736/60000 (75%)]	Loss: 13.681847
Train Epoch: 4 [51136/60000 (85%)]	Loss: 12.037758
Train Epoch: 4 [57536/60000 (96%)]	Loss: 13.660390

Test set: Average loss: 14.3221, Accuracy: 1154/10000 (12%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 14.174014
Train Epoch: 5 [12736/60000 (21%)]	Loss: 14.346869
Train Epoch: 5 [19136/60000 (32%)]	Loss: 14.734778
Train Epoch: 5 [25536/60000 (43%)]	Loss: 14.352207
Train Epoch: 5 [31936/60000 (53%)]	Loss: 12.683034
Train Epoch: 5 [38336/60000 (64%)]	Loss: 13.865265
Train Epoch: 5 [44736/60000 (75%)]	Loss: 16.776844
Train Epoch: 5 [51136/60000 (85%)]	Loss: 16.714218
Train Epoch: 5 [57536/60000 (96%)]	Loss: 14.301629

Test set: Average loss: 14.8832, Accuracy: 1110/10000 (11%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 13.438487
Train Epoch: 6 [12736/60000 (21%)]	Loss: 12.186666
Train Epoch: 6 [19136/60000 (32%)]	Loss: 14.160165
Train Epoch: 6 [25536/60000 (43%)]	Loss: 14.205384
Train Epoch: 6 [31936/60000 (53%)]	Loss: 14.453500
Train Epoch: 6 [38336/60000 (64%)]	Loss: 17.220381
Train Epoch: 6 [44736/60000 (75%)]	Loss: 15.691951
Train Epoch: 6 [51136/60000 (85%)]	Loss: 15.028850
Train Epoch: 6 [57536/60000 (96%)]	Loss: 16.436247

Test set: Average loss: 14.5424, Accuracy: 1049/10000 (10%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 14.753870
Train Epoch: 7 [12736/60000 (21%)]	Loss: 14.978045
Train Epoch: 7 [19136/60000 (32%)]	Loss: 13.149835
Train Epoch: 7 [25536/60000 (43%)]	Loss: 13.275581
Train Epoch: 7 [31936/60000 (53%)]	Loss: 11.458142
Train Epoch: 7 [38336/60000 (64%)]	Loss: 15.051395
Train Epoch: 7 [44736/60000 (75%)]	Loss: 14.354885
Train Epoch: 7 [51136/60000 (85%)]	Loss: 12.974998
Train Epoch: 7 [57536/60000 (96%)]	Loss: 12.927502

Test set: Average loss: 15.0991, Accuracy: 1047/10000 (10%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 15.874996
Train Epoch: 8 [12736/60000 (21%)]	Loss: 15.807514
Train Epoch: 8 [19136/60000 (32%)]	Loss: 12.935112
Train Epoch: 8 [25536/60000 (43%)]	Loss: 14.811499
Train Epoch: 8 [31936/60000 (53%)]	Loss: 14.958426
Train Epoch: 8 [38336/60000 (64%)]	Loss: 13.832304
Train Epoch: 8 [44736/60000 (75%)]	Loss: 14.942019
Train Epoch: 8 [51136/60000 (85%)]	Loss: 13.939295
Train Epoch: 8 [57536/60000 (96%)]	Loss: 13.580645

Test set: Average loss: 15.1144, Accuracy: 1057/10000 (11%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 13.820927
Train Epoch: 9 [12736/60000 (21%)]	Loss: 13.610881
Train Epoch: 9 [19136/60000 (32%)]	Loss: 13.756950
Train Epoch: 9 [25536/60000 (43%)]	Loss: 15.145981
Train Epoch: 9 [31936/60000 (53%)]	Loss: 14.009302
Train Epoch: 9 [38336/60000 (64%)]	Loss: 15.257246
Train Epoch: 9 [44736/60000 (75%)]	Loss: 16.072266
Train Epoch: 9 [51136/60000 (85%)]	Loss: 16.175491
Train Epoch: 9 [57536/60000 (96%)]	Loss: 14.320423

Test set: Average loss: 15.3510, Accuracy: 1040/10000 (10%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 14.852839
Train Epoch: 10 [12736/60000 (21%)]	Loss: 13.593258
Train Epoch: 10 [19136/60000 (32%)]	Loss: 16.050785
Train Epoch: 10 [25536/60000 (43%)]	Loss: 14.755902
Train Epoch: 10 [31936/60000 (53%)]	Loss: 17.139069
Train Epoch: 10 [38336/60000 (64%)]	Loss: 16.618032
Train Epoch: 10 [44736/60000 (75%)]	Loss: 14.037962
Train Epoch: 10 [51136/60000 (85%)]	Loss: 16.943190
Train Epoch: 10 [57536/60000 (96%)]	Loss: 16.105236

Test set: Average loss: 14.4257, Accuracy: 1060/10000 (11%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 13.809252
Train Epoch: 11 [12736/60000 (21%)]	Loss: 12.508357
Train Epoch: 11 [19136/60000 (32%)]	Loss: 11.492483
Train Epoch: 11 [25536/60000 (43%)]	Loss: 14.952041
Train Epoch: 11 [31936/60000 (53%)]	Loss: 13.736154
Train Epoch: 11 [38336/60000 (64%)]	Loss: 14.417579
Train Epoch: 11 [44736/60000 (75%)]	Loss: 16.055595
Train Epoch: 11 [51136/60000 (85%)]	Loss: 12.892971
Train Epoch: 11 [57536/60000 (96%)]	Loss: 14.914207

Test set: Average loss: 15.2686, Accuracy: 1075/10000 (11%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 16.083345
Train Epoch: 12 [12736/60000 (21%)]	Loss: 16.257801
Train Epoch: 12 [19136/60000 (32%)]	Loss: 15.115700
Train Epoch: 12 [25536/60000 (43%)]	Loss: 13.305701
Train Epoch: 12 [31936/60000 (53%)]	Loss: 14.572887
Train Epoch: 12 [38336/60000 (64%)]	Loss: 15.566939
Train Epoch: 12 [44736/60000 (75%)]	Loss: 14.914195
Train Epoch: 12 [51136/60000 (85%)]	Loss: 15.487210
Train Epoch: 12 [57536/60000 (96%)]	Loss: 14.309809

Test set: Average loss: 15.4139, Accuracy: 912/10000 (9%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 15.594731
Train Epoch: 13 [12736/60000 (21%)]	Loss: 17.101900
Train Epoch: 13 [19136/60000 (32%)]	Loss: 14.921484
Train Epoch: 13 [25536/60000 (43%)]	Loss: 15.797550
Train Epoch: 13 [31936/60000 (53%)]	Loss: 15.808489
Train Epoch: 13 [38336/60000 (64%)]	Loss: 15.120792
Train Epoch: 13 [44736/60000 (75%)]	Loss: 12.995293
Train Epoch: 13 [51136/60000 (85%)]	Loss: 16.590807
Train Epoch: 13 [57536/60000 (96%)]	Loss: 15.710371

Test set: Average loss: 15.4804, Accuracy: 982/10000 (10%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.44 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1951591
