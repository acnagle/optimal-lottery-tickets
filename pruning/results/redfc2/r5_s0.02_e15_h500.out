Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.147642
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.262311
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.183369
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.792807
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.409176
Train Epoch: 1 [38336/60000 (64%)]	Loss: 4.080945
Train Epoch: 1 [44736/60000 (75%)]	Loss: 5.067652
Train Epoch: 1 [51136/60000 (85%)]	Loss: 5.304578
Train Epoch: 1 [57536/60000 (96%)]	Loss: 6.211132

Test set: Average loss: 6.7495, Accuracy: 3214/10000 (32%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 7.270298
Train Epoch: 2 [12736/60000 (21%)]	Loss: 7.630579
Train Epoch: 2 [19136/60000 (32%)]	Loss: 10.035781
Train Epoch: 2 [25536/60000 (43%)]	Loss: 10.906910
Train Epoch: 2 [31936/60000 (53%)]	Loss: 11.867736
Train Epoch: 2 [38336/60000 (64%)]	Loss: 11.500815
Train Epoch: 2 [44736/60000 (75%)]	Loss: 10.575611
Train Epoch: 2 [51136/60000 (85%)]	Loss: 11.289475
Train Epoch: 2 [57536/60000 (96%)]	Loss: 12.841454

Test set: Average loss: 11.2188, Accuracy: 1520/10000 (15%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 11.513909
Train Epoch: 3 [12736/60000 (21%)]	Loss: 13.862879
Train Epoch: 3 [19136/60000 (32%)]	Loss: 12.848390
Train Epoch: 3 [25536/60000 (43%)]	Loss: 11.759005
Train Epoch: 3 [31936/60000 (53%)]	Loss: 12.899843
Train Epoch: 3 [38336/60000 (64%)]	Loss: 13.500763
Train Epoch: 3 [44736/60000 (75%)]	Loss: 13.532167
Train Epoch: 3 [51136/60000 (85%)]	Loss: 14.077774
Train Epoch: 3 [57536/60000 (96%)]	Loss: 12.900247

Test set: Average loss: 13.7056, Accuracy: 1199/10000 (12%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 12.689224
Train Epoch: 4 [12736/60000 (21%)]	Loss: 14.366243
Train Epoch: 4 [19136/60000 (32%)]	Loss: 12.806208
Train Epoch: 4 [25536/60000 (43%)]	Loss: 16.336266
Train Epoch: 4 [31936/60000 (53%)]	Loss: 12.285982
Train Epoch: 4 [38336/60000 (64%)]	Loss: 11.915908
Train Epoch: 4 [44736/60000 (75%)]	Loss: 12.901068
Train Epoch: 4 [51136/60000 (85%)]	Loss: 12.225291
Train Epoch: 4 [57536/60000 (96%)]	Loss: 13.002505

Test set: Average loss: 14.1010, Accuracy: 1147/10000 (11%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 14.177479
Train Epoch: 5 [12736/60000 (21%)]	Loss: 14.955462
Train Epoch: 5 [19136/60000 (32%)]	Loss: 15.481037
Train Epoch: 5 [25536/60000 (43%)]	Loss: 14.061399
Train Epoch: 5 [31936/60000 (53%)]	Loss: 12.680463
Train Epoch: 5 [38336/60000 (64%)]	Loss: 13.709667
Train Epoch: 5 [44736/60000 (75%)]	Loss: 16.755905
Train Epoch: 5 [51136/60000 (85%)]	Loss: 17.226616
Train Epoch: 5 [57536/60000 (96%)]	Loss: 14.103404

Test set: Average loss: 14.2862, Accuracy: 1115/10000 (11%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 13.807740
Train Epoch: 6 [12736/60000 (21%)]	Loss: 12.343873
Train Epoch: 6 [19136/60000 (32%)]	Loss: 13.685470
Train Epoch: 6 [25536/60000 (43%)]	Loss: 14.092036
Train Epoch: 6 [31936/60000 (53%)]	Loss: 14.913410
Train Epoch: 6 [38336/60000 (64%)]	Loss: 16.577768
Train Epoch: 6 [44736/60000 (75%)]	Loss: 15.251057
Train Epoch: 6 [51136/60000 (85%)]	Loss: 15.660752
Train Epoch: 6 [57536/60000 (96%)]	Loss: 16.256327

Test set: Average loss: 14.9594, Accuracy: 990/10000 (10%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 14.685360
Train Epoch: 7 [12736/60000 (21%)]	Loss: 14.159544
Train Epoch: 7 [19136/60000 (32%)]	Loss: 13.604621
Train Epoch: 7 [25536/60000 (43%)]	Loss: 13.316234
Train Epoch: 7 [31936/60000 (53%)]	Loss: 11.378665
Train Epoch: 7 [38336/60000 (64%)]	Loss: 15.412357
Train Epoch: 7 [44736/60000 (75%)]	Loss: 14.627470
Train Epoch: 7 [51136/60000 (85%)]	Loss: 13.865832
Train Epoch: 7 [57536/60000 (96%)]	Loss: 13.025638

Test set: Average loss: 14.7009, Accuracy: 1113/10000 (11%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 15.247424
Train Epoch: 8 [12736/60000 (21%)]	Loss: 15.691970
Train Epoch: 8 [19136/60000 (32%)]	Loss: 12.572739
Train Epoch: 8 [25536/60000 (43%)]	Loss: 15.056919
Train Epoch: 8 [31936/60000 (53%)]	Loss: 15.287718
Train Epoch: 8 [38336/60000 (64%)]	Loss: 14.083886
Train Epoch: 8 [44736/60000 (75%)]	Loss: 15.310352
Train Epoch: 8 [51136/60000 (85%)]	Loss: 13.942224
Train Epoch: 8 [57536/60000 (96%)]	Loss: 13.988566

Test set: Average loss: 15.0843, Accuracy: 1073/10000 (11%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 13.866661
Train Epoch: 9 [12736/60000 (21%)]	Loss: 13.839341
Train Epoch: 9 [19136/60000 (32%)]	Loss: 13.753323
Train Epoch: 9 [25536/60000 (43%)]	Loss: 15.086806
Train Epoch: 9 [31936/60000 (53%)]	Loss: 13.981121
Train Epoch: 9 [38336/60000 (64%)]	Loss: 15.635167
Train Epoch: 9 [44736/60000 (75%)]	Loss: 15.771034
Train Epoch: 9 [51136/60000 (85%)]	Loss: 16.674545
Train Epoch: 9 [57536/60000 (96%)]	Loss: 13.691329

Test set: Average loss: 15.2296, Accuracy: 1075/10000 (11%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 15.337296
Train Epoch: 10 [12736/60000 (21%)]	Loss: 13.687814
Train Epoch: 10 [19136/60000 (32%)]	Loss: 16.687004
Train Epoch: 10 [25536/60000 (43%)]	Loss: 14.898662
Train Epoch: 10 [31936/60000 (53%)]	Loss: 17.290394
Train Epoch: 10 [38336/60000 (64%)]	Loss: 16.582146
Train Epoch: 10 [44736/60000 (75%)]	Loss: 14.654273
Train Epoch: 10 [51136/60000 (85%)]	Loss: 17.050781
Train Epoch: 10 [57536/60000 (96%)]	Loss: 15.655743

Test set: Average loss: 15.3021, Accuracy: 1105/10000 (11%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 14.278893
Train Epoch: 11 [12736/60000 (21%)]	Loss: 12.362682
Train Epoch: 11 [19136/60000 (32%)]	Loss: 11.756143
Train Epoch: 11 [25536/60000 (43%)]	Loss: 14.465925
Train Epoch: 11 [31936/60000 (53%)]	Loss: 14.366307
Train Epoch: 11 [38336/60000 (64%)]	Loss: 14.714668
Train Epoch: 11 [44736/60000 (75%)]	Loss: 16.296879
Train Epoch: 11 [51136/60000 (85%)]	Loss: 13.053831
Train Epoch: 11 [57536/60000 (96%)]	Loss: 14.483920

Test set: Average loss: 15.1990, Accuracy: 993/10000 (10%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 15.559077
Train Epoch: 12 [12736/60000 (21%)]	Loss: 16.156296
Train Epoch: 12 [19136/60000 (32%)]	Loss: 14.571150
Train Epoch: 12 [25536/60000 (43%)]	Loss: 13.062901
Train Epoch: 12 [31936/60000 (53%)]	Loss: 15.176579
Train Epoch: 12 [38336/60000 (64%)]	Loss: 16.108553
Train Epoch: 12 [44736/60000 (75%)]	Loss: 16.373045
Train Epoch: 12 [51136/60000 (85%)]	Loss: 15.457554
Train Epoch: 12 [57536/60000 (96%)]	Loss: 14.172873

Test set: Average loss: 15.6393, Accuracy: 1002/10000 (10%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 15.681149
Train Epoch: 13 [12736/60000 (21%)]	Loss: 16.966112
Train Epoch: 13 [19136/60000 (32%)]	Loss: 14.805791
Train Epoch: 13 [25536/60000 (43%)]	Loss: 15.895083
Train Epoch: 13 [31936/60000 (53%)]	Loss: 15.129672
Train Epoch: 13 [38336/60000 (64%)]	Loss: 15.583292
Train Epoch: 13 [44736/60000 (75%)]	Loss: 12.776894
Train Epoch: 13 [51136/60000 (85%)]	Loss: 16.185471
Train Epoch: 13 [57536/60000 (96%)]	Loss: 15.311408

Test set: Average loss: 15.1700, Accuracy: 1073/10000 (11%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 12.235707
Train Epoch: 14 [12736/60000 (21%)]	Loss: 14.552673
Train Epoch: 14 [19136/60000 (32%)]	Loss: 18.219540
Train Epoch: 14 [25536/60000 (43%)]	Loss: 13.237865
Train Epoch: 14 [31936/60000 (53%)]	Loss: 15.031068
Train Epoch: 14 [38336/60000 (64%)]	Loss: 18.770023
Train Epoch: 14 [44736/60000 (75%)]	Loss: 14.070119
Train Epoch: 14 [51136/60000 (85%)]	Loss: 16.872562
Train Epoch: 14 [57536/60000 (96%)]	Loss: 15.838708

Test set: Average loss: 15.3017, Accuracy: 990/10000 (10%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 14.792131
Train Epoch: 15 [12736/60000 (21%)]	Loss: 14.970958
Train Epoch: 15 [19136/60000 (32%)]	Loss: 14.829344
Train Epoch: 15 [25536/60000 (43%)]	Loss: 14.127095
Train Epoch: 15 [31936/60000 (53%)]	Loss: 16.202042
Train Epoch: 15 [38336/60000 (64%)]	Loss: 16.718058
Train Epoch: 15 [44736/60000 (75%)]	Loss: 12.262918
Train Epoch: 15 [51136/60000 (85%)]	Loss: 14.545345
Train Epoch: 15 [57536/60000 (96%)]	Loss: 16.594158

Test set: Average loss: 15.1860, Accuracy: 1081/10000 (11%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.64 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1951591
