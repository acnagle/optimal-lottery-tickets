Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.776434
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.822870
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.917803
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.081477
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.142877
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.278734
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.052520
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.387055
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.192310

Test set: Average loss: 1.7530, Accuracy: 5650/10000 (56%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.318110
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.277087
Train Epoch: 2 [19136/60000 (32%)]	Loss: 2.354747
Train Epoch: 2 [25536/60000 (43%)]	Loss: 3.193903
Train Epoch: 2 [31936/60000 (53%)]	Loss: 2.513916
Train Epoch: 2 [38336/60000 (64%)]	Loss: 3.053119
Train Epoch: 2 [44736/60000 (75%)]	Loss: 2.686924
Train Epoch: 2 [51136/60000 (85%)]	Loss: 3.303777
Train Epoch: 2 [57536/60000 (96%)]	Loss: 3.143880

Test set: Average loss: 3.5839, Accuracy: 2707/10000 (27%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 4.015050
Train Epoch: 3 [12736/60000 (21%)]	Loss: 4.694502
Train Epoch: 3 [19136/60000 (32%)]	Loss: 4.265346
Train Epoch: 3 [25536/60000 (43%)]	Loss: 3.600881
Train Epoch: 3 [31936/60000 (53%)]	Loss: 5.372248
Train Epoch: 3 [38336/60000 (64%)]	Loss: 4.942663
Train Epoch: 3 [44736/60000 (75%)]	Loss: 5.320306
Train Epoch: 3 [51136/60000 (85%)]	Loss: 5.393510
Train Epoch: 3 [57536/60000 (96%)]	Loss: 5.086147

Test set: Average loss: 5.3818, Accuracy: 1512/10000 (15%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 6.604850
Train Epoch: 4 [12736/60000 (21%)]	Loss: 4.585861
Train Epoch: 4 [19136/60000 (32%)]	Loss: 5.804243
Train Epoch: 4 [25536/60000 (43%)]	Loss: 6.286103
Train Epoch: 4 [31936/60000 (53%)]	Loss: 5.558273
Train Epoch: 4 [38336/60000 (64%)]	Loss: 6.159295
Train Epoch: 4 [44736/60000 (75%)]	Loss: 5.909281
Train Epoch: 4 [51136/60000 (85%)]	Loss: 6.265776
Train Epoch: 4 [57536/60000 (96%)]	Loss: 7.161479

Test set: Average loss: 6.4234, Accuracy: 1259/10000 (13%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 6.244805
Train Epoch: 5 [12736/60000 (21%)]	Loss: 6.628922
Train Epoch: 5 [19136/60000 (32%)]	Loss: 7.798925
Train Epoch: 5 [25536/60000 (43%)]	Loss: 7.138994
Train Epoch: 5 [31936/60000 (53%)]	Loss: 6.320200
Train Epoch: 5 [38336/60000 (64%)]	Loss: 6.837102
Train Epoch: 5 [44736/60000 (75%)]	Loss: 7.133608
Train Epoch: 5 [51136/60000 (85%)]	Loss: 7.194714
Train Epoch: 5 [57536/60000 (96%)]	Loss: 6.794286

Test set: Average loss: 6.8889, Accuracy: 1120/10000 (11%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 6.551502
Train Epoch: 6 [12736/60000 (21%)]	Loss: 6.898436
Train Epoch: 6 [19136/60000 (32%)]	Loss: 6.279610
Train Epoch: 6 [25536/60000 (43%)]	Loss: 7.608397
Train Epoch: 6 [31936/60000 (53%)]	Loss: 6.766810
Train Epoch: 6 [38336/60000 (64%)]	Loss: 7.133993
Train Epoch: 6 [44736/60000 (75%)]	Loss: 7.607892
Train Epoch: 6 [51136/60000 (85%)]	Loss: 7.500782
Train Epoch: 6 [57536/60000 (96%)]	Loss: 7.215126

Test set: Average loss: 7.2321, Accuracy: 1000/10000 (10%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 7.041330
Train Epoch: 7 [12736/60000 (21%)]	Loss: 7.314273
Train Epoch: 7 [19136/60000 (32%)]	Loss: 6.775246
Train Epoch: 7 [25536/60000 (43%)]	Loss: 6.414833
Train Epoch: 7 [31936/60000 (53%)]	Loss: 6.407842
Train Epoch: 7 [38336/60000 (64%)]	Loss: 7.543600
Train Epoch: 7 [44736/60000 (75%)]	Loss: 7.104839
Train Epoch: 7 [51136/60000 (85%)]	Loss: 8.418015
Train Epoch: 7 [57536/60000 (96%)]	Loss: 8.138854

Test set: Average loss: 7.3796, Accuracy: 967/10000 (10%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 8.512345
Train Epoch: 8 [12736/60000 (21%)]	Loss: 7.762082
Train Epoch: 8 [19136/60000 (32%)]	Loss: 6.457109
Train Epoch: 8 [25536/60000 (43%)]	Loss: 7.418843
Train Epoch: 8 [31936/60000 (53%)]	Loss: 6.547717
Train Epoch: 8 [38336/60000 (64%)]	Loss: 7.528690
Train Epoch: 8 [44736/60000 (75%)]	Loss: 8.149812
Train Epoch: 8 [51136/60000 (85%)]	Loss: 7.496203
Train Epoch: 8 [57536/60000 (96%)]	Loss: 8.077691

Test set: Average loss: 7.2917, Accuracy: 1025/10000 (10%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 7.017216
Train Epoch: 9 [12736/60000 (21%)]	Loss: 7.417166
Train Epoch: 9 [19136/60000 (32%)]	Loss: 7.417346
Train Epoch: 9 [25536/60000 (43%)]	Loss: 8.696605
Train Epoch: 9 [31936/60000 (53%)]	Loss: 6.881860
Train Epoch: 9 [38336/60000 (64%)]	Loss: 8.003964
Train Epoch: 9 [44736/60000 (75%)]	Loss: 8.297291
Train Epoch: 9 [51136/60000 (85%)]	Loss: 7.922019
Train Epoch: 9 [57536/60000 (96%)]	Loss: 7.548203

Test set: Average loss: 7.7062, Accuracy: 935/10000 (9%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 7.212375
Train Epoch: 10 [12736/60000 (21%)]	Loss: 7.052685
Train Epoch: 10 [19136/60000 (32%)]	Loss: 7.332219
Train Epoch: 10 [25536/60000 (43%)]	Loss: 8.237293
Train Epoch: 10 [31936/60000 (53%)]	Loss: 7.899108
Train Epoch: 10 [38336/60000 (64%)]	Loss: 7.314671
Train Epoch: 10 [44736/60000 (75%)]	Loss: 7.587698
Train Epoch: 10 [51136/60000 (85%)]	Loss: 7.862456
Train Epoch: 10 [57536/60000 (96%)]	Loss: 6.947835

Test set: Average loss: 7.6844, Accuracy: 984/10000 (10%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 7.010693
Train Epoch: 11 [12736/60000 (21%)]	Loss: 6.620736
Train Epoch: 11 [19136/60000 (32%)]	Loss: 7.177567
Train Epoch: 11 [25536/60000 (43%)]	Loss: 8.217482
Train Epoch: 11 [31936/60000 (53%)]	Loss: 6.992668
Train Epoch: 11 [38336/60000 (64%)]	Loss: 7.366080
Train Epoch: 11 [44736/60000 (75%)]	Loss: 9.643104
Train Epoch: 11 [51136/60000 (85%)]	Loss: 6.935272
Train Epoch: 11 [57536/60000 (96%)]	Loss: 8.172551

Test set: Average loss: 7.7811, Accuracy: 904/10000 (9%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 7.007850
Train Epoch: 12 [12736/60000 (21%)]	Loss: 8.486357
Train Epoch: 12 [19136/60000 (32%)]	Loss: 8.527340
Train Epoch: 12 [25536/60000 (43%)]	Loss: 7.724162
Train Epoch: 12 [31936/60000 (53%)]	Loss: 8.810511
Train Epoch: 12 [38336/60000 (64%)]	Loss: 8.681594
Train Epoch: 12 [44736/60000 (75%)]	Loss: 8.749392
Train Epoch: 12 [51136/60000 (85%)]	Loss: 8.354139
Train Epoch: 12 [57536/60000 (96%)]	Loss: 7.923207

Test set: Average loss: 8.0176, Accuracy: 809/10000 (8%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 7.231063
Train Epoch: 13 [12736/60000 (21%)]	Loss: 8.558306
Train Epoch: 13 [19136/60000 (32%)]	Loss: 8.144950
Train Epoch: 13 [25536/60000 (43%)]	Loss: 8.339156
Train Epoch: 13 [31936/60000 (53%)]	Loss: 7.473948
Train Epoch: 13 [38336/60000 (64%)]	Loss: 8.447318
Train Epoch: 13 [44736/60000 (75%)]	Loss: 7.848155
Train Epoch: 13 [51136/60000 (85%)]	Loss: 8.025703
Train Epoch: 13 [57536/60000 (96%)]	Loss: 7.857656

Test set: Average loss: 7.9994, Accuracy: 848/10000 (8%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 8.361727
Train Epoch: 14 [12736/60000 (21%)]	Loss: 8.192946
Train Epoch: 14 [19136/60000 (32%)]	Loss: 8.562188
Train Epoch: 14 [25536/60000 (43%)]	Loss: 8.630203
Train Epoch: 14 [31936/60000 (53%)]	Loss: 8.383853
Train Epoch: 14 [38336/60000 (64%)]	Loss: 8.886634
Train Epoch: 14 [44736/60000 (75%)]	Loss: 8.807090
Train Epoch: 14 [51136/60000 (85%)]	Loss: 8.284093
Train Epoch: 14 [57536/60000 (96%)]	Loss: 8.123570

Test set: Average loss: 8.0143, Accuracy: 838/10000 (8%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 8.122684
Train Epoch: 15 [12736/60000 (21%)]	Loss: 6.890807
Train Epoch: 15 [19136/60000 (32%)]	Loss: 6.826798
Train Epoch: 15 [25536/60000 (43%)]	Loss: 7.302988
Train Epoch: 15 [31936/60000 (53%)]	Loss: 8.730944
Train Epoch: 15 [38336/60000 (64%)]	Loss: 7.640333
Train Epoch: 15 [44736/60000 (75%)]	Loss: 6.771693
Train Epoch: 15 [51136/60000 (85%)]	Loss: 8.007908
Train Epoch: 15 [57536/60000 (96%)]	Loss: 8.231749

Test set: Average loss: 8.0219, Accuracy: 831/10000 (8%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 8.346090
Train Epoch: 16 [12736/60000 (21%)]	Loss: 7.772840
Train Epoch: 16 [19136/60000 (32%)]	Loss: 8.652712
Train Epoch: 16 [25536/60000 (43%)]	Loss: 7.610313
Train Epoch: 16 [31936/60000 (53%)]	Loss: 7.486588
Train Epoch: 16 [38336/60000 (64%)]	Loss: 8.807486
Train Epoch: 16 [44736/60000 (75%)]	Loss: 9.844543
Train Epoch: 16 [51136/60000 (85%)]	Loss: 8.185110
Train Epoch: 16 [57536/60000 (96%)]	Loss: 7.993368

Test set: Average loss: 7.9271, Accuracy: 846/10000 (8%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 7.217669
Train Epoch: 17 [12736/60000 (21%)]	Loss: 8.663830
Train Epoch: 17 [19136/60000 (32%)]	Loss: 8.913841
Train Epoch: 17 [25536/60000 (43%)]	Loss: 7.688454
Train Epoch: 17 [31936/60000 (53%)]	Loss: 8.974694
Train Epoch: 17 [38336/60000 (64%)]	Loss: 8.186080
Train Epoch: 17 [44736/60000 (75%)]	Loss: 8.354174
Train Epoch: 17 [51136/60000 (85%)]	Loss: 7.398198
Train Epoch: 17 [57536/60000 (96%)]	Loss: 8.302209

Test set: Average loss: 8.0899, Accuracy: 849/10000 (8%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 7.387163
Train Epoch: 18 [12736/60000 (21%)]	Loss: 8.904947
Train Epoch: 18 [19136/60000 (32%)]	Loss: 8.422697
Train Epoch: 18 [25536/60000 (43%)]	Loss: 7.770079
Train Epoch: 18 [31936/60000 (53%)]	Loss: 7.736786
Train Epoch: 18 [38336/60000 (64%)]	Loss: 7.167361
Train Epoch: 18 [44736/60000 (75%)]	Loss: 7.141287
Train Epoch: 18 [51136/60000 (85%)]	Loss: 8.306726
Train Epoch: 18 [57536/60000 (96%)]	Loss: 7.943967

Test set: Average loss: 8.2666, Accuracy: 865/10000 (9%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 9.395378
Train Epoch: 19 [12736/60000 (21%)]	Loss: 9.339571
Train Epoch: 19 [19136/60000 (32%)]	Loss: 8.380758
Train Epoch: 19 [25536/60000 (43%)]	Loss: 7.553907
Train Epoch: 19 [31936/60000 (53%)]	Loss: 7.861230
Train Epoch: 19 [38336/60000 (64%)]	Loss: 8.831771
Train Epoch: 19 [44736/60000 (75%)]	Loss: 7.864415
Train Epoch: 19 [51136/60000 (85%)]	Loss: 7.912817
Train Epoch: 19 [57536/60000 (96%)]	Loss: 9.609742

Test set: Average loss: 8.6372, Accuracy: 727/10000 (7%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.99 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1951591
