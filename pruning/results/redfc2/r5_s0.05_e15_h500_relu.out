Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=True, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.517663
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.645766
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.763680
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.387334
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.408293
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.336996
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.442142
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.232538
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.307562

Test set: Average loss: 0.3110, Accuracy: 8997/10000 (90%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.142332
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.431767
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.203448
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.381302
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.361096
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.342406
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.374213
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.449741
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.389353

Test set: Average loss: 0.3268, Accuracy: 9024/10000 (90%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.386372
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.257597
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.304707
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.448968
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.459849
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.458780
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.399131
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.388389
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.672360

Test set: Average loss: 0.3532, Accuracy: 8862/10000 (89%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.377075
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.638986
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.361382
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.428768
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.766187
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.801630
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.369124
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.420662
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.647654

Test set: Average loss: 0.4813, Accuracy: 8520/10000 (85%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.682321
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.485865
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.666853
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.819536
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.471353
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.011422
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.557894
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.043958
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.776223

Test set: Average loss: 0.8637, Accuracy: 7550/10000 (76%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.638541
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.287623
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.994625
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.780245
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.079008
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.195479
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.059512
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.119728
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.626181

Test set: Average loss: 1.3630, Accuracy: 6287/10000 (63%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.591734
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.670518
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.425740
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.176953
Train Epoch: 7 [31936/60000 (53%)]	Loss: 2.187560
Train Epoch: 7 [38336/60000 (64%)]	Loss: 2.241789
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.967002
Train Epoch: 7 [51136/60000 (85%)]	Loss: 2.532252
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.930259

Test set: Average loss: 2.1848, Accuracy: 4615/10000 (46%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 2.707282
Train Epoch: 8 [12736/60000 (21%)]	Loss: 2.155242
Train Epoch: 8 [19136/60000 (32%)]	Loss: 2.207015
Train Epoch: 8 [25536/60000 (43%)]	Loss: 2.156473
Train Epoch: 8 [31936/60000 (53%)]	Loss: 2.503181
Train Epoch: 8 [38336/60000 (64%)]	Loss: 2.242047
Train Epoch: 8 [44736/60000 (75%)]	Loss: 3.020878
Train Epoch: 8 [51136/60000 (85%)]	Loss: 2.418768
Train Epoch: 8 [57536/60000 (96%)]	Loss: 2.669155

Test set: Average loss: 2.5049, Accuracy: 4429/10000 (44%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 2.136372
Train Epoch: 9 [12736/60000 (21%)]	Loss: 2.638893
Train Epoch: 9 [19136/60000 (32%)]	Loss: 2.725127
Train Epoch: 9 [25536/60000 (43%)]	Loss: 3.028028
Train Epoch: 9 [31936/60000 (53%)]	Loss: 2.474238
Train Epoch: 9 [38336/60000 (64%)]	Loss: 2.744859
Train Epoch: 9 [44736/60000 (75%)]	Loss: 3.057433
Train Epoch: 9 [51136/60000 (85%)]	Loss: 3.218758
Train Epoch: 9 [57536/60000 (96%)]	Loss: 2.843419

Test set: Average loss: 2.9933, Accuracy: 3729/10000 (37%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 3.242228
Train Epoch: 10 [12736/60000 (21%)]	Loss: 2.817439
Train Epoch: 10 [19136/60000 (32%)]	Loss: 2.949360
Train Epoch: 10 [25536/60000 (43%)]	Loss: 2.866904
Train Epoch: 10 [31936/60000 (53%)]	Loss: 2.270618
Train Epoch: 10 [38336/60000 (64%)]	Loss: 3.274162
Train Epoch: 10 [44736/60000 (75%)]	Loss: 2.873190
Train Epoch: 10 [51136/60000 (85%)]	Loss: 2.894297
Train Epoch: 10 [57536/60000 (96%)]	Loss: 3.166837

Test set: Average loss: 2.8680, Accuracy: 3429/10000 (34%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 2.617560
Train Epoch: 11 [12736/60000 (21%)]	Loss: 2.365891
Train Epoch: 11 [19136/60000 (32%)]	Loss: 3.650620
Train Epoch: 11 [25536/60000 (43%)]	Loss: 2.963112
Train Epoch: 11 [31936/60000 (53%)]	Loss: 2.922050
Train Epoch: 11 [38336/60000 (64%)]	Loss: 3.561987
Train Epoch: 11 [44736/60000 (75%)]	Loss: 3.536284
Train Epoch: 11 [51136/60000 (85%)]	Loss: 3.056584
Train Epoch: 11 [57536/60000 (96%)]	Loss: 2.742823

Test set: Average loss: 3.5079, Accuracy: 2919/10000 (29%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 3.138201
Train Epoch: 12 [12736/60000 (21%)]	Loss: 3.886425
Train Epoch: 12 [19136/60000 (32%)]	Loss: 3.377322
Train Epoch: 12 [25536/60000 (43%)]	Loss: 3.553141
Train Epoch: 12 [31936/60000 (53%)]	Loss: 3.979299
Train Epoch: 12 [38336/60000 (64%)]	Loss: 4.233361
Train Epoch: 12 [44736/60000 (75%)]	Loss: 3.987150
Train Epoch: 12 [51136/60000 (85%)]	Loss: 3.498137
Train Epoch: 12 [57536/60000 (96%)]	Loss: 3.240644

Test set: Average loss: 4.0069, Accuracy: 2209/10000 (22%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 2.931652
Train Epoch: 13 [12736/60000 (21%)]	Loss: 3.982292
Train Epoch: 13 [19136/60000 (32%)]	Loss: 3.534172
Train Epoch: 13 [25536/60000 (43%)]	Loss: 3.482110
Train Epoch: 13 [31936/60000 (53%)]	Loss: 3.493992
Train Epoch: 13 [38336/60000 (64%)]	Loss: 4.369119
Train Epoch: 13 [44736/60000 (75%)]	Loss: 3.353403
Train Epoch: 13 [51136/60000 (85%)]	Loss: 3.464198
Train Epoch: 13 [57536/60000 (96%)]	Loss: 3.512965

Test set: Average loss: 3.3622, Accuracy: 2688/10000 (27%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 2.913506
Train Epoch: 14 [12736/60000 (21%)]	Loss: 3.391086
Train Epoch: 14 [19136/60000 (32%)]	Loss: 3.491120
Train Epoch: 14 [25536/60000 (43%)]	Loss: 3.569188
Train Epoch: 14 [31936/60000 (53%)]	Loss: 2.963380
Train Epoch: 14 [38336/60000 (64%)]	Loss: 4.291819
Train Epoch: 14 [44736/60000 (75%)]	Loss: 4.128805
Train Epoch: 14 [51136/60000 (85%)]	Loss: 3.247238
Train Epoch: 14 [57536/60000 (96%)]	Loss: 2.565518

Test set: Average loss: 3.3536, Accuracy: 2715/10000 (27%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 2.902739
Train Epoch: 15 [12736/60000 (21%)]	Loss: 2.647226
Train Epoch: 15 [19136/60000 (32%)]	Loss: 2.952305
Train Epoch: 15 [25536/60000 (43%)]	Loss: 2.595819
Train Epoch: 15 [31936/60000 (53%)]	Loss: 3.878572
Train Epoch: 15 [38336/60000 (64%)]	Loss: 3.524882
Train Epoch: 15 [44736/60000 (75%)]	Loss: 2.419132
Train Epoch: 15 [51136/60000 (85%)]	Loss: 3.905555
Train Epoch: 15 [57536/60000 (96%)]	Loss: 2.821637

Test set: Average loss: 3.5995, Accuracy: 3263/10000 (33%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.64 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1891849
