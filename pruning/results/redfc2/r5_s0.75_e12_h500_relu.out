Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=True, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.743024
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.527251
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.715980
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.490911
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.442560
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.425960
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.415416
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.299683
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.384081

Test set: Average loss: 0.3648, Accuracy: 8973/10000 (90%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.369347
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.441374
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.329689
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.454241
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.308704
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.316029
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.403943
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.480492
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.350618

Test set: Average loss: 0.3284, Accuracy: 9084/10000 (91%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.259328
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.266674
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.356144
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.378264
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.388100
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.395051
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.425354
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.342004
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.540342

Test set: Average loss: 0.3211, Accuracy: 9081/10000 (91%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.243200
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.559130
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.321464
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.387786
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.495135
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.501893
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.347947
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.260212
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.436600

Test set: Average loss: 0.3127, Accuracy: 9140/10000 (91%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.390301
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.318900
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.238594
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.428150
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.257779
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.383269
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.244278
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.406205
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.281150

Test set: Average loss: 0.3414, Accuracy: 8997/10000 (90%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.299104
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.305891
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.350370
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.270980
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.245120
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.286708
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.267764
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.288566
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.398752

Test set: Average loss: 0.3058, Accuracy: 9172/10000 (92%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.254453
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.273301
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.274213
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.207745
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.222394
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.328783
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.454106
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.305220
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.259340

Test set: Average loss: 0.3120, Accuracy: 9098/10000 (91%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.527557
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.333559
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.342107
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.372126
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.355523
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.210409
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.560782
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.326953
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.329126

Test set: Average loss: 0.3124, Accuracy: 9145/10000 (91%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.267726
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.385389
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.284316
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.361235
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.341349
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.418325
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.285837
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.502687
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.263885

Test set: Average loss: 0.2997, Accuracy: 9159/10000 (92%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.389821
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.355089
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.241008
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.253255
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.338096
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.354034
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.304282
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.203641
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.286260

Test set: Average loss: 0.2775, Accuracy: 9232/10000 (92%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.247731
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.257555
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.158348
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.281683
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.376862
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.214840
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.258430
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.348666
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.275043

Test set: Average loss: 0.2645, Accuracy: 9290/10000 (93%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.244481
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.322365
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.305208
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.162115
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.177352
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.440828
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.219317
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.259085
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.166854

Test set: Average loss: 0.2611, Accuracy: 9299/10000 (93%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.32 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 497855
