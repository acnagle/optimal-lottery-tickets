Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.98, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.251168
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.148080
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.037038
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.997554
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.919232
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.786208
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.788889
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.746992
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.747068

Test set: Average loss: 1.6558, Accuracy: 5639/10000 (56%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.702959
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.619479
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.643878
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.609790
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.576481
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.595888
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.535017
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.577769
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.559070

Test set: Average loss: 1.4596, Accuracy: 6245/10000 (62%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.387846
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.445264
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.574197
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.394342
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.408785
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.535226
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.508455
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.435633
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.477762

Test set: Average loss: 1.4421, Accuracy: 6438/10000 (64%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.408132
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.385763
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.463475
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.528828
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.505097
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.487418
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.409869
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.287664
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.527694

Test set: Average loss: 1.4579, Accuracy: 6320/10000 (63%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.504145
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.409719
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.412740
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.450925
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.458444
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.556004
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.482756
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.508085
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.528290

Test set: Average loss: 1.4464, Accuracy: 6012/10000 (60%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.456345
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.511746
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.545029
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.344558
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.370031
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.465554
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.430896
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.441353
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.473465

Test set: Average loss: 1.4901, Accuracy: 5860/10000 (59%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.478369
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.533776
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.567177
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.560867
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.507932
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.546185
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.625536
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.577451
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.483417

Test set: Average loss: 1.5249, Accuracy: 5462/10000 (55%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.644048
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.545504
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.530714
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.531099
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.554645
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.530172
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.563825
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.568126
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.571876

Test set: Average loss: 1.5290, Accuracy: 5375/10000 (54%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.539792
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.564835
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.556803
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.550711
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.453618
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.605551
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.570226
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.667759
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.542895

Test set: Average loss: 1.5314, Accuracy: 5523/10000 (55%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.629628
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.512346
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.554024
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.665137
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.536414
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.720731
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.679505
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.531845
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.634822

Test set: Average loss: 1.5405, Accuracy: 5465/10000 (55%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.492229
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.485484
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.554975
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.600089
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.716824
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.558686
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.583680
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.538596
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.513571

Test set: Average loss: 1.5644, Accuracy: 5877/10000 (59%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 1.626064
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.730448
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.635940
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.383994
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.650428
Train Epoch: 12 [38336/60000 (64%)]	Loss: 1.685651
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.527123
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.623043
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.584569

Test set: Average loss: 1.5517, Accuracy: 5838/10000 (58%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.567073
Train Epoch: 13 [12736/60000 (21%)]	Loss: 1.539398
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.472835
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.634201
Train Epoch: 13 [31936/60000 (53%)]	Loss: 1.583023
Train Epoch: 13 [38336/60000 (64%)]	Loss: 1.620999
Train Epoch: 13 [44736/60000 (75%)]	Loss: 1.446221
Train Epoch: 13 [51136/60000 (85%)]	Loss: 1.574512
Train Epoch: 13 [57536/60000 (96%)]	Loss: 1.587202

Test set: Average loss: 1.5462, Accuracy: 5612/10000 (56%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.437803
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.508463
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.587719
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.448481
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.493676
Train Epoch: 14 [38336/60000 (64%)]	Loss: 1.572137
Train Epoch: 14 [44736/60000 (75%)]	Loss: 1.485806
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.579897
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.424107

Test set: Average loss: 1.5188, Accuracy: 5803/10000 (58%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 1.516947
Train Epoch: 15 [12736/60000 (21%)]	Loss: 1.441113
Train Epoch: 15 [19136/60000 (32%)]	Loss: 1.418455
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.494844
Train Epoch: 15 [31936/60000 (53%)]	Loss: 1.496658
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.518945
Train Epoch: 15 [44736/60000 (75%)]	Loss: 1.479268
Train Epoch: 15 [51136/60000 (85%)]	Loss: 1.618716
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.494460

Test set: Average loss: 1.4722, Accuracy: 5941/10000 (59%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 1.466923
Train Epoch: 16 [12736/60000 (21%)]	Loss: 1.367896
Train Epoch: 16 [19136/60000 (32%)]	Loss: 1.251031
Train Epoch: 16 [25536/60000 (43%)]	Loss: 1.452758
Train Epoch: 16 [31936/60000 (53%)]	Loss: 1.495496
Train Epoch: 16 [38336/60000 (64%)]	Loss: 1.543237
Train Epoch: 16 [44736/60000 (75%)]	Loss: 1.442313
Train Epoch: 16 [51136/60000 (85%)]	Loss: 1.358130
Train Epoch: 16 [57536/60000 (96%)]	Loss: 1.453511

Test set: Average loss: 1.4507, Accuracy: 5846/10000 (58%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 1.386048
Train Epoch: 17 [12736/60000 (21%)]	Loss: 1.469631
Train Epoch: 17 [19136/60000 (32%)]	Loss: 1.427734
Train Epoch: 17 [25536/60000 (43%)]	Loss: 1.388734
Train Epoch: 17 [31936/60000 (53%)]	Loss: 1.403456
Train Epoch: 17 [38336/60000 (64%)]	Loss: 1.355829
Train Epoch: 17 [44736/60000 (75%)]	Loss: 1.456775
Train Epoch: 17 [51136/60000 (85%)]	Loss: 1.360562
Train Epoch: 17 [57536/60000 (96%)]	Loss: 1.554149

Test set: Average loss: 1.4126, Accuracy: 6348/10000 (63%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 1.358392
Train Epoch: 18 [12736/60000 (21%)]	Loss: 1.407230
Train Epoch: 18 [19136/60000 (32%)]	Loss: 1.401805
Train Epoch: 18 [25536/60000 (43%)]	Loss: 1.399199
Train Epoch: 18 [31936/60000 (53%)]	Loss: 1.316873
Train Epoch: 18 [38336/60000 (64%)]	Loss: 1.385026
Train Epoch: 18 [44736/60000 (75%)]	Loss: 1.377889
Train Epoch: 18 [51136/60000 (85%)]	Loss: 1.379390
Train Epoch: 18 [57536/60000 (96%)]	Loss: 1.352687

Test set: Average loss: 1.3744, Accuracy: 6361/10000 (64%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 1.339061
Train Epoch: 19 [12736/60000 (21%)]	Loss: 1.324595
Train Epoch: 19 [19136/60000 (32%)]	Loss: 1.360660
Train Epoch: 19 [25536/60000 (43%)]	Loss: 1.339257
Train Epoch: 19 [31936/60000 (53%)]	Loss: 1.327537
Train Epoch: 19 [38336/60000 (64%)]	Loss: 1.333981
Train Epoch: 19 [44736/60000 (75%)]	Loss: 1.340443
Train Epoch: 19 [51136/60000 (85%)]	Loss: 1.491796
Train Epoch: 19 [57536/60000 (96%)]	Loss: 1.245862

Test set: Average loss: 1.3682, Accuracy: 6599/10000 (66%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.98, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.99 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 39828
