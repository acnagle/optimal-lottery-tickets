Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.99, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.302585
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.302585
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.302585
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.302585
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.302585
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.302585
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.302552
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.302529
Train Epoch: 1 [57536/60000 (96%)]	Loss: 2.302541

Test set: Average loss: 2.3024, Accuracy: 1007/10000 (10%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.302104
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.300205
Train Epoch: 2 [19136/60000 (32%)]	Loss: 2.299778
Train Epoch: 2 [25536/60000 (43%)]	Loss: 2.301467
Train Epoch: 2 [31936/60000 (53%)]	Loss: 2.300526
Train Epoch: 2 [38336/60000 (64%)]	Loss: 2.299700
Train Epoch: 2 [44736/60000 (75%)]	Loss: 2.297882
Train Epoch: 2 [51136/60000 (85%)]	Loss: 2.283787
Train Epoch: 2 [57536/60000 (96%)]	Loss: 2.306599

Test set: Average loss: 2.2790, Accuracy: 1497/10000 (15%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 2.268156
Train Epoch: 3 [12736/60000 (21%)]	Loss: 2.274538
Train Epoch: 3 [19136/60000 (32%)]	Loss: 2.276101
Train Epoch: 3 [25536/60000 (43%)]	Loss: 2.269594
Train Epoch: 3 [31936/60000 (53%)]	Loss: 2.270381
Train Epoch: 3 [38336/60000 (64%)]	Loss: 2.276665
Train Epoch: 3 [44736/60000 (75%)]	Loss: 2.257529
Train Epoch: 3 [51136/60000 (85%)]	Loss: 2.283264
Train Epoch: 3 [57536/60000 (96%)]	Loss: 2.281909

Test set: Average loss: 2.2491, Accuracy: 1689/10000 (17%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 2.265314
Train Epoch: 4 [12736/60000 (21%)]	Loss: 2.293857
Train Epoch: 4 [19136/60000 (32%)]	Loss: 2.249429
Train Epoch: 4 [25536/60000 (43%)]	Loss: 2.239077
Train Epoch: 4 [31936/60000 (53%)]	Loss: 2.228516
Train Epoch: 4 [38336/60000 (64%)]	Loss: 2.283018
Train Epoch: 4 [44736/60000 (75%)]	Loss: 2.265368
Train Epoch: 4 [51136/60000 (85%)]	Loss: 2.289673
Train Epoch: 4 [57536/60000 (96%)]	Loss: 2.247188

Test set: Average loss: 2.2378, Accuracy: 1835/10000 (18%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 2.245060
Train Epoch: 5 [12736/60000 (21%)]	Loss: 2.206561
Train Epoch: 5 [19136/60000 (32%)]	Loss: 2.252883
Train Epoch: 5 [25536/60000 (43%)]	Loss: 2.217383
Train Epoch: 5 [31936/60000 (53%)]	Loss: 2.234615
Train Epoch: 5 [38336/60000 (64%)]	Loss: 2.218099
Train Epoch: 5 [44736/60000 (75%)]	Loss: 2.227520
Train Epoch: 5 [51136/60000 (85%)]	Loss: 2.213732
Train Epoch: 5 [57536/60000 (96%)]	Loss: 2.217891

Test set: Average loss: 2.2180, Accuracy: 2208/10000 (22%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 2.211138
Train Epoch: 6 [12736/60000 (21%)]	Loss: 2.232546
Train Epoch: 6 [19136/60000 (32%)]	Loss: 2.176503
Train Epoch: 6 [25536/60000 (43%)]	Loss: 2.245947
Train Epoch: 6 [31936/60000 (53%)]	Loss: 2.203738
Train Epoch: 6 [38336/60000 (64%)]	Loss: 2.240444
Train Epoch: 6 [44736/60000 (75%)]	Loss: 2.229004
Train Epoch: 6 [51136/60000 (85%)]	Loss: 2.211498
Train Epoch: 6 [57536/60000 (96%)]	Loss: 2.197593

Test set: Average loss: 2.1969, Accuracy: 2816/10000 (28%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 2.169598
Train Epoch: 7 [12736/60000 (21%)]	Loss: 2.248509
Train Epoch: 7 [19136/60000 (32%)]	Loss: 2.213855
Train Epoch: 7 [25536/60000 (43%)]	Loss: 2.223691
Train Epoch: 7 [31936/60000 (53%)]	Loss: 2.162391
Train Epoch: 7 [38336/60000 (64%)]	Loss: 2.230523
Train Epoch: 7 [44736/60000 (75%)]	Loss: 2.236526
Train Epoch: 7 [51136/60000 (85%)]	Loss: 2.230905
Train Epoch: 7 [57536/60000 (96%)]	Loss: 2.191819

Test set: Average loss: 2.1948, Accuracy: 2846/10000 (28%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 2.249987
Train Epoch: 8 [12736/60000 (21%)]	Loss: 2.169600
Train Epoch: 8 [19136/60000 (32%)]	Loss: 2.219987
Train Epoch: 8 [25536/60000 (43%)]	Loss: 2.213459
Train Epoch: 8 [31936/60000 (53%)]	Loss: 2.228000
Train Epoch: 8 [38336/60000 (64%)]	Loss: 2.220463
Train Epoch: 8 [44736/60000 (75%)]	Loss: 2.188181
Train Epoch: 8 [51136/60000 (85%)]	Loss: 2.169939
Train Epoch: 8 [57536/60000 (96%)]	Loss: 2.205871

Test set: Average loss: 2.1859, Accuracy: 3049/10000 (30%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 2.115478
Train Epoch: 9 [12736/60000 (21%)]	Loss: 2.227396
Train Epoch: 9 [19136/60000 (32%)]	Loss: 2.174025
Train Epoch: 9 [25536/60000 (43%)]	Loss: 2.187183
Train Epoch: 9 [31936/60000 (53%)]	Loss: 2.187639
Train Epoch: 9 [38336/60000 (64%)]	Loss: 2.211410
Train Epoch: 9 [44736/60000 (75%)]	Loss: 2.165573
Train Epoch: 9 [51136/60000 (85%)]	Loss: 2.182100
Train Epoch: 9 [57536/60000 (96%)]	Loss: 2.200453

Test set: Average loss: 2.1840, Accuracy: 3063/10000 (31%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 2.156198
Train Epoch: 10 [12736/60000 (21%)]	Loss: 2.164462
Train Epoch: 10 [19136/60000 (32%)]	Loss: 2.170772
Train Epoch: 10 [25536/60000 (43%)]	Loss: 2.195314
Train Epoch: 10 [31936/60000 (53%)]	Loss: 2.222957
Train Epoch: 10 [38336/60000 (64%)]	Loss: 2.240860
Train Epoch: 10 [44736/60000 (75%)]	Loss: 2.258981
Train Epoch: 10 [51136/60000 (85%)]	Loss: 2.170116
Train Epoch: 10 [57536/60000 (96%)]	Loss: 2.255277

Test set: Average loss: 2.1723, Accuracy: 3115/10000 (31%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 2.141095
Train Epoch: 11 [12736/60000 (21%)]	Loss: 2.158143
Train Epoch: 11 [19136/60000 (32%)]	Loss: 2.175462
Train Epoch: 11 [25536/60000 (43%)]	Loss: 2.183977
Train Epoch: 11 [31936/60000 (53%)]	Loss: 2.203719
Train Epoch: 11 [38336/60000 (64%)]	Loss: 2.137198
Train Epoch: 11 [44736/60000 (75%)]	Loss: 2.180188
Train Epoch: 11 [51136/60000 (85%)]	Loss: 2.200791
Train Epoch: 11 [57536/60000 (96%)]	Loss: 2.170362

Test set: Average loss: 2.1679, Accuracy: 3197/10000 (32%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 2.145365
Train Epoch: 12 [12736/60000 (21%)]	Loss: 2.170593
Train Epoch: 12 [19136/60000 (32%)]	Loss: 2.176063
Train Epoch: 12 [25536/60000 (43%)]	Loss: 2.189697
Train Epoch: 12 [31936/60000 (53%)]	Loss: 2.189273
Train Epoch: 12 [38336/60000 (64%)]	Loss: 2.134135
Train Epoch: 12 [44736/60000 (75%)]	Loss: 2.156612
Train Epoch: 12 [51136/60000 (85%)]	Loss: 2.123559
Train Epoch: 12 [57536/60000 (96%)]	Loss: 2.156971

Test set: Average loss: 2.1593, Accuracy: 3112/10000 (31%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 2.201099
Train Epoch: 13 [12736/60000 (21%)]	Loss: 2.169918
Train Epoch: 13 [19136/60000 (32%)]	Loss: 2.167484
Train Epoch: 13 [25536/60000 (43%)]	Loss: 2.176375
Train Epoch: 13 [31936/60000 (53%)]	Loss: 2.145105
Train Epoch: 13 [38336/60000 (64%)]	Loss: 2.217331
Train Epoch: 13 [44736/60000 (75%)]	Loss: 2.160405
Train Epoch: 13 [51136/60000 (85%)]	Loss: 2.128821
Train Epoch: 13 [57536/60000 (96%)]	Loss: 2.187099

Test set: Average loss: 2.1560, Accuracy: 3217/10000 (32%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 2.187025
Train Epoch: 14 [12736/60000 (21%)]	Loss: 2.145060
Train Epoch: 14 [19136/60000 (32%)]	Loss: 2.166026
Train Epoch: 14 [25536/60000 (43%)]	Loss: 2.132133
Train Epoch: 14 [31936/60000 (53%)]	Loss: 2.143530
Train Epoch: 14 [38336/60000 (64%)]	Loss: 2.137543
Train Epoch: 14 [44736/60000 (75%)]	Loss: 2.175709
Train Epoch: 14 [51136/60000 (85%)]	Loss: 2.140079
Train Epoch: 14 [57536/60000 (96%)]	Loss: 2.139446

Test set: Average loss: 2.1421, Accuracy: 3487/10000 (35%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 2.123221
Train Epoch: 15 [12736/60000 (21%)]	Loss: 2.171844
Train Epoch: 15 [19136/60000 (32%)]	Loss: 2.193871
Train Epoch: 15 [25536/60000 (43%)]	Loss: 2.122467
Train Epoch: 15 [31936/60000 (53%)]	Loss: 2.134492
Train Epoch: 15 [38336/60000 (64%)]	Loss: 2.183423
Train Epoch: 15 [44736/60000 (75%)]	Loss: 2.148156
Train Epoch: 15 [51136/60000 (85%)]	Loss: 2.159641
Train Epoch: 15 [57536/60000 (96%)]	Loss: 2.144495

Test set: Average loss: 2.1380, Accuracy: 3077/10000 (31%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 2.139467
Train Epoch: 16 [12736/60000 (21%)]	Loss: 2.082967
Train Epoch: 16 [19136/60000 (32%)]	Loss: 2.129986
Train Epoch: 16 [25536/60000 (43%)]	Loss: 2.169668
Train Epoch: 16 [31936/60000 (53%)]	Loss: 2.127864
Train Epoch: 16 [38336/60000 (64%)]	Loss: 2.166702
Train Epoch: 16 [44736/60000 (75%)]	Loss: 2.122163
Train Epoch: 16 [51136/60000 (85%)]	Loss: 2.140873
Train Epoch: 16 [57536/60000 (96%)]	Loss: 2.159528

Test set: Average loss: 2.1377, Accuracy: 3081/10000 (31%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 2.135301
Train Epoch: 17 [12736/60000 (21%)]	Loss: 2.139726
Train Epoch: 17 [19136/60000 (32%)]	Loss: 2.131992
Train Epoch: 17 [25536/60000 (43%)]	Loss: 2.135502
Train Epoch: 17 [31936/60000 (53%)]	Loss: 2.151671
Train Epoch: 17 [38336/60000 (64%)]	Loss: 2.170135
Train Epoch: 17 [44736/60000 (75%)]	Loss: 2.167833
Train Epoch: 17 [51136/60000 (85%)]	Loss: 2.142273
Train Epoch: 17 [57536/60000 (96%)]	Loss: 2.183660

Test set: Average loss: 2.1364, Accuracy: 3155/10000 (32%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.99, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.79 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 19914
