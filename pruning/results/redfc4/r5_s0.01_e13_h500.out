Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 31.911699
Train Epoch: 1 [12736/60000 (21%)]	Loss: 61.911823
Train Epoch: 1 [19136/60000 (32%)]	Loss: 91.175339
Train Epoch: 1 [25536/60000 (43%)]	Loss: 93.368652
Train Epoch: 1 [31936/60000 (53%)]	Loss: 97.209946
Train Epoch: 1 [38336/60000 (64%)]	Loss: 109.680611
Train Epoch: 1 [44736/60000 (75%)]	Loss: 124.418159
Train Epoch: 1 [51136/60000 (85%)]	Loss: 113.008614
Train Epoch: 1 [57536/60000 (96%)]	Loss: 135.440491

Test set: Average loss: 126.7376, Accuracy: 1154/10000 (12%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 118.310211
Train Epoch: 2 [12736/60000 (21%)]	Loss: 127.903183
Train Epoch: 2 [19136/60000 (32%)]	Loss: 133.893845
Train Epoch: 2 [25536/60000 (43%)]	Loss: 133.468231
Train Epoch: 2 [31936/60000 (53%)]	Loss: 125.506950
Train Epoch: 2 [38336/60000 (64%)]	Loss: 150.462265
Train Epoch: 2 [44736/60000 (75%)]	Loss: 137.963669
Train Epoch: 2 [51136/60000 (85%)]	Loss: 148.590469
Train Epoch: 2 [57536/60000 (96%)]	Loss: 156.071579

Test set: Average loss: 145.0586, Accuracy: 1103/10000 (11%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 125.279358
Train Epoch: 3 [12736/60000 (21%)]	Loss: 143.250793
Train Epoch: 3 [19136/60000 (32%)]	Loss: 155.069229
Train Epoch: 3 [25536/60000 (43%)]	Loss: 163.191879
Train Epoch: 3 [31936/60000 (53%)]	Loss: 139.295410
Train Epoch: 3 [38336/60000 (64%)]	Loss: 142.344757
Train Epoch: 3 [44736/60000 (75%)]	Loss: 138.865295
Train Epoch: 3 [51136/60000 (85%)]	Loss: 139.615677
Train Epoch: 3 [57536/60000 (96%)]	Loss: 145.450928

Test set: Average loss: 147.9854, Accuracy: 1126/10000 (11%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 138.577255
Train Epoch: 4 [12736/60000 (21%)]	Loss: 182.503036
Train Epoch: 4 [19136/60000 (32%)]	Loss: 152.424988
Train Epoch: 4 [25536/60000 (43%)]	Loss: 163.085419
Train Epoch: 4 [31936/60000 (53%)]	Loss: 150.624725
Train Epoch: 4 [38336/60000 (64%)]	Loss: 167.546783
Train Epoch: 4 [44736/60000 (75%)]	Loss: 140.581116
Train Epoch: 4 [51136/60000 (85%)]	Loss: 153.490311
Train Epoch: 4 [57536/60000 (96%)]	Loss: 125.872917

Test set: Average loss: 153.6791, Accuracy: 1098/10000 (11%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 155.181000
Train Epoch: 5 [12736/60000 (21%)]	Loss: 151.695786
Train Epoch: 5 [19136/60000 (32%)]	Loss: 151.603439
Train Epoch: 5 [25536/60000 (43%)]	Loss: 153.059158
Train Epoch: 5 [31936/60000 (53%)]	Loss: 165.023468
Train Epoch: 5 [38336/60000 (64%)]	Loss: 137.130554
Train Epoch: 5 [44736/60000 (75%)]	Loss: 160.835098
Train Epoch: 5 [51136/60000 (85%)]	Loss: 150.053879
Train Epoch: 5 [57536/60000 (96%)]	Loss: 170.810760

Test set: Average loss: 157.4259, Accuracy: 1083/10000 (11%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 136.474655
Train Epoch: 6 [12736/60000 (21%)]	Loss: 139.646484
Train Epoch: 6 [19136/60000 (32%)]	Loss: 173.362106
Train Epoch: 6 [25536/60000 (43%)]	Loss: 153.253662
Train Epoch: 6 [31936/60000 (53%)]	Loss: 176.315216
Train Epoch: 6 [38336/60000 (64%)]	Loss: 157.006729
Train Epoch: 6 [44736/60000 (75%)]	Loss: 148.630737
Train Epoch: 6 [51136/60000 (85%)]	Loss: 164.555817
Train Epoch: 6 [57536/60000 (96%)]	Loss: 171.430420

Test set: Average loss: 158.0920, Accuracy: 1096/10000 (11%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 157.842499
Train Epoch: 7 [12736/60000 (21%)]	Loss: 162.908310
Train Epoch: 7 [19136/60000 (32%)]	Loss: 169.176331
Train Epoch: 7 [25536/60000 (43%)]	Loss: 147.569153
Train Epoch: 7 [31936/60000 (53%)]	Loss: 169.526703
Train Epoch: 7 [38336/60000 (64%)]	Loss: 167.606857
Train Epoch: 7 [44736/60000 (75%)]	Loss: 150.755066
Train Epoch: 7 [51136/60000 (85%)]	Loss: 144.330032
Train Epoch: 7 [57536/60000 (96%)]	Loss: 171.541992

Test set: Average loss: 154.2054, Accuracy: 1085/10000 (11%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 156.372528
Train Epoch: 8 [12736/60000 (21%)]	Loss: 142.972977
Train Epoch: 8 [19136/60000 (32%)]	Loss: 168.861877
Train Epoch: 8 [25536/60000 (43%)]	Loss: 154.345825
Train Epoch: 8 [31936/60000 (53%)]	Loss: 151.011612
Train Epoch: 8 [38336/60000 (64%)]	Loss: 153.001389
Train Epoch: 8 [44736/60000 (75%)]	Loss: 152.962845
Train Epoch: 8 [51136/60000 (85%)]	Loss: 151.249893
Train Epoch: 8 [57536/60000 (96%)]	Loss: 147.416687

Test set: Average loss: 154.8810, Accuracy: 1063/10000 (11%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 152.862930
Train Epoch: 9 [12736/60000 (21%)]	Loss: 162.664200
Train Epoch: 9 [19136/60000 (32%)]	Loss: 160.824432
Train Epoch: 9 [25536/60000 (43%)]	Loss: 145.317963
Train Epoch: 9 [31936/60000 (53%)]	Loss: 156.509979
Train Epoch: 9 [38336/60000 (64%)]	Loss: 161.312897
Train Epoch: 9 [44736/60000 (75%)]	Loss: 160.545273
Train Epoch: 9 [51136/60000 (85%)]	Loss: 164.233749
Train Epoch: 9 [57536/60000 (96%)]	Loss: 183.419876

Test set: Average loss: 161.6614, Accuracy: 1086/10000 (11%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 162.674438
Train Epoch: 10 [12736/60000 (21%)]	Loss: 151.785950
Train Epoch: 10 [19136/60000 (32%)]	Loss: 160.829819
Train Epoch: 10 [25536/60000 (43%)]	Loss: 167.826477
Train Epoch: 10 [31936/60000 (53%)]	Loss: 194.076141
Train Epoch: 10 [38336/60000 (64%)]	Loss: 159.015671
Train Epoch: 10 [44736/60000 (75%)]	Loss: 169.159119
Train Epoch: 10 [51136/60000 (85%)]	Loss: 182.616272
Train Epoch: 10 [57536/60000 (96%)]	Loss: 157.242432

Test set: Average loss: 160.1213, Accuracy: 1072/10000 (11%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 144.874557
Train Epoch: 11 [12736/60000 (21%)]	Loss: 157.257980
Train Epoch: 11 [19136/60000 (32%)]	Loss: 174.777893
Train Epoch: 11 [25536/60000 (43%)]	Loss: 130.270081
Train Epoch: 11 [31936/60000 (53%)]	Loss: 160.813766
Train Epoch: 11 [38336/60000 (64%)]	Loss: 146.941162
Train Epoch: 11 [44736/60000 (75%)]	Loss: 152.995987
Train Epoch: 11 [51136/60000 (85%)]	Loss: 163.015610
Train Epoch: 11 [57536/60000 (96%)]	Loss: 171.130981

Test set: Average loss: 157.6647, Accuracy: 1065/10000 (11%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 142.063522
Train Epoch: 12 [12736/60000 (21%)]	Loss: 163.384949
Train Epoch: 12 [19136/60000 (32%)]	Loss: 177.328842
Train Epoch: 12 [25536/60000 (43%)]	Loss: 160.475357
Train Epoch: 12 [31936/60000 (53%)]	Loss: 158.840103
Train Epoch: 12 [38336/60000 (64%)]	Loss: 162.910507
Train Epoch: 12 [44736/60000 (75%)]	Loss: 157.984360
Train Epoch: 12 [51136/60000 (85%)]	Loss: 174.741943
Train Epoch: 12 [57536/60000 (96%)]	Loss: 152.554382

Test set: Average loss: 156.4846, Accuracy: 1103/10000 (11%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 163.432022
Train Epoch: 13 [12736/60000 (21%)]	Loss: 145.786758
Train Epoch: 13 [19136/60000 (32%)]	Loss: 195.309998
Train Epoch: 13 [25536/60000 (43%)]	Loss: 161.090012
Train Epoch: 13 [31936/60000 (53%)]	Loss: 163.674026
Train Epoch: 13 [38336/60000 (64%)]	Loss: 157.678040
Train Epoch: 13 [44736/60000 (75%)]	Loss: 157.220810
Train Epoch: 13 [51136/60000 (85%)]	Loss: 143.708572
Train Epoch: 13 [57536/60000 (96%)]	Loss: 158.641052

Test set: Average loss: 154.5018, Accuracy: 1075/10000 (11%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.60 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4451455
