Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 4.100196
Train Epoch: 1 [12736/60000 (21%)]	Loss: 6.280535
Train Epoch: 1 [19136/60000 (32%)]	Loss: 8.182125
Train Epoch: 1 [25536/60000 (43%)]	Loss: 11.816093
Train Epoch: 1 [31936/60000 (53%)]	Loss: 9.195341
Train Epoch: 1 [38336/60000 (64%)]	Loss: 10.442177
Train Epoch: 1 [44736/60000 (75%)]	Loss: 14.871454
Train Epoch: 1 [51136/60000 (85%)]	Loss: 17.012016
Train Epoch: 1 [57536/60000 (96%)]	Loss: 19.724110

Test set: Average loss: 18.5289, Accuracy: 2239/10000 (22%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 27.362635
Train Epoch: 2 [12736/60000 (21%)]	Loss: 22.037664
Train Epoch: 2 [19136/60000 (32%)]	Loss: 25.239218
Train Epoch: 2 [25536/60000 (43%)]	Loss: 22.198063
Train Epoch: 2 [31936/60000 (53%)]	Loss: 21.411793
Train Epoch: 2 [38336/60000 (64%)]	Loss: 22.863911
Train Epoch: 2 [44736/60000 (75%)]	Loss: 26.929008
Train Epoch: 2 [51136/60000 (85%)]	Loss: 24.501339
Train Epoch: 2 [57536/60000 (96%)]	Loss: 26.443781

Test set: Average loss: 27.2009, Accuracy: 1686/10000 (17%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 21.914761
Train Epoch: 3 [12736/60000 (21%)]	Loss: 25.692366
Train Epoch: 3 [19136/60000 (32%)]	Loss: 24.197266
Train Epoch: 3 [25536/60000 (43%)]	Loss: 24.892298
Train Epoch: 3 [31936/60000 (53%)]	Loss: 28.512272
Train Epoch: 3 [38336/60000 (64%)]	Loss: 29.886707
Train Epoch: 3 [44736/60000 (75%)]	Loss: 26.632669
Train Epoch: 3 [51136/60000 (85%)]	Loss: 23.392441
Train Epoch: 3 [57536/60000 (96%)]	Loss: 28.655348

Test set: Average loss: 29.4859, Accuracy: 1489/10000 (15%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 26.852699
Train Epoch: 4 [12736/60000 (21%)]	Loss: 33.441425
Train Epoch: 4 [19136/60000 (32%)]	Loss: 33.546761
Train Epoch: 4 [25536/60000 (43%)]	Loss: 33.854668
Train Epoch: 4 [31936/60000 (53%)]	Loss: 32.516888
Train Epoch: 4 [38336/60000 (64%)]	Loss: 27.587002
Train Epoch: 4 [44736/60000 (75%)]	Loss: 30.927711
Train Epoch: 4 [51136/60000 (85%)]	Loss: 26.223619
Train Epoch: 4 [57536/60000 (96%)]	Loss: 22.836514

Test set: Average loss: 31.0139, Accuracy: 1454/10000 (15%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 31.694498
Train Epoch: 5 [12736/60000 (21%)]	Loss: 28.168051
Train Epoch: 5 [19136/60000 (32%)]	Loss: 30.184994
Train Epoch: 5 [25536/60000 (43%)]	Loss: 29.590715
Train Epoch: 5 [31936/60000 (53%)]	Loss: 32.225933
Train Epoch: 5 [38336/60000 (64%)]	Loss: 29.106838
Train Epoch: 5 [44736/60000 (75%)]	Loss: 34.710396
Train Epoch: 5 [51136/60000 (85%)]	Loss: 31.332811
Train Epoch: 5 [57536/60000 (96%)]	Loss: 35.675930

Test set: Average loss: 32.5627, Accuracy: 1509/10000 (15%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 31.209593
Train Epoch: 6 [12736/60000 (21%)]	Loss: 34.424641
Train Epoch: 6 [19136/60000 (32%)]	Loss: 35.449539
Train Epoch: 6 [25536/60000 (43%)]	Loss: 27.470753
Train Epoch: 6 [31936/60000 (53%)]	Loss: 32.782471
Train Epoch: 6 [38336/60000 (64%)]	Loss: 30.837196
Train Epoch: 6 [44736/60000 (75%)]	Loss: 37.245064
Train Epoch: 6 [51136/60000 (85%)]	Loss: 35.577812
Train Epoch: 6 [57536/60000 (96%)]	Loss: 36.490463

Test set: Average loss: 33.0731, Accuracy: 1460/10000 (15%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 31.268406
Train Epoch: 7 [12736/60000 (21%)]	Loss: 26.892738
Train Epoch: 7 [19136/60000 (32%)]	Loss: 30.508242
Train Epoch: 7 [25536/60000 (43%)]	Loss: 34.560947
Train Epoch: 7 [31936/60000 (53%)]	Loss: 40.266907
Train Epoch: 7 [38336/60000 (64%)]	Loss: 31.119732
Train Epoch: 7 [44736/60000 (75%)]	Loss: 34.577621
Train Epoch: 7 [51136/60000 (85%)]	Loss: 30.682438
Train Epoch: 7 [57536/60000 (96%)]	Loss: 34.397095

Test set: Average loss: 33.4464, Accuracy: 1448/10000 (14%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 35.446503
Train Epoch: 8 [12736/60000 (21%)]	Loss: 25.827868
Train Epoch: 8 [19136/60000 (32%)]	Loss: 35.520317
Train Epoch: 8 [25536/60000 (43%)]	Loss: 31.293161
Train Epoch: 8 [31936/60000 (53%)]	Loss: 29.218096
Train Epoch: 8 [38336/60000 (64%)]	Loss: 36.840034
Train Epoch: 8 [44736/60000 (75%)]	Loss: 33.707897
Train Epoch: 8 [51136/60000 (85%)]	Loss: 32.750805
Train Epoch: 8 [57536/60000 (96%)]	Loss: 33.866886

Test set: Average loss: 33.7912, Accuracy: 1469/10000 (15%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 34.681469
Train Epoch: 9 [12736/60000 (21%)]	Loss: 33.249836
Train Epoch: 9 [19136/60000 (32%)]	Loss: 37.425655
Train Epoch: 9 [25536/60000 (43%)]	Loss: 28.026798
Train Epoch: 9 [31936/60000 (53%)]	Loss: 30.937111
Train Epoch: 9 [38336/60000 (64%)]	Loss: 34.707264
Train Epoch: 9 [44736/60000 (75%)]	Loss: 31.299170
Train Epoch: 9 [51136/60000 (85%)]	Loss: 30.852180
Train Epoch: 9 [57536/60000 (96%)]	Loss: 37.470371

Test set: Average loss: 34.1722, Accuracy: 1435/10000 (14%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 35.558105
Train Epoch: 10 [12736/60000 (21%)]	Loss: 34.570011
Train Epoch: 10 [19136/60000 (32%)]	Loss: 36.107124
Train Epoch: 10 [25536/60000 (43%)]	Loss: 29.783899
Train Epoch: 10 [31936/60000 (53%)]	Loss: 37.430893
Train Epoch: 10 [38336/60000 (64%)]	Loss: 33.740055
Train Epoch: 10 [44736/60000 (75%)]	Loss: 38.060925
Train Epoch: 10 [51136/60000 (85%)]	Loss: 35.498390
Train Epoch: 10 [57536/60000 (96%)]	Loss: 32.004715

Test set: Average loss: 33.9863, Accuracy: 1431/10000 (14%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 35.620441
Train Epoch: 11 [12736/60000 (21%)]	Loss: 36.728371
Train Epoch: 11 [19136/60000 (32%)]	Loss: 33.247040
Train Epoch: 11 [25536/60000 (43%)]	Loss: 35.110958
Train Epoch: 11 [31936/60000 (53%)]	Loss: 30.989719
Train Epoch: 11 [38336/60000 (64%)]	Loss: 33.968376
Train Epoch: 11 [44736/60000 (75%)]	Loss: 34.548656
Train Epoch: 11 [51136/60000 (85%)]	Loss: 34.688068
Train Epoch: 11 [57536/60000 (96%)]	Loss: 38.440891

Test set: Average loss: 34.0235, Accuracy: 1432/10000 (14%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 34.468018
Train Epoch: 12 [12736/60000 (21%)]	Loss: 26.753069
Train Epoch: 12 [19136/60000 (32%)]	Loss: 36.256668
Train Epoch: 12 [25536/60000 (43%)]	Loss: 34.359589
Train Epoch: 12 [31936/60000 (53%)]	Loss: 31.746191
Train Epoch: 12 [38336/60000 (64%)]	Loss: 35.093269
Train Epoch: 12 [44736/60000 (75%)]	Loss: 35.893448
Train Epoch: 12 [51136/60000 (85%)]	Loss: 34.517132
Train Epoch: 12 [57536/60000 (96%)]	Loss: 35.204163

Test set: Average loss: 33.8947, Accuracy: 1434/10000 (14%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 34.096020
Train Epoch: 13 [12736/60000 (21%)]	Loss: 34.939358
Train Epoch: 13 [19136/60000 (32%)]	Loss: 36.206329
Train Epoch: 13 [25536/60000 (43%)]	Loss: 41.015499
Train Epoch: 13 [31936/60000 (53%)]	Loss: 36.915600
Train Epoch: 13 [38336/60000 (64%)]	Loss: 35.726921
Train Epoch: 13 [44736/60000 (75%)]	Loss: 31.012135
Train Epoch: 13 [51136/60000 (85%)]	Loss: 37.084309
Train Epoch: 13 [57536/60000 (96%)]	Loss: 32.015835

Test set: Average loss: 34.0301, Accuracy: 1498/10000 (15%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 33.701389
Train Epoch: 14 [12736/60000 (21%)]	Loss: 31.073175
Train Epoch: 14 [19136/60000 (32%)]	Loss: 33.700191
Train Epoch: 14 [25536/60000 (43%)]	Loss: 28.619953
Train Epoch: 14 [31936/60000 (53%)]	Loss: 35.695671
Train Epoch: 14 [38336/60000 (64%)]	Loss: 29.122967
Train Epoch: 14 [44736/60000 (75%)]	Loss: 35.406181
Train Epoch: 14 [51136/60000 (85%)]	Loss: 32.907543
Train Epoch: 14 [57536/60000 (96%)]	Loss: 37.198120

Test set: Average loss: 32.7502, Accuracy: 1496/10000 (15%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 33.764561
Train Epoch: 15 [12736/60000 (21%)]	Loss: 35.692055
Train Epoch: 15 [19136/60000 (32%)]	Loss: 35.386589
Train Epoch: 15 [25536/60000 (43%)]	Loss: 33.029964
Train Epoch: 15 [31936/60000 (53%)]	Loss: 30.534203
Train Epoch: 15 [38336/60000 (64%)]	Loss: 33.254482
Train Epoch: 15 [44736/60000 (75%)]	Loss: 36.761234
Train Epoch: 15 [51136/60000 (85%)]	Loss: 29.828802
Train Epoch: 15 [57536/60000 (96%)]	Loss: 31.818979

Test set: Average loss: 33.5651, Accuracy: 1433/10000 (14%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=True, wd=0.0005)


Total time spent pruning/training: 3.00 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4451455
