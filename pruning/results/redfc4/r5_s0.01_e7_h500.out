Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=7, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 31.911699
Train Epoch: 1 [12736/60000 (21%)]	Loss: 61.911823
Train Epoch: 1 [19136/60000 (32%)]	Loss: 91.175339
Train Epoch: 1 [25536/60000 (43%)]	Loss: 93.368652
Train Epoch: 1 [31936/60000 (53%)]	Loss: 97.209946
Train Epoch: 1 [38336/60000 (64%)]	Loss: 109.680611
Train Epoch: 1 [44736/60000 (75%)]	Loss: 124.418159
Train Epoch: 1 [51136/60000 (85%)]	Loss: 113.008614
Train Epoch: 1 [57536/60000 (96%)]	Loss: 135.440491

Test set: Average loss: 126.7376, Accuracy: 1154/10000 (12%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 118.823715
Train Epoch: 2 [12736/60000 (21%)]	Loss: 133.554626
Train Epoch: 2 [19136/60000 (32%)]	Loss: 131.617783
Train Epoch: 2 [25536/60000 (43%)]	Loss: 133.791565
Train Epoch: 2 [31936/60000 (53%)]	Loss: 128.823990
Train Epoch: 2 [38336/60000 (64%)]	Loss: 148.566147
Train Epoch: 2 [44736/60000 (75%)]	Loss: 138.513443
Train Epoch: 2 [51136/60000 (85%)]	Loss: 154.029068
Train Epoch: 2 [57536/60000 (96%)]	Loss: 153.235443

Test set: Average loss: 141.8173, Accuracy: 1161/10000 (12%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 125.074699
Train Epoch: 3 [12736/60000 (21%)]	Loss: 145.346451
Train Epoch: 3 [19136/60000 (32%)]	Loss: 161.447357
Train Epoch: 3 [25536/60000 (43%)]	Loss: 156.398224
Train Epoch: 3 [31936/60000 (53%)]	Loss: 146.895752
Train Epoch: 3 [38336/60000 (64%)]	Loss: 138.036270
Train Epoch: 3 [44736/60000 (75%)]	Loss: 136.305954
Train Epoch: 3 [51136/60000 (85%)]	Loss: 142.300751
Train Epoch: 3 [57536/60000 (96%)]	Loss: 142.218567

Test set: Average loss: 149.7568, Accuracy: 1125/10000 (11%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 133.450775
Train Epoch: 4 [12736/60000 (21%)]	Loss: 185.778015
Train Epoch: 4 [19136/60000 (32%)]	Loss: 149.104904
Train Epoch: 4 [25536/60000 (43%)]	Loss: 159.536560
Train Epoch: 4 [31936/60000 (53%)]	Loss: 152.086334
Train Epoch: 4 [38336/60000 (64%)]	Loss: 162.534103
Train Epoch: 4 [44736/60000 (75%)]	Loss: 142.878220
Train Epoch: 4 [51136/60000 (85%)]	Loss: 156.471451
Train Epoch: 4 [57536/60000 (96%)]	Loss: 122.389969

Test set: Average loss: 153.4805, Accuracy: 1077/10000 (11%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 156.666428
Train Epoch: 5 [12736/60000 (21%)]	Loss: 148.985428
Train Epoch: 5 [19136/60000 (32%)]	Loss: 138.738907
Train Epoch: 5 [25536/60000 (43%)]	Loss: 155.051926
Train Epoch: 5 [31936/60000 (53%)]	Loss: 163.374771
Train Epoch: 5 [38336/60000 (64%)]	Loss: 139.261505
Train Epoch: 5 [44736/60000 (75%)]	Loss: 160.260986
Train Epoch: 5 [51136/60000 (85%)]	Loss: 149.456360
Train Epoch: 5 [57536/60000 (96%)]	Loss: 158.621017

Test set: Average loss: 151.5060, Accuracy: 1100/10000 (11%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 143.160278
Train Epoch: 6 [12736/60000 (21%)]	Loss: 134.715820
Train Epoch: 6 [19136/60000 (32%)]	Loss: 168.549484
Train Epoch: 6 [25536/60000 (43%)]	Loss: 148.634064
Train Epoch: 6 [31936/60000 (53%)]	Loss: 175.242767
Train Epoch: 6 [38336/60000 (64%)]	Loss: 148.949524
Train Epoch: 6 [44736/60000 (75%)]	Loss: 149.523865
Train Epoch: 6 [51136/60000 (85%)]	Loss: 161.625916
Train Epoch: 6 [57536/60000 (96%)]	Loss: 166.578415

Test set: Average loss: 152.6617, Accuracy: 1062/10000 (11%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 153.402359
Train Epoch: 7 [12736/60000 (21%)]	Loss: 159.751526
Train Epoch: 7 [19136/60000 (32%)]	Loss: 161.685043
Train Epoch: 7 [25536/60000 (43%)]	Loss: 148.388489
Train Epoch: 7 [31936/60000 (53%)]	Loss: 162.123962
Train Epoch: 7 [38336/60000 (64%)]	Loss: 160.393265
Train Epoch: 7 [44736/60000 (75%)]	Loss: 149.946655
Train Epoch: 7 [51136/60000 (85%)]	Loss: 145.976868
Train Epoch: 7 [57536/60000 (96%)]	Loss: 175.123215

Test set: Average loss: 152.0389, Accuracy: 1088/10000 (11%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=7, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.40 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4451455
