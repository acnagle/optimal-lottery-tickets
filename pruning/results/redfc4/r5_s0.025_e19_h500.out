Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 11.195581
Train Epoch: 1 [12736/60000 (21%)]	Loss: 11.993148
Train Epoch: 1 [19136/60000 (32%)]	Loss: 18.973293
Train Epoch: 1 [25536/60000 (43%)]	Loss: 13.737168
Train Epoch: 1 [31936/60000 (53%)]	Loss: 21.636826
Train Epoch: 1 [38336/60000 (64%)]	Loss: 23.369637
Train Epoch: 1 [44736/60000 (75%)]	Loss: 18.424709
Train Epoch: 1 [51136/60000 (85%)]	Loss: 25.789642
Train Epoch: 1 [57536/60000 (96%)]	Loss: 34.440708

Test set: Average loss: 33.2640, Accuracy: 5096/10000 (51%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 37.085251
Train Epoch: 2 [12736/60000 (21%)]	Loss: 32.644081
Train Epoch: 2 [19136/60000 (32%)]	Loss: 46.298794
Train Epoch: 2 [25536/60000 (43%)]	Loss: 38.146843
Train Epoch: 2 [31936/60000 (53%)]	Loss: 30.247215
Train Epoch: 2 [38336/60000 (64%)]	Loss: 48.019405
Train Epoch: 2 [44736/60000 (75%)]	Loss: 32.271454
Train Epoch: 2 [51136/60000 (85%)]	Loss: 43.791359
Train Epoch: 2 [57536/60000 (96%)]	Loss: 42.557030

Test set: Average loss: 53.9304, Accuracy: 3598/10000 (36%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 54.182434
Train Epoch: 3 [12736/60000 (21%)]	Loss: 51.725052
Train Epoch: 3 [19136/60000 (32%)]	Loss: 48.640194
Train Epoch: 3 [25536/60000 (43%)]	Loss: 54.409267
Train Epoch: 3 [31936/60000 (53%)]	Loss: 44.992947
Train Epoch: 3 [38336/60000 (64%)]	Loss: 44.496120
Train Epoch: 3 [44736/60000 (75%)]	Loss: 57.314335
Train Epoch: 3 [51136/60000 (85%)]	Loss: 49.777485
Train Epoch: 3 [57536/60000 (96%)]	Loss: 53.284225

Test set: Average loss: 52.4312, Accuracy: 3190/10000 (32%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 51.843861
Train Epoch: 4 [12736/60000 (21%)]	Loss: 78.974762
Train Epoch: 4 [19136/60000 (32%)]	Loss: 47.728573
Train Epoch: 4 [25536/60000 (43%)]	Loss: 61.071426
Train Epoch: 4 [31936/60000 (53%)]	Loss: 71.880211
Train Epoch: 4 [38336/60000 (64%)]	Loss: 63.762520
Train Epoch: 4 [44736/60000 (75%)]	Loss: 54.979126
Train Epoch: 4 [51136/60000 (85%)]	Loss: 59.604607
Train Epoch: 4 [57536/60000 (96%)]	Loss: 45.022629

Test set: Average loss: 60.2882, Accuracy: 2963/10000 (30%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 65.381165
Train Epoch: 5 [12736/60000 (21%)]	Loss: 65.551315
Train Epoch: 5 [19136/60000 (32%)]	Loss: 72.344559
Train Epoch: 5 [25536/60000 (43%)]	Loss: 55.258091
Train Epoch: 5 [31936/60000 (53%)]	Loss: 66.667076
Train Epoch: 5 [38336/60000 (64%)]	Loss: 66.874725
Train Epoch: 5 [44736/60000 (75%)]	Loss: 63.976723
Train Epoch: 5 [51136/60000 (85%)]	Loss: 60.359463
Train Epoch: 5 [57536/60000 (96%)]	Loss: 68.301865

Test set: Average loss: 64.0577, Accuracy: 2395/10000 (24%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 62.039543
Train Epoch: 6 [12736/60000 (21%)]	Loss: 59.919186
Train Epoch: 6 [19136/60000 (32%)]	Loss: 71.688034
Train Epoch: 6 [25536/60000 (43%)]	Loss: 71.205879
Train Epoch: 6 [31936/60000 (53%)]	Loss: 83.365288
Train Epoch: 6 [38336/60000 (64%)]	Loss: 58.907639
Train Epoch: 6 [44736/60000 (75%)]	Loss: 72.400360
Train Epoch: 6 [51136/60000 (85%)]	Loss: 63.133499
Train Epoch: 6 [57536/60000 (96%)]	Loss: 74.141411

Test set: Average loss: 68.8619, Accuracy: 2657/10000 (27%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 69.692551
Train Epoch: 7 [12736/60000 (21%)]	Loss: 72.634705
Train Epoch: 7 [19136/60000 (32%)]	Loss: 76.479866
Train Epoch: 7 [25536/60000 (43%)]	Loss: 67.184692
Train Epoch: 7 [31936/60000 (53%)]	Loss: 68.152901
Train Epoch: 7 [38336/60000 (64%)]	Loss: 73.896454
Train Epoch: 7 [44736/60000 (75%)]	Loss: 70.190491
Train Epoch: 7 [51136/60000 (85%)]	Loss: 67.079201
Train Epoch: 7 [57536/60000 (96%)]	Loss: 79.709396

Test set: Average loss: 72.2490, Accuracy: 2394/10000 (24%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 73.910599
Train Epoch: 8 [12736/60000 (21%)]	Loss: 62.115192
Train Epoch: 8 [19136/60000 (32%)]	Loss: 69.253487
Train Epoch: 8 [25536/60000 (43%)]	Loss: 67.841423
Train Epoch: 8 [31936/60000 (53%)]	Loss: 63.496918
Train Epoch: 8 [38336/60000 (64%)]	Loss: 67.428093
Train Epoch: 8 [44736/60000 (75%)]	Loss: 82.271927
Train Epoch: 8 [51136/60000 (85%)]	Loss: 70.579582
Train Epoch: 8 [57536/60000 (96%)]	Loss: 59.193684

Test set: Average loss: 70.9952, Accuracy: 1919/10000 (19%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 62.726578
Train Epoch: 9 [12736/60000 (21%)]	Loss: 67.304756
Train Epoch: 9 [19136/60000 (32%)]	Loss: 76.696312
Train Epoch: 9 [25536/60000 (43%)]	Loss: 68.259346
Train Epoch: 9 [31936/60000 (53%)]	Loss: 57.312855
Train Epoch: 9 [38336/60000 (64%)]	Loss: 80.230202
Train Epoch: 9 [44736/60000 (75%)]	Loss: 67.839096
Train Epoch: 9 [51136/60000 (85%)]	Loss: 69.844910
Train Epoch: 9 [57536/60000 (96%)]	Loss: 71.269516

Test set: Average loss: 72.4684, Accuracy: 2093/10000 (21%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 89.301369
Train Epoch: 10 [12736/60000 (21%)]	Loss: 67.056931
Train Epoch: 10 [19136/60000 (32%)]	Loss: 67.760773
Train Epoch: 10 [25536/60000 (43%)]	Loss: 83.230057
Train Epoch: 10 [31936/60000 (53%)]	Loss: 98.925179
Train Epoch: 10 [38336/60000 (64%)]	Loss: 66.222931
Train Epoch: 10 [44736/60000 (75%)]	Loss: 81.546768
Train Epoch: 10 [51136/60000 (85%)]	Loss: 92.231308
Train Epoch: 10 [57536/60000 (96%)]	Loss: 68.506104

Test set: Average loss: 77.7459, Accuracy: 1748/10000 (17%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 68.717880
Train Epoch: 11 [12736/60000 (21%)]	Loss: 67.373093
Train Epoch: 11 [19136/60000 (32%)]	Loss: 87.244324
Train Epoch: 11 [25536/60000 (43%)]	Loss: 71.489441
Train Epoch: 11 [31936/60000 (53%)]	Loss: 62.835793
Train Epoch: 11 [38336/60000 (64%)]	Loss: 64.868629
Train Epoch: 11 [44736/60000 (75%)]	Loss: 60.126881
Train Epoch: 11 [51136/60000 (85%)]	Loss: 81.808121
Train Epoch: 11 [57536/60000 (96%)]	Loss: 71.418610

Test set: Average loss: 76.7953, Accuracy: 1955/10000 (20%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 79.625885
Train Epoch: 12 [12736/60000 (21%)]	Loss: 88.630325
Train Epoch: 12 [19136/60000 (32%)]	Loss: 98.512726
Train Epoch: 12 [25536/60000 (43%)]	Loss: 84.445488
Train Epoch: 12 [31936/60000 (53%)]	Loss: 69.093529
Train Epoch: 12 [38336/60000 (64%)]	Loss: 66.858086
Train Epoch: 12 [44736/60000 (75%)]	Loss: 74.050240
Train Epoch: 12 [51136/60000 (85%)]	Loss: 87.026367
Train Epoch: 12 [57536/60000 (96%)]	Loss: 72.273155

Test set: Average loss: 72.4616, Accuracy: 2166/10000 (22%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 77.954285
Train Epoch: 13 [12736/60000 (21%)]	Loss: 66.388008
Train Epoch: 13 [19136/60000 (32%)]	Loss: 109.040642
Train Epoch: 13 [25536/60000 (43%)]	Loss: 69.602669
Train Epoch: 13 [31936/60000 (53%)]	Loss: 76.086098
Train Epoch: 13 [38336/60000 (64%)]	Loss: 72.299240
Train Epoch: 13 [44736/60000 (75%)]	Loss: 67.970284
Train Epoch: 13 [51136/60000 (85%)]	Loss: 63.785492
Train Epoch: 13 [57536/60000 (96%)]	Loss: 70.271889

Test set: Average loss: 77.1356, Accuracy: 2287/10000 (23%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 78.885803
Train Epoch: 14 [12736/60000 (21%)]	Loss: 70.167747
Train Epoch: 14 [19136/60000 (32%)]	Loss: 83.497345
Train Epoch: 14 [25536/60000 (43%)]	Loss: 72.375923
Train Epoch: 14 [31936/60000 (53%)]	Loss: 81.731354
Train Epoch: 14 [38336/60000 (64%)]	Loss: 66.339363
Train Epoch: 14 [44736/60000 (75%)]	Loss: 71.207565
Train Epoch: 14 [51136/60000 (85%)]	Loss: 83.836807
Train Epoch: 14 [57536/60000 (96%)]	Loss: 72.371346

Test set: Average loss: 76.9158, Accuracy: 2172/10000 (22%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 80.204407
Train Epoch: 15 [12736/60000 (21%)]	Loss: 69.707924
Train Epoch: 15 [19136/60000 (32%)]	Loss: 84.930855
Train Epoch: 15 [25536/60000 (43%)]	Loss: 73.415237
Train Epoch: 15 [31936/60000 (53%)]	Loss: 97.211647
Train Epoch: 15 [38336/60000 (64%)]	Loss: 85.597870
Train Epoch: 15 [44736/60000 (75%)]	Loss: 91.733696
Train Epoch: 15 [51136/60000 (85%)]	Loss: 72.281525
Train Epoch: 15 [57536/60000 (96%)]	Loss: 55.417458

Test set: Average loss: 73.0223, Accuracy: 2446/10000 (24%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 71.399109
Train Epoch: 16 [12736/60000 (21%)]	Loss: 72.646278
Train Epoch: 16 [19136/60000 (32%)]	Loss: 81.783096
Train Epoch: 16 [25536/60000 (43%)]	Loss: 73.206566
Train Epoch: 16 [31936/60000 (53%)]	Loss: 69.260635
Train Epoch: 16 [38336/60000 (64%)]	Loss: 81.384811
Train Epoch: 16 [44736/60000 (75%)]	Loss: 65.304581
Train Epoch: 16 [51136/60000 (85%)]	Loss: 75.925682
Train Epoch: 16 [57536/60000 (96%)]	Loss: 67.354256

Test set: Average loss: 71.3077, Accuracy: 2095/10000 (21%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 86.152710
Train Epoch: 17 [12736/60000 (21%)]	Loss: 66.416000
Train Epoch: 17 [19136/60000 (32%)]	Loss: 85.148781
Train Epoch: 17 [25536/60000 (43%)]	Loss: 68.632889
Train Epoch: 17 [31936/60000 (53%)]	Loss: 74.225899
Train Epoch: 17 [38336/60000 (64%)]	Loss: 82.190659
Train Epoch: 17 [44736/60000 (75%)]	Loss: 68.096535
Train Epoch: 17 [51136/60000 (85%)]	Loss: 64.998955
Train Epoch: 17 [57536/60000 (96%)]	Loss: 93.785820

Test set: Average loss: 73.9175, Accuracy: 2326/10000 (23%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 78.260399
Train Epoch: 18 [12736/60000 (21%)]	Loss: 90.232559
Train Epoch: 18 [19136/60000 (32%)]	Loss: 64.624008
Train Epoch: 18 [25536/60000 (43%)]	Loss: 66.590134
Train Epoch: 18 [31936/60000 (53%)]	Loss: 58.766960
Train Epoch: 18 [38336/60000 (64%)]	Loss: 72.191223
Train Epoch: 18 [44736/60000 (75%)]	Loss: 91.457710
Train Epoch: 18 [51136/60000 (85%)]	Loss: 56.670376
Train Epoch: 18 [57536/60000 (96%)]	Loss: 66.530930

Test set: Average loss: 74.2421, Accuracy: 2072/10000 (21%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 60.586838
Train Epoch: 19 [12736/60000 (21%)]	Loss: 56.751797
Train Epoch: 19 [19136/60000 (32%)]	Loss: 65.310753
Train Epoch: 19 [25536/60000 (43%)]	Loss: 67.589745
Train Epoch: 19 [31936/60000 (53%)]	Loss: 66.061653
Train Epoch: 19 [38336/60000 (64%)]	Loss: 69.855629
Train Epoch: 19 [44736/60000 (75%)]	Loss: 72.857788
Train Epoch: 19 [51136/60000 (85%)]	Loss: 68.898132
Train Epoch: 19 [57536/60000 (96%)]	Loss: 70.695793

Test set: Average loss: 77.4729, Accuracy: 2250/10000 (22%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.77 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4384009
