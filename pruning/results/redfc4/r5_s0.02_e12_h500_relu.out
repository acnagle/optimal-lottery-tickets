Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.904168
Train Epoch: 1 [12736/60000 (21%)]	Loss: 3.295049
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.552685
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.573287
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.663903
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.334898
Train Epoch: 1 [44736/60000 (75%)]	Loss: 4.441846
Train Epoch: 1 [51136/60000 (85%)]	Loss: 3.991321
Train Epoch: 1 [57536/60000 (96%)]	Loss: 3.708132

Test set: Average loss: 4.7151, Accuracy: 5944/10000 (59%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 8.819766
Train Epoch: 2 [12736/60000 (21%)]	Loss: 6.604763
Train Epoch: 2 [19136/60000 (32%)]	Loss: 6.932981
Train Epoch: 2 [25536/60000 (43%)]	Loss: 5.804445
Train Epoch: 2 [31936/60000 (53%)]	Loss: 4.718695
Train Epoch: 2 [38336/60000 (64%)]	Loss: 6.303666
Train Epoch: 2 [44736/60000 (75%)]	Loss: 7.651096
Train Epoch: 2 [51136/60000 (85%)]	Loss: 8.378777
Train Epoch: 2 [57536/60000 (96%)]	Loss: 7.391409

Test set: Average loss: 8.1468, Accuracy: 4635/10000 (46%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 6.824366
Train Epoch: 3 [12736/60000 (21%)]	Loss: 8.015343
Train Epoch: 3 [19136/60000 (32%)]	Loss: 8.019350
Train Epoch: 3 [25536/60000 (43%)]	Loss: 7.062718
Train Epoch: 3 [31936/60000 (53%)]	Loss: 9.261779
Train Epoch: 3 [38336/60000 (64%)]	Loss: 10.587471
Train Epoch: 3 [44736/60000 (75%)]	Loss: 9.496137
Train Epoch: 3 [51136/60000 (85%)]	Loss: 8.382142
Train Epoch: 3 [57536/60000 (96%)]	Loss: 10.761279

Test set: Average loss: 12.0351, Accuracy: 3410/10000 (34%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 11.243097
Train Epoch: 4 [12736/60000 (21%)]	Loss: 14.753280
Train Epoch: 4 [19136/60000 (32%)]	Loss: 13.835694
Train Epoch: 4 [25536/60000 (43%)]	Loss: 15.455432
Train Epoch: 4 [31936/60000 (53%)]	Loss: 15.544985
Train Epoch: 4 [38336/60000 (64%)]	Loss: 11.445009
Train Epoch: 4 [44736/60000 (75%)]	Loss: 16.071438
Train Epoch: 4 [51136/60000 (85%)]	Loss: 14.585103
Train Epoch: 4 [57536/60000 (96%)]	Loss: 10.203504

Test set: Average loss: 15.7028, Accuracy: 2456/10000 (25%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 15.833333
Train Epoch: 5 [12736/60000 (21%)]	Loss: 11.737316
Train Epoch: 5 [19136/60000 (32%)]	Loss: 13.844254
Train Epoch: 5 [25536/60000 (43%)]	Loss: 15.259411
Train Epoch: 5 [31936/60000 (53%)]	Loss: 19.044636
Train Epoch: 5 [38336/60000 (64%)]	Loss: 17.554958
Train Epoch: 5 [44736/60000 (75%)]	Loss: 19.329592
Train Epoch: 5 [51136/60000 (85%)]	Loss: 19.130482
Train Epoch: 5 [57536/60000 (96%)]	Loss: 20.616304

Test set: Average loss: 18.2432, Accuracy: 2213/10000 (22%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 16.404224
Train Epoch: 6 [12736/60000 (21%)]	Loss: 19.017269
Train Epoch: 6 [19136/60000 (32%)]	Loss: 20.590998
Train Epoch: 6 [25536/60000 (43%)]	Loss: 18.346092
Train Epoch: 6 [31936/60000 (53%)]	Loss: 17.104660
Train Epoch: 6 [38336/60000 (64%)]	Loss: 18.415920
Train Epoch: 6 [44736/60000 (75%)]	Loss: 22.027983
Train Epoch: 6 [51136/60000 (85%)]	Loss: 20.900640
Train Epoch: 6 [57536/60000 (96%)]	Loss: 21.499496

Test set: Average loss: 19.6831, Accuracy: 1964/10000 (20%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 18.850428
Train Epoch: 7 [12736/60000 (21%)]	Loss: 16.190109
Train Epoch: 7 [19136/60000 (32%)]	Loss: 18.869778
Train Epoch: 7 [25536/60000 (43%)]	Loss: 19.662092
Train Epoch: 7 [31936/60000 (53%)]	Loss: 22.402052
Train Epoch: 7 [38336/60000 (64%)]	Loss: 20.192680
Train Epoch: 7 [44736/60000 (75%)]	Loss: 20.735796
Train Epoch: 7 [51136/60000 (85%)]	Loss: 20.099966
Train Epoch: 7 [57536/60000 (96%)]	Loss: 21.266666

Test set: Average loss: 19.3410, Accuracy: 1853/10000 (19%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 21.290741
Train Epoch: 8 [12736/60000 (21%)]	Loss: 13.775208
Train Epoch: 8 [19136/60000 (32%)]	Loss: 21.478138
Train Epoch: 8 [25536/60000 (43%)]	Loss: 18.742170
Train Epoch: 8 [31936/60000 (53%)]	Loss: 18.502382
Train Epoch: 8 [38336/60000 (64%)]	Loss: 23.602886
Train Epoch: 8 [44736/60000 (75%)]	Loss: 19.023848
Train Epoch: 8 [51136/60000 (85%)]	Loss: 20.197403
Train Epoch: 8 [57536/60000 (96%)]	Loss: 21.825840

Test set: Average loss: 20.1000, Accuracy: 1951/10000 (20%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 21.963079
Train Epoch: 9 [12736/60000 (21%)]	Loss: 19.043217
Train Epoch: 9 [19136/60000 (32%)]	Loss: 22.021883
Train Epoch: 9 [25536/60000 (43%)]	Loss: 15.150013
Train Epoch: 9 [31936/60000 (53%)]	Loss: 18.555696
Train Epoch: 9 [38336/60000 (64%)]	Loss: 21.225430
Train Epoch: 9 [44736/60000 (75%)]	Loss: 21.245401
Train Epoch: 9 [51136/60000 (85%)]	Loss: 17.060102
Train Epoch: 9 [57536/60000 (96%)]	Loss: 22.539536

Test set: Average loss: 21.0510, Accuracy: 1813/10000 (18%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 22.027542
Train Epoch: 10 [12736/60000 (21%)]	Loss: 19.404980
Train Epoch: 10 [19136/60000 (32%)]	Loss: 21.167223
Train Epoch: 10 [25536/60000 (43%)]	Loss: 16.396563
Train Epoch: 10 [31936/60000 (53%)]	Loss: 22.221039
Train Epoch: 10 [38336/60000 (64%)]	Loss: 21.395855
Train Epoch: 10 [44736/60000 (75%)]	Loss: 22.477760
Train Epoch: 10 [51136/60000 (85%)]	Loss: 21.077675
Train Epoch: 10 [57536/60000 (96%)]	Loss: 19.631660

Test set: Average loss: 20.1307, Accuracy: 1865/10000 (19%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 18.595598
Train Epoch: 11 [12736/60000 (21%)]	Loss: 20.892435
Train Epoch: 11 [19136/60000 (32%)]	Loss: 14.531034
Train Epoch: 11 [25536/60000 (43%)]	Loss: 21.083355
Train Epoch: 11 [31936/60000 (53%)]	Loss: 17.329100
Train Epoch: 11 [38336/60000 (64%)]	Loss: 18.804178
Train Epoch: 11 [44736/60000 (75%)]	Loss: 17.914648
Train Epoch: 11 [51136/60000 (85%)]	Loss: 18.531509
Train Epoch: 11 [57536/60000 (96%)]	Loss: 22.527052

Test set: Average loss: 19.5687, Accuracy: 2012/10000 (20%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 18.623642
Train Epoch: 12 [12736/60000 (21%)]	Loss: 15.446588
Train Epoch: 12 [19136/60000 (32%)]	Loss: 18.710388
Train Epoch: 12 [25536/60000 (43%)]	Loss: 20.965191
Train Epoch: 12 [31936/60000 (53%)]	Loss: 19.033106
Train Epoch: 12 [38336/60000 (64%)]	Loss: 18.636272
Train Epoch: 12 [44736/60000 (75%)]	Loss: 21.714718
Train Epoch: 12 [51136/60000 (85%)]	Loss: 18.961559
Train Epoch: 12 [57536/60000 (96%)]	Loss: 20.359411

Test set: Average loss: 20.1004, Accuracy: 1971/10000 (20%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005)


Total time spent pruning/training: 2.42 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4406491
