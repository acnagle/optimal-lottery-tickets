Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.904168
Train Epoch: 1 [12736/60000 (21%)]	Loss: 3.295049
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.552685
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.573287
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.663903
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.334898
Train Epoch: 1 [44736/60000 (75%)]	Loss: 4.441846
Train Epoch: 1 [51136/60000 (85%)]	Loss: 3.991321
Train Epoch: 1 [57536/60000 (96%)]	Loss: 3.708132

Test set: Average loss: 4.7151, Accuracy: 5944/10000 (59%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 8.193544
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.877265
Train Epoch: 2 [19136/60000 (32%)]	Loss: 5.630192
Train Epoch: 2 [25536/60000 (43%)]	Loss: 3.854267
Train Epoch: 2 [31936/60000 (53%)]	Loss: 3.617236
Train Epoch: 2 [38336/60000 (64%)]	Loss: 5.658109
Train Epoch: 2 [44736/60000 (75%)]	Loss: 6.832699
Train Epoch: 2 [51136/60000 (85%)]	Loss: 8.435730
Train Epoch: 2 [57536/60000 (96%)]	Loss: 5.452314

Test set: Average loss: 9.4685, Accuracy: 4271/10000 (43%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 8.139593
Train Epoch: 3 [12736/60000 (21%)]	Loss: 8.547771
Train Epoch: 3 [19136/60000 (32%)]	Loss: 5.481549
Train Epoch: 3 [25536/60000 (43%)]	Loss: 5.547244
Train Epoch: 3 [31936/60000 (53%)]	Loss: 6.691477
Train Epoch: 3 [38336/60000 (64%)]	Loss: 9.855619
Train Epoch: 3 [44736/60000 (75%)]	Loss: 9.293154
Train Epoch: 3 [51136/60000 (85%)]	Loss: 9.060799
Train Epoch: 3 [57536/60000 (96%)]	Loss: 11.910259

Test set: Average loss: 12.0358, Accuracy: 3452/10000 (35%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 11.409686
Train Epoch: 4 [12736/60000 (21%)]	Loss: 13.787891
Train Epoch: 4 [19136/60000 (32%)]	Loss: 12.926135
Train Epoch: 4 [25536/60000 (43%)]	Loss: 14.401608
Train Epoch: 4 [31936/60000 (53%)]	Loss: 14.843670
Train Epoch: 4 [38336/60000 (64%)]	Loss: 13.203419
Train Epoch: 4 [44736/60000 (75%)]	Loss: 16.626421
Train Epoch: 4 [51136/60000 (85%)]	Loss: 14.824743
Train Epoch: 4 [57536/60000 (96%)]	Loss: 10.289221

Test set: Average loss: 15.8416, Accuracy: 2336/10000 (23%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 17.101505
Train Epoch: 5 [12736/60000 (21%)]	Loss: 13.563359
Train Epoch: 5 [19136/60000 (32%)]	Loss: 14.723516
Train Epoch: 5 [25536/60000 (43%)]	Loss: 16.049168
Train Epoch: 5 [31936/60000 (53%)]	Loss: 18.887053
Train Epoch: 5 [38336/60000 (64%)]	Loss: 17.670258
Train Epoch: 5 [44736/60000 (75%)]	Loss: 18.824749
Train Epoch: 5 [51136/60000 (85%)]	Loss: 18.900841
Train Epoch: 5 [57536/60000 (96%)]	Loss: 21.165606

Test set: Average loss: 18.2424, Accuracy: 2159/10000 (22%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 17.852119
Train Epoch: 6 [12736/60000 (21%)]	Loss: 19.482622
Train Epoch: 6 [19136/60000 (32%)]	Loss: 21.024843
Train Epoch: 6 [25536/60000 (43%)]	Loss: 17.970146
Train Epoch: 6 [31936/60000 (53%)]	Loss: 17.153376
Train Epoch: 6 [38336/60000 (64%)]	Loss: 19.879683
Train Epoch: 6 [44736/60000 (75%)]	Loss: 23.494038
Train Epoch: 6 [51136/60000 (85%)]	Loss: 22.465084
Train Epoch: 6 [57536/60000 (96%)]	Loss: 21.475630

Test set: Average loss: 19.9331, Accuracy: 1895/10000 (19%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 19.634731
Train Epoch: 7 [12736/60000 (21%)]	Loss: 15.653880
Train Epoch: 7 [19136/60000 (32%)]	Loss: 18.663061
Train Epoch: 7 [25536/60000 (43%)]	Loss: 21.836302
Train Epoch: 7 [31936/60000 (53%)]	Loss: 23.689207
Train Epoch: 7 [38336/60000 (64%)]	Loss: 20.427912
Train Epoch: 7 [44736/60000 (75%)]	Loss: 21.570454
Train Epoch: 7 [51136/60000 (85%)]	Loss: 20.441032
Train Epoch: 7 [57536/60000 (96%)]	Loss: 22.098228

Test set: Average loss: 20.4469, Accuracy: 1843/10000 (18%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 23.109217
Train Epoch: 8 [12736/60000 (21%)]	Loss: 14.118123
Train Epoch: 8 [19136/60000 (32%)]	Loss: 22.263264
Train Epoch: 8 [25536/60000 (43%)]	Loss: 18.873734
Train Epoch: 8 [31936/60000 (53%)]	Loss: 19.547663
Train Epoch: 8 [38336/60000 (64%)]	Loss: 24.546789
Train Epoch: 8 [44736/60000 (75%)]	Loss: 21.215836
Train Epoch: 8 [51136/60000 (85%)]	Loss: 22.591583
Train Epoch: 8 [57536/60000 (96%)]	Loss: 22.293079

Test set: Average loss: 21.6035, Accuracy: 1862/10000 (19%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 22.935465
Train Epoch: 9 [12736/60000 (21%)]	Loss: 19.729593
Train Epoch: 9 [19136/60000 (32%)]	Loss: 22.756414
Train Epoch: 9 [25536/60000 (43%)]	Loss: 15.795382
Train Epoch: 9 [31936/60000 (53%)]	Loss: 18.985882
Train Epoch: 9 [38336/60000 (64%)]	Loss: 22.592627
Train Epoch: 9 [44736/60000 (75%)]	Loss: 21.058998
Train Epoch: 9 [51136/60000 (85%)]	Loss: 18.255823
Train Epoch: 9 [57536/60000 (96%)]	Loss: 24.972694

Test set: Average loss: 21.8417, Accuracy: 1743/10000 (17%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 23.014002
Train Epoch: 10 [12736/60000 (21%)]	Loss: 21.018604
Train Epoch: 10 [19136/60000 (32%)]	Loss: 22.023951
Train Epoch: 10 [25536/60000 (43%)]	Loss: 18.212482
Train Epoch: 10 [31936/60000 (53%)]	Loss: 24.442875
Train Epoch: 10 [38336/60000 (64%)]	Loss: 21.643026
Train Epoch: 10 [44736/60000 (75%)]	Loss: 24.105787
Train Epoch: 10 [51136/60000 (85%)]	Loss: 22.382994
Train Epoch: 10 [57536/60000 (96%)]	Loss: 20.896599

Test set: Average loss: 21.1517, Accuracy: 1934/10000 (19%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 18.940258
Train Epoch: 11 [12736/60000 (21%)]	Loss: 22.338213
Train Epoch: 11 [19136/60000 (32%)]	Loss: 17.028755
Train Epoch: 11 [25536/60000 (43%)]	Loss: 20.310339
Train Epoch: 11 [31936/60000 (53%)]	Loss: 18.066307
Train Epoch: 11 [38336/60000 (64%)]	Loss: 20.077925
Train Epoch: 11 [44736/60000 (75%)]	Loss: 20.369480
Train Epoch: 11 [51136/60000 (85%)]	Loss: 20.697281
Train Epoch: 11 [57536/60000 (96%)]	Loss: 22.352028

Test set: Average loss: 21.1976, Accuracy: 1799/10000 (18%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 20.586384
Train Epoch: 12 [12736/60000 (21%)]	Loss: 16.362583
Train Epoch: 12 [19136/60000 (32%)]	Loss: 21.007687
Train Epoch: 12 [25536/60000 (43%)]	Loss: 23.138536
Train Epoch: 12 [31936/60000 (53%)]	Loss: 18.825787
Train Epoch: 12 [38336/60000 (64%)]	Loss: 19.227566
Train Epoch: 12 [44736/60000 (75%)]	Loss: 22.518837
Train Epoch: 12 [51136/60000 (85%)]	Loss: 20.176069
Train Epoch: 12 [57536/60000 (96%)]	Loss: 22.094238

Test set: Average loss: 20.8887, Accuracy: 2002/10000 (20%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 18.282127
Train Epoch: 13 [12736/60000 (21%)]	Loss: 23.464876
Train Epoch: 13 [19136/60000 (32%)]	Loss: 20.957930
Train Epoch: 13 [25536/60000 (43%)]	Loss: 24.903551
Train Epoch: 13 [31936/60000 (53%)]	Loss: 17.685144
Train Epoch: 13 [38336/60000 (64%)]	Loss: 19.253523
Train Epoch: 13 [44736/60000 (75%)]	Loss: 19.581551
Train Epoch: 13 [51136/60000 (85%)]	Loss: 21.785143
Train Epoch: 13 [57536/60000 (96%)]	Loss: 21.586603

Test set: Average loss: 20.0374, Accuracy: 1947/10000 (19%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005)


Total time spent pruning/training: 2.61 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4406491
