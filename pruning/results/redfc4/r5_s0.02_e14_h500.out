Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 7.253252
Train Epoch: 1 [12736/60000 (21%)]	Loss: 25.429331
Train Epoch: 1 [19136/60000 (32%)]	Loss: 34.917747
Train Epoch: 1 [25536/60000 (43%)]	Loss: 38.026100
Train Epoch: 1 [31936/60000 (53%)]	Loss: 29.555229
Train Epoch: 1 [38336/60000 (64%)]	Loss: 27.226795
Train Epoch: 1 [44736/60000 (75%)]	Loss: 33.277142
Train Epoch: 1 [51136/60000 (85%)]	Loss: 45.097240
Train Epoch: 1 [57536/60000 (96%)]	Loss: 48.676105

Test set: Average loss: 47.5576, Accuracy: 3854/10000 (39%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 48.123535
Train Epoch: 2 [12736/60000 (21%)]	Loss: 49.244602
Train Epoch: 2 [19136/60000 (32%)]	Loss: 62.082794
Train Epoch: 2 [25536/60000 (43%)]	Loss: 55.894543
Train Epoch: 2 [31936/60000 (53%)]	Loss: 49.841476
Train Epoch: 2 [38336/60000 (64%)]	Loss: 66.049751
Train Epoch: 2 [44736/60000 (75%)]	Loss: 67.480736
Train Epoch: 2 [51136/60000 (85%)]	Loss: 68.837456
Train Epoch: 2 [57536/60000 (96%)]	Loss: 75.821075

Test set: Average loss: 71.6589, Accuracy: 2158/10000 (22%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 72.627312
Train Epoch: 3 [12736/60000 (21%)]	Loss: 74.811111
Train Epoch: 3 [19136/60000 (32%)]	Loss: 79.438988
Train Epoch: 3 [25536/60000 (43%)]	Loss: 81.598656
Train Epoch: 3 [31936/60000 (53%)]	Loss: 63.488945
Train Epoch: 3 [38336/60000 (64%)]	Loss: 75.920769
Train Epoch: 3 [44736/60000 (75%)]	Loss: 73.153351
Train Epoch: 3 [51136/60000 (85%)]	Loss: 82.046638
Train Epoch: 3 [57536/60000 (96%)]	Loss: 79.079384

Test set: Average loss: 75.0463, Accuracy: 2210/10000 (22%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 72.337593
Train Epoch: 4 [12736/60000 (21%)]	Loss: 119.003387
Train Epoch: 4 [19136/60000 (32%)]	Loss: 73.788185
Train Epoch: 4 [25536/60000 (43%)]	Loss: 93.665878
Train Epoch: 4 [31936/60000 (53%)]	Loss: 90.679550
Train Epoch: 4 [38336/60000 (64%)]	Loss: 91.691795
Train Epoch: 4 [44736/60000 (75%)]	Loss: 77.481232
Train Epoch: 4 [51136/60000 (85%)]	Loss: 88.859390
Train Epoch: 4 [57536/60000 (96%)]	Loss: 69.352623

Test set: Average loss: 82.6463, Accuracy: 2218/10000 (22%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 96.090096
Train Epoch: 5 [12736/60000 (21%)]	Loss: 80.564987
Train Epoch: 5 [19136/60000 (32%)]	Loss: 88.006874
Train Epoch: 5 [25536/60000 (43%)]	Loss: 89.748596
Train Epoch: 5 [31936/60000 (53%)]	Loss: 93.174286
Train Epoch: 5 [38336/60000 (64%)]	Loss: 83.711151
Train Epoch: 5 [44736/60000 (75%)]	Loss: 87.103165
Train Epoch: 5 [51136/60000 (85%)]	Loss: 82.590446
Train Epoch: 5 [57536/60000 (96%)]	Loss: 105.965149

Test set: Average loss: 92.6734, Accuracy: 1852/10000 (19%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 82.792534
Train Epoch: 6 [12736/60000 (21%)]	Loss: 90.098167
Train Epoch: 6 [19136/60000 (32%)]	Loss: 112.941681
Train Epoch: 6 [25536/60000 (43%)]	Loss: 98.862595
Train Epoch: 6 [31936/60000 (53%)]	Loss: 102.175636
Train Epoch: 6 [38336/60000 (64%)]	Loss: 92.507057
Train Epoch: 6 [44736/60000 (75%)]	Loss: 90.670708
Train Epoch: 6 [51136/60000 (85%)]	Loss: 92.033195
Train Epoch: 6 [57536/60000 (96%)]	Loss: 97.907532

Test set: Average loss: 90.3811, Accuracy: 1859/10000 (19%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 96.043144
Train Epoch: 7 [12736/60000 (21%)]	Loss: 90.012352
Train Epoch: 7 [19136/60000 (32%)]	Loss: 106.761345
Train Epoch: 7 [25536/60000 (43%)]	Loss: 77.989220
Train Epoch: 7 [31936/60000 (53%)]	Loss: 101.735855
Train Epoch: 7 [38336/60000 (64%)]	Loss: 100.569023
Train Epoch: 7 [44736/60000 (75%)]	Loss: 93.428474
Train Epoch: 7 [51136/60000 (85%)]	Loss: 93.880302
Train Epoch: 7 [57536/60000 (96%)]	Loss: 106.025421

Test set: Average loss: 89.7799, Accuracy: 1780/10000 (18%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 95.151848
Train Epoch: 8 [12736/60000 (21%)]	Loss: 84.735283
Train Epoch: 8 [19136/60000 (32%)]	Loss: 88.698158
Train Epoch: 8 [25536/60000 (43%)]	Loss: 104.279366
Train Epoch: 8 [31936/60000 (53%)]	Loss: 88.383720
Train Epoch: 8 [38336/60000 (64%)]	Loss: 92.265411
Train Epoch: 8 [44736/60000 (75%)]	Loss: 97.412865
Train Epoch: 8 [51136/60000 (85%)]	Loss: 97.517296
Train Epoch: 8 [57536/60000 (96%)]	Loss: 87.433960

Test set: Average loss: 97.6888, Accuracy: 1610/10000 (16%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 91.369911
Train Epoch: 9 [12736/60000 (21%)]	Loss: 94.123734
Train Epoch: 9 [19136/60000 (32%)]	Loss: 106.121262
Train Epoch: 9 [25536/60000 (43%)]	Loss: 84.837219
Train Epoch: 9 [31936/60000 (53%)]	Loss: 93.117035
Train Epoch: 9 [38336/60000 (64%)]	Loss: 98.049919
Train Epoch: 9 [44736/60000 (75%)]	Loss: 99.311485
Train Epoch: 9 [51136/60000 (85%)]	Loss: 101.022453
Train Epoch: 9 [57536/60000 (96%)]	Loss: 105.027733

Test set: Average loss: 96.9137, Accuracy: 1487/10000 (15%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 98.801331
Train Epoch: 10 [12736/60000 (21%)]	Loss: 101.401550
Train Epoch: 10 [19136/60000 (32%)]	Loss: 93.517563
Train Epoch: 10 [25536/60000 (43%)]	Loss: 103.417351
Train Epoch: 10 [31936/60000 (53%)]	Loss: 124.514412
Train Epoch: 10 [38336/60000 (64%)]	Loss: 89.020264
Train Epoch: 10 [44736/60000 (75%)]	Loss: 93.303993
Train Epoch: 10 [51136/60000 (85%)]	Loss: 114.195610
Train Epoch: 10 [57536/60000 (96%)]	Loss: 93.072929

Test set: Average loss: 89.7661, Accuracy: 1454/10000 (15%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 91.488731
Train Epoch: 11 [12736/60000 (21%)]	Loss: 95.796120
Train Epoch: 11 [19136/60000 (32%)]	Loss: 102.333862
Train Epoch: 11 [25536/60000 (43%)]	Loss: 87.858223
Train Epoch: 11 [31936/60000 (53%)]	Loss: 92.038628
Train Epoch: 11 [38336/60000 (64%)]	Loss: 84.374046
Train Epoch: 11 [44736/60000 (75%)]	Loss: 80.307236
Train Epoch: 11 [51136/60000 (85%)]	Loss: 95.164322
Train Epoch: 11 [57536/60000 (96%)]	Loss: 102.124283

Test set: Average loss: 96.6099, Accuracy: 1466/10000 (15%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 87.920334
Train Epoch: 12 [12736/60000 (21%)]	Loss: 105.541100
Train Epoch: 12 [19136/60000 (32%)]	Loss: 113.790215
Train Epoch: 12 [25536/60000 (43%)]	Loss: 112.093262
Train Epoch: 12 [31936/60000 (53%)]	Loss: 96.448639
Train Epoch: 12 [38336/60000 (64%)]	Loss: 95.522346
Train Epoch: 12 [44736/60000 (75%)]	Loss: 91.325912
Train Epoch: 12 [51136/60000 (85%)]	Loss: 109.184601
Train Epoch: 12 [57536/60000 (96%)]	Loss: 89.359818

Test set: Average loss: 92.2525, Accuracy: 1600/10000 (16%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 103.310875
Train Epoch: 13 [12736/60000 (21%)]	Loss: 92.886360
Train Epoch: 13 [19136/60000 (32%)]	Loss: 129.359467
Train Epoch: 13 [25536/60000 (43%)]	Loss: 98.215324
Train Epoch: 13 [31936/60000 (53%)]	Loss: 108.220268
Train Epoch: 13 [38336/60000 (64%)]	Loss: 94.371796
Train Epoch: 13 [44736/60000 (75%)]	Loss: 96.158043
Train Epoch: 13 [51136/60000 (85%)]	Loss: 78.958008
Train Epoch: 13 [57536/60000 (96%)]	Loss: 94.941460

Test set: Average loss: 97.7932, Accuracy: 1524/10000 (15%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 104.200874
Train Epoch: 14 [12736/60000 (21%)]	Loss: 85.090843
Train Epoch: 14 [19136/60000 (32%)]	Loss: 102.659233
Train Epoch: 14 [25536/60000 (43%)]	Loss: 87.522324
Train Epoch: 14 [31936/60000 (53%)]	Loss: 102.540573
Train Epoch: 14 [38336/60000 (64%)]	Loss: 84.676727
Train Epoch: 14 [44736/60000 (75%)]	Loss: 92.298454
Train Epoch: 14 [51136/60000 (85%)]	Loss: 111.881569
Train Epoch: 14 [57536/60000 (96%)]	Loss: 92.087425

Test set: Average loss: 97.8411, Accuracy: 1653/10000 (17%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.79 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4406491
