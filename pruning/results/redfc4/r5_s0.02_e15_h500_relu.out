Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.904168
Train Epoch: 1 [12736/60000 (21%)]	Loss: 3.295049
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.552685
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.573287
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.663903
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.334898
Train Epoch: 1 [44736/60000 (75%)]	Loss: 4.441846
Train Epoch: 1 [51136/60000 (85%)]	Loss: 3.991321
Train Epoch: 1 [57536/60000 (96%)]	Loss: 3.708132

Test set: Average loss: 4.7151, Accuracy: 5944/10000 (59%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 7.498073
Train Epoch: 2 [12736/60000 (21%)]	Loss: 3.952282
Train Epoch: 2 [19136/60000 (32%)]	Loss: 4.581941
Train Epoch: 2 [25536/60000 (43%)]	Loss: 7.394085
Train Epoch: 2 [31936/60000 (53%)]	Loss: 3.529492
Train Epoch: 2 [38336/60000 (64%)]	Loss: 6.674248
Train Epoch: 2 [44736/60000 (75%)]	Loss: 7.883231
Train Epoch: 2 [51136/60000 (85%)]	Loss: 6.540404
Train Epoch: 2 [57536/60000 (96%)]	Loss: 6.190026

Test set: Average loss: 7.9877, Accuracy: 4947/10000 (49%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 6.836744
Train Epoch: 3 [12736/60000 (21%)]	Loss: 7.822057
Train Epoch: 3 [19136/60000 (32%)]	Loss: 5.870748
Train Epoch: 3 [25536/60000 (43%)]	Loss: 5.773081
Train Epoch: 3 [31936/60000 (53%)]	Loss: 7.989787
Train Epoch: 3 [38336/60000 (64%)]	Loss: 11.234317
Train Epoch: 3 [44736/60000 (75%)]	Loss: 8.202958
Train Epoch: 3 [51136/60000 (85%)]	Loss: 9.417871
Train Epoch: 3 [57536/60000 (96%)]	Loss: 11.818273

Test set: Average loss: 12.8375, Accuracy: 3184/10000 (32%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 10.156390
Train Epoch: 4 [12736/60000 (21%)]	Loss: 14.589701
Train Epoch: 4 [19136/60000 (32%)]	Loss: 13.122883
Train Epoch: 4 [25536/60000 (43%)]	Loss: 15.460114
Train Epoch: 4 [31936/60000 (53%)]	Loss: 14.741323
Train Epoch: 4 [38336/60000 (64%)]	Loss: 13.063379
Train Epoch: 4 [44736/60000 (75%)]	Loss: 16.530310
Train Epoch: 4 [51136/60000 (85%)]	Loss: 14.677975
Train Epoch: 4 [57536/60000 (96%)]	Loss: 10.487487

Test set: Average loss: 15.8839, Accuracy: 2457/10000 (25%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 15.666019
Train Epoch: 5 [12736/60000 (21%)]	Loss: 13.610382
Train Epoch: 5 [19136/60000 (32%)]	Loss: 15.056616
Train Epoch: 5 [25536/60000 (43%)]	Loss: 16.022274
Train Epoch: 5 [31936/60000 (53%)]	Loss: 19.389563
Train Epoch: 5 [38336/60000 (64%)]	Loss: 16.917656
Train Epoch: 5 [44736/60000 (75%)]	Loss: 18.236816
Train Epoch: 5 [51136/60000 (85%)]	Loss: 18.792877
Train Epoch: 5 [57536/60000 (96%)]	Loss: 22.044430

Test set: Average loss: 18.6350, Accuracy: 2132/10000 (21%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 17.152716
Train Epoch: 6 [12736/60000 (21%)]	Loss: 20.190218
Train Epoch: 6 [19136/60000 (32%)]	Loss: 22.388203
Train Epoch: 6 [25536/60000 (43%)]	Loss: 18.388432
Train Epoch: 6 [31936/60000 (53%)]	Loss: 18.480120
Train Epoch: 6 [38336/60000 (64%)]	Loss: 19.217844
Train Epoch: 6 [44736/60000 (75%)]	Loss: 23.365509
Train Epoch: 6 [51136/60000 (85%)]	Loss: 20.661251
Train Epoch: 6 [57536/60000 (96%)]	Loss: 22.171335

Test set: Average loss: 19.9793, Accuracy: 1983/10000 (20%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 20.251453
Train Epoch: 7 [12736/60000 (21%)]	Loss: 15.550135
Train Epoch: 7 [19136/60000 (32%)]	Loss: 19.384222
Train Epoch: 7 [25536/60000 (43%)]	Loss: 21.533295
Train Epoch: 7 [31936/60000 (53%)]	Loss: 23.401785
Train Epoch: 7 [38336/60000 (64%)]	Loss: 20.250614
Train Epoch: 7 [44736/60000 (75%)]	Loss: 22.107395
Train Epoch: 7 [51136/60000 (85%)]	Loss: 20.640970
Train Epoch: 7 [57536/60000 (96%)]	Loss: 22.533882

Test set: Average loss: 21.4719, Accuracy: 1733/10000 (17%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 23.142057
Train Epoch: 8 [12736/60000 (21%)]	Loss: 14.654109
Train Epoch: 8 [19136/60000 (32%)]	Loss: 22.921326
Train Epoch: 8 [25536/60000 (43%)]	Loss: 19.951008
Train Epoch: 8 [31936/60000 (53%)]	Loss: 19.106861
Train Epoch: 8 [38336/60000 (64%)]	Loss: 24.416676
Train Epoch: 8 [44736/60000 (75%)]	Loss: 21.436750
Train Epoch: 8 [51136/60000 (85%)]	Loss: 22.761520
Train Epoch: 8 [57536/60000 (96%)]	Loss: 23.627583

Test set: Average loss: 21.8823, Accuracy: 1896/10000 (19%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 23.136463
Train Epoch: 9 [12736/60000 (21%)]	Loss: 21.236506
Train Epoch: 9 [19136/60000 (32%)]	Loss: 25.136009
Train Epoch: 9 [25536/60000 (43%)]	Loss: 17.217163
Train Epoch: 9 [31936/60000 (53%)]	Loss: 19.502583
Train Epoch: 9 [38336/60000 (64%)]	Loss: 23.381027
Train Epoch: 9 [44736/60000 (75%)]	Loss: 22.881388
Train Epoch: 9 [51136/60000 (85%)]	Loss: 19.219292
Train Epoch: 9 [57536/60000 (96%)]	Loss: 23.962534

Test set: Average loss: 22.9724, Accuracy: 1778/10000 (18%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 23.829306
Train Epoch: 10 [12736/60000 (21%)]	Loss: 21.052145
Train Epoch: 10 [19136/60000 (32%)]	Loss: 23.470854
Train Epoch: 10 [25536/60000 (43%)]	Loss: 19.266148
Train Epoch: 10 [31936/60000 (53%)]	Loss: 24.260986
Train Epoch: 10 [38336/60000 (64%)]	Loss: 20.865919
Train Epoch: 10 [44736/60000 (75%)]	Loss: 25.354908
Train Epoch: 10 [51136/60000 (85%)]	Loss: 23.403391
Train Epoch: 10 [57536/60000 (96%)]	Loss: 21.397614

Test set: Average loss: 22.7912, Accuracy: 1699/10000 (17%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 20.576180
Train Epoch: 11 [12736/60000 (21%)]	Loss: 23.991377
Train Epoch: 11 [19136/60000 (32%)]	Loss: 19.401827
Train Epoch: 11 [25536/60000 (43%)]	Loss: 23.802040
Train Epoch: 11 [31936/60000 (53%)]	Loss: 19.398838
Train Epoch: 11 [38336/60000 (64%)]	Loss: 22.476437
Train Epoch: 11 [44736/60000 (75%)]	Loss: 21.184565
Train Epoch: 11 [51136/60000 (85%)]	Loss: 22.526854
Train Epoch: 11 [57536/60000 (96%)]	Loss: 25.323996

Test set: Average loss: 22.7571, Accuracy: 1867/10000 (19%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 21.927515
Train Epoch: 12 [12736/60000 (21%)]	Loss: 18.483532
Train Epoch: 12 [19136/60000 (32%)]	Loss: 22.891294
Train Epoch: 12 [25536/60000 (43%)]	Loss: 24.781897
Train Epoch: 12 [31936/60000 (53%)]	Loss: 20.908350
Train Epoch: 12 [38336/60000 (64%)]	Loss: 22.310019
Train Epoch: 12 [44736/60000 (75%)]	Loss: 25.042627
Train Epoch: 12 [51136/60000 (85%)]	Loss: 22.872046
Train Epoch: 12 [57536/60000 (96%)]	Loss: 23.278202

Test set: Average loss: 22.6492, Accuracy: 2045/10000 (20%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 21.866116
Train Epoch: 13 [12736/60000 (21%)]	Loss: 24.837385
Train Epoch: 13 [19136/60000 (32%)]	Loss: 24.060843
Train Epoch: 13 [25536/60000 (43%)]	Loss: 26.688412
Train Epoch: 13 [31936/60000 (53%)]	Loss: 22.402256
Train Epoch: 13 [38336/60000 (64%)]	Loss: 22.834888
Train Epoch: 13 [44736/60000 (75%)]	Loss: 21.235287
Train Epoch: 13 [51136/60000 (85%)]	Loss: 23.549706
Train Epoch: 13 [57536/60000 (96%)]	Loss: 21.556870

Test set: Average loss: 22.3288, Accuracy: 1900/10000 (19%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 20.037985
Train Epoch: 14 [12736/60000 (21%)]	Loss: 18.086720
Train Epoch: 14 [19136/60000 (32%)]	Loss: 20.633644
Train Epoch: 14 [25536/60000 (43%)]	Loss: 18.957579
Train Epoch: 14 [31936/60000 (53%)]	Loss: 23.501492
Train Epoch: 14 [38336/60000 (64%)]	Loss: 19.030851
Train Epoch: 14 [44736/60000 (75%)]	Loss: 21.598278
Train Epoch: 14 [51136/60000 (85%)]	Loss: 21.058617
Train Epoch: 14 [57536/60000 (96%)]	Loss: 23.292780

Test set: Average loss: 21.4180, Accuracy: 1846/10000 (18%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 20.678873
Train Epoch: 15 [12736/60000 (21%)]	Loss: 21.978142
Train Epoch: 15 [19136/60000 (32%)]	Loss: 21.160646
Train Epoch: 15 [25536/60000 (43%)]	Loss: 19.918152
Train Epoch: 15 [31936/60000 (53%)]	Loss: 19.829805
Train Epoch: 15 [38336/60000 (64%)]	Loss: 22.507738
Train Epoch: 15 [44736/60000 (75%)]	Loss: 20.730858
Train Epoch: 15 [51136/60000 (85%)]	Loss: 17.911095
Train Epoch: 15 [57536/60000 (96%)]	Loss: 19.835300

Test set: Average loss: 21.4296, Accuracy: 2001/10000 (20%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005)


Total time spent pruning/training: 3.00 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4406491
