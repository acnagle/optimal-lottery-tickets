Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=16, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 7.253252
Train Epoch: 1 [12736/60000 (21%)]	Loss: 25.429331
Train Epoch: 1 [19136/60000 (32%)]	Loss: 34.917747
Train Epoch: 1 [25536/60000 (43%)]	Loss: 38.026100
Train Epoch: 1 [31936/60000 (53%)]	Loss: 29.555229
Train Epoch: 1 [38336/60000 (64%)]	Loss: 27.226795
Train Epoch: 1 [44736/60000 (75%)]	Loss: 33.277142
Train Epoch: 1 [51136/60000 (85%)]	Loss: 45.097240
Train Epoch: 1 [57536/60000 (96%)]	Loss: 48.676105

Test set: Average loss: 47.5576, Accuracy: 3854/10000 (39%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 56.172115
Train Epoch: 2 [12736/60000 (21%)]	Loss: 50.428940
Train Epoch: 2 [19136/60000 (32%)]	Loss: 59.183590
Train Epoch: 2 [25536/60000 (43%)]	Loss: 54.590267
Train Epoch: 2 [31936/60000 (53%)]	Loss: 44.944439
Train Epoch: 2 [38336/60000 (64%)]	Loss: 63.847412
Train Epoch: 2 [44736/60000 (75%)]	Loss: 58.673920
Train Epoch: 2 [51136/60000 (85%)]	Loss: 62.239990
Train Epoch: 2 [57536/60000 (96%)]	Loss: 66.336594

Test set: Average loss: 69.0588, Accuracy: 2200/10000 (22%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 72.669281
Train Epoch: 3 [12736/60000 (21%)]	Loss: 63.712181
Train Epoch: 3 [19136/60000 (32%)]	Loss: 73.254883
Train Epoch: 3 [25536/60000 (43%)]	Loss: 90.709930
Train Epoch: 3 [31936/60000 (53%)]	Loss: 67.645828
Train Epoch: 3 [38336/60000 (64%)]	Loss: 77.795448
Train Epoch: 3 [44736/60000 (75%)]	Loss: 73.002716
Train Epoch: 3 [51136/60000 (85%)]	Loss: 82.414406
Train Epoch: 3 [57536/60000 (96%)]	Loss: 79.832710

Test set: Average loss: 78.2615, Accuracy: 2313/10000 (23%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 69.487152
Train Epoch: 4 [12736/60000 (21%)]	Loss: 107.810776
Train Epoch: 4 [19136/60000 (32%)]	Loss: 74.667938
Train Epoch: 4 [25536/60000 (43%)]	Loss: 92.029411
Train Epoch: 4 [31936/60000 (53%)]	Loss: 95.965187
Train Epoch: 4 [38336/60000 (64%)]	Loss: 91.610718
Train Epoch: 4 [44736/60000 (75%)]	Loss: 82.488625
Train Epoch: 4 [51136/60000 (85%)]	Loss: 95.145218
Train Epoch: 4 [57536/60000 (96%)]	Loss: 69.266335

Test set: Average loss: 82.9951, Accuracy: 2091/10000 (21%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 88.391922
Train Epoch: 5 [12736/60000 (21%)]	Loss: 99.556335
Train Epoch: 5 [19136/60000 (32%)]	Loss: 87.238228
Train Epoch: 5 [25536/60000 (43%)]	Loss: 89.602730
Train Epoch: 5 [31936/60000 (53%)]	Loss: 89.806870
Train Epoch: 5 [38336/60000 (64%)]	Loss: 91.002739
Train Epoch: 5 [44736/60000 (75%)]	Loss: 101.981400
Train Epoch: 5 [51136/60000 (85%)]	Loss: 88.936180
Train Epoch: 5 [57536/60000 (96%)]	Loss: 96.950157

Test set: Average loss: 90.6918, Accuracy: 1664/10000 (17%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 85.563316
Train Epoch: 6 [12736/60000 (21%)]	Loss: 79.670380
Train Epoch: 6 [19136/60000 (32%)]	Loss: 99.614380
Train Epoch: 6 [25536/60000 (43%)]	Loss: 100.296913
Train Epoch: 6 [31936/60000 (53%)]	Loss: 112.553085
Train Epoch: 6 [38336/60000 (64%)]	Loss: 92.303581
Train Epoch: 6 [44736/60000 (75%)]	Loss: 92.613609
Train Epoch: 6 [51136/60000 (85%)]	Loss: 88.956741
Train Epoch: 6 [57536/60000 (96%)]	Loss: 88.516075

Test set: Average loss: 88.5988, Accuracy: 1924/10000 (19%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 94.106659
Train Epoch: 7 [12736/60000 (21%)]	Loss: 95.458618
Train Epoch: 7 [19136/60000 (32%)]	Loss: 107.245651
Train Epoch: 7 [25536/60000 (43%)]	Loss: 85.950653
Train Epoch: 7 [31936/60000 (53%)]	Loss: 94.883087
Train Epoch: 7 [38336/60000 (64%)]	Loss: 105.500534
Train Epoch: 7 [44736/60000 (75%)]	Loss: 85.653404
Train Epoch: 7 [51136/60000 (85%)]	Loss: 87.844208
Train Epoch: 7 [57536/60000 (96%)]	Loss: 107.620712

Test set: Average loss: 95.8851, Accuracy: 1598/10000 (16%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 95.718887
Train Epoch: 8 [12736/60000 (21%)]	Loss: 80.366684
Train Epoch: 8 [19136/60000 (32%)]	Loss: 94.765602
Train Epoch: 8 [25536/60000 (43%)]	Loss: 93.748283
Train Epoch: 8 [31936/60000 (53%)]	Loss: 86.901085
Train Epoch: 8 [38336/60000 (64%)]	Loss: 92.839348
Train Epoch: 8 [44736/60000 (75%)]	Loss: 94.287292
Train Epoch: 8 [51136/60000 (85%)]	Loss: 93.681831
Train Epoch: 8 [57536/60000 (96%)]	Loss: 85.346870

Test set: Average loss: 96.6548, Accuracy: 1568/10000 (16%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 90.394615
Train Epoch: 9 [12736/60000 (21%)]	Loss: 94.857552
Train Epoch: 9 [19136/60000 (32%)]	Loss: 107.744438
Train Epoch: 9 [25536/60000 (43%)]	Loss: 86.382149
Train Epoch: 9 [31936/60000 (53%)]	Loss: 95.871613
Train Epoch: 9 [38336/60000 (64%)]	Loss: 95.575623
Train Epoch: 9 [44736/60000 (75%)]	Loss: 95.423576
Train Epoch: 9 [51136/60000 (85%)]	Loss: 97.177116
Train Epoch: 9 [57536/60000 (96%)]	Loss: 96.248863

Test set: Average loss: 96.8528, Accuracy: 1399/10000 (14%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 96.432358
Train Epoch: 10 [12736/60000 (21%)]	Loss: 94.855507
Train Epoch: 10 [19136/60000 (32%)]	Loss: 97.307693
Train Epoch: 10 [25536/60000 (43%)]	Loss: 101.784622
Train Epoch: 10 [31936/60000 (53%)]	Loss: 128.651428
Train Epoch: 10 [38336/60000 (64%)]	Loss: 93.881775
Train Epoch: 10 [44736/60000 (75%)]	Loss: 92.310486
Train Epoch: 10 [51136/60000 (85%)]	Loss: 110.993546
Train Epoch: 10 [57536/60000 (96%)]	Loss: 93.239365

Test set: Average loss: 95.8355, Accuracy: 1699/10000 (17%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 95.739265
Train Epoch: 11 [12736/60000 (21%)]	Loss: 95.797699
Train Epoch: 11 [19136/60000 (32%)]	Loss: 105.309525
Train Epoch: 11 [25536/60000 (43%)]	Loss: 84.410210
Train Epoch: 11 [31936/60000 (53%)]	Loss: 93.193497
Train Epoch: 11 [38336/60000 (64%)]	Loss: 85.089760
Train Epoch: 11 [44736/60000 (75%)]	Loss: 89.668907
Train Epoch: 11 [51136/60000 (85%)]	Loss: 94.906219
Train Epoch: 11 [57536/60000 (96%)]	Loss: 99.590790

Test set: Average loss: 99.4349, Accuracy: 1482/10000 (15%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 93.712013
Train Epoch: 12 [12736/60000 (21%)]	Loss: 107.651932
Train Epoch: 12 [19136/60000 (32%)]	Loss: 122.564766
Train Epoch: 12 [25536/60000 (43%)]	Loss: 101.920967
Train Epoch: 12 [31936/60000 (53%)]	Loss: 90.690735
Train Epoch: 12 [38336/60000 (64%)]	Loss: 102.872726
Train Epoch: 12 [44736/60000 (75%)]	Loss: 90.208511
Train Epoch: 12 [51136/60000 (85%)]	Loss: 113.237953
Train Epoch: 12 [57536/60000 (96%)]	Loss: 98.273285

Test set: Average loss: 95.5846, Accuracy: 1614/10000 (16%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 102.783051
Train Epoch: 13 [12736/60000 (21%)]	Loss: 89.604919
Train Epoch: 13 [19136/60000 (32%)]	Loss: 138.810944
Train Epoch: 13 [25536/60000 (43%)]	Loss: 82.892677
Train Epoch: 13 [31936/60000 (53%)]	Loss: 107.393600
Train Epoch: 13 [38336/60000 (64%)]	Loss: 95.536911
Train Epoch: 13 [44736/60000 (75%)]	Loss: 95.767586
Train Epoch: 13 [51136/60000 (85%)]	Loss: 81.422501
Train Epoch: 13 [57536/60000 (96%)]	Loss: 93.038315

Test set: Average loss: 100.5132, Accuracy: 1545/10000 (15%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 110.584084
Train Epoch: 14 [12736/60000 (21%)]	Loss: 86.469513
Train Epoch: 14 [19136/60000 (32%)]	Loss: 114.126617
Train Epoch: 14 [25536/60000 (43%)]	Loss: 96.241570
Train Epoch: 14 [31936/60000 (53%)]	Loss: 108.427872
Train Epoch: 14 [38336/60000 (64%)]	Loss: 84.406586
Train Epoch: 14 [44736/60000 (75%)]	Loss: 89.030441
Train Epoch: 14 [51136/60000 (85%)]	Loss: 105.434258
Train Epoch: 14 [57536/60000 (96%)]	Loss: 95.587845

Test set: Average loss: 100.2847, Accuracy: 1678/10000 (17%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 100.085716
Train Epoch: 15 [12736/60000 (21%)]	Loss: 88.215691
Train Epoch: 15 [19136/60000 (32%)]	Loss: 104.035919
Train Epoch: 15 [25536/60000 (43%)]	Loss: 98.195656
Train Epoch: 15 [31936/60000 (53%)]	Loss: 118.938049
Train Epoch: 15 [38336/60000 (64%)]	Loss: 109.142464
Train Epoch: 15 [44736/60000 (75%)]	Loss: 118.394073
Train Epoch: 15 [51136/60000 (85%)]	Loss: 92.253265
Train Epoch: 15 [57536/60000 (96%)]	Loss: 77.706757

Test set: Average loss: 99.6566, Accuracy: 1709/10000 (17%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 90.220184
Train Epoch: 16 [12736/60000 (21%)]	Loss: 94.670456
Train Epoch: 16 [19136/60000 (32%)]	Loss: 112.846031
Train Epoch: 16 [25536/60000 (43%)]	Loss: 103.819305
Train Epoch: 16 [31936/60000 (53%)]	Loss: 99.492073
Train Epoch: 16 [38336/60000 (64%)]	Loss: 100.326118
Train Epoch: 16 [44736/60000 (75%)]	Loss: 85.414856
Train Epoch: 16 [51136/60000 (85%)]	Loss: 97.592003
Train Epoch: 16 [57536/60000 (96%)]	Loss: 89.930244

Test set: Average loss: 95.9312, Accuracy: 1609/10000 (16%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=16, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.18 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4406491
