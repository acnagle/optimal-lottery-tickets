Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.904168
Train Epoch: 1 [12736/60000 (21%)]	Loss: 3.295049
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.552685
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.573287
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.663903
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.334898
Train Epoch: 1 [44736/60000 (75%)]	Loss: 4.441846
Train Epoch: 1 [51136/60000 (85%)]	Loss: 3.991321
Train Epoch: 1 [57536/60000 (96%)]	Loss: 3.708132

Test set: Average loss: 4.7151, Accuracy: 5944/10000 (59%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 8.656765
Train Epoch: 2 [12736/60000 (21%)]	Loss: 3.623158
Train Epoch: 2 [19136/60000 (32%)]	Loss: 4.904076
Train Epoch: 2 [25536/60000 (43%)]	Loss: 4.460390
Train Epoch: 2 [31936/60000 (53%)]	Loss: 4.203327
Train Epoch: 2 [38336/60000 (64%)]	Loss: 8.066242
Train Epoch: 2 [44736/60000 (75%)]	Loss: 7.530194
Train Epoch: 2 [51136/60000 (85%)]	Loss: 6.604313
Train Epoch: 2 [57536/60000 (96%)]	Loss: 4.710775

Test set: Average loss: 7.8925, Accuracy: 4889/10000 (49%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 8.058053
Train Epoch: 3 [12736/60000 (21%)]	Loss: 9.006749
Train Epoch: 3 [19136/60000 (32%)]	Loss: 5.254945
Train Epoch: 3 [25536/60000 (43%)]	Loss: 6.113322
Train Epoch: 3 [31936/60000 (53%)]	Loss: 7.022909
Train Epoch: 3 [38336/60000 (64%)]	Loss: 10.808659
Train Epoch: 3 [44736/60000 (75%)]	Loss: 10.832449
Train Epoch: 3 [51136/60000 (85%)]	Loss: 9.042326
Train Epoch: 3 [57536/60000 (96%)]	Loss: 11.566889

Test set: Average loss: 12.2992, Accuracy: 3124/10000 (31%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 11.569924
Train Epoch: 4 [12736/60000 (21%)]	Loss: 15.326077
Train Epoch: 4 [19136/60000 (32%)]	Loss: 13.188766
Train Epoch: 4 [25536/60000 (43%)]	Loss: 15.956616
Train Epoch: 4 [31936/60000 (53%)]	Loss: 14.765923
Train Epoch: 4 [38336/60000 (64%)]	Loss: 13.523464
Train Epoch: 4 [44736/60000 (75%)]	Loss: 16.513023
Train Epoch: 4 [51136/60000 (85%)]	Loss: 14.857431
Train Epoch: 4 [57536/60000 (96%)]	Loss: 11.042168

Test set: Average loss: 16.1733, Accuracy: 2505/10000 (25%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 16.955400
Train Epoch: 5 [12736/60000 (21%)]	Loss: 13.903662
Train Epoch: 5 [19136/60000 (32%)]	Loss: 14.495015
Train Epoch: 5 [25536/60000 (43%)]	Loss: 15.247830
Train Epoch: 5 [31936/60000 (53%)]	Loss: 18.975233
Train Epoch: 5 [38336/60000 (64%)]	Loss: 18.558519
Train Epoch: 5 [44736/60000 (75%)]	Loss: 18.960281
Train Epoch: 5 [51136/60000 (85%)]	Loss: 18.684193
Train Epoch: 5 [57536/60000 (96%)]	Loss: 22.245768

Test set: Average loss: 18.8665, Accuracy: 1993/10000 (20%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 17.066051
Train Epoch: 6 [12736/60000 (21%)]	Loss: 20.721510
Train Epoch: 6 [19136/60000 (32%)]	Loss: 21.741301
Train Epoch: 6 [25536/60000 (43%)]	Loss: 19.078806
Train Epoch: 6 [31936/60000 (53%)]	Loss: 17.875957
Train Epoch: 6 [38336/60000 (64%)]	Loss: 19.534542
Train Epoch: 6 [44736/60000 (75%)]	Loss: 23.882723
Train Epoch: 6 [51136/60000 (85%)]	Loss: 21.560179
Train Epoch: 6 [57536/60000 (96%)]	Loss: 23.182760

Test set: Average loss: 20.6845, Accuracy: 2061/10000 (21%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 20.377344
Train Epoch: 7 [12736/60000 (21%)]	Loss: 16.771502
Train Epoch: 7 [19136/60000 (32%)]	Loss: 19.846918
Train Epoch: 7 [25536/60000 (43%)]	Loss: 21.766525
Train Epoch: 7 [31936/60000 (53%)]	Loss: 23.561398
Train Epoch: 7 [38336/60000 (64%)]	Loss: 21.218636
Train Epoch: 7 [44736/60000 (75%)]	Loss: 21.871460
Train Epoch: 7 [51136/60000 (85%)]	Loss: 20.646515
Train Epoch: 7 [57536/60000 (96%)]	Loss: 22.812349

Test set: Average loss: 21.9296, Accuracy: 1759/10000 (18%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 23.573400
Train Epoch: 8 [12736/60000 (21%)]	Loss: 15.351814
Train Epoch: 8 [19136/60000 (32%)]	Loss: 23.841562
Train Epoch: 8 [25536/60000 (43%)]	Loss: 20.192888
Train Epoch: 8 [31936/60000 (53%)]	Loss: 19.994173
Train Epoch: 8 [38336/60000 (64%)]	Loss: 25.064154
Train Epoch: 8 [44736/60000 (75%)]	Loss: 22.005898
Train Epoch: 8 [51136/60000 (85%)]	Loss: 23.363657
Train Epoch: 8 [57536/60000 (96%)]	Loss: 23.321203

Test set: Average loss: 22.7221, Accuracy: 1785/10000 (18%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 24.157639
Train Epoch: 9 [12736/60000 (21%)]	Loss: 21.233467
Train Epoch: 9 [19136/60000 (32%)]	Loss: 24.730984
Train Epoch: 9 [25536/60000 (43%)]	Loss: 17.912374
Train Epoch: 9 [31936/60000 (53%)]	Loss: 20.462313
Train Epoch: 9 [38336/60000 (64%)]	Loss: 23.689013
Train Epoch: 9 [44736/60000 (75%)]	Loss: 22.205610
Train Epoch: 9 [51136/60000 (85%)]	Loss: 19.338448
Train Epoch: 9 [57536/60000 (96%)]	Loss: 25.226288

Test set: Average loss: 23.5690, Accuracy: 1704/10000 (17%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 25.188858
Train Epoch: 10 [12736/60000 (21%)]	Loss: 22.931948
Train Epoch: 10 [19136/60000 (32%)]	Loss: 24.189873
Train Epoch: 10 [25536/60000 (43%)]	Loss: 20.465498
Train Epoch: 10 [31936/60000 (53%)]	Loss: 26.258123
Train Epoch: 10 [38336/60000 (64%)]	Loss: 24.671856
Train Epoch: 10 [44736/60000 (75%)]	Loss: 26.913651
Train Epoch: 10 [51136/60000 (85%)]	Loss: 24.616108
Train Epoch: 10 [57536/60000 (96%)]	Loss: 23.123507

Test set: Average loss: 23.6941, Accuracy: 1690/10000 (17%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 22.981150
Train Epoch: 11 [12736/60000 (21%)]	Loss: 25.264772
Train Epoch: 11 [19136/60000 (32%)]	Loss: 20.147236
Train Epoch: 11 [25536/60000 (43%)]	Loss: 24.086967
Train Epoch: 11 [31936/60000 (53%)]	Loss: 20.710810
Train Epoch: 11 [38336/60000 (64%)]	Loss: 24.157852
Train Epoch: 11 [44736/60000 (75%)]	Loss: 22.435205
Train Epoch: 11 [51136/60000 (85%)]	Loss: 23.807425
Train Epoch: 11 [57536/60000 (96%)]	Loss: 28.037460

Test set: Average loss: 24.1048, Accuracy: 1738/10000 (17%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 23.964878
Train Epoch: 12 [12736/60000 (21%)]	Loss: 19.477167
Train Epoch: 12 [19136/60000 (32%)]	Loss: 23.911385
Train Epoch: 12 [25536/60000 (43%)]	Loss: 27.064268
Train Epoch: 12 [31936/60000 (53%)]	Loss: 22.099627
Train Epoch: 12 [38336/60000 (64%)]	Loss: 23.773693
Train Epoch: 12 [44736/60000 (75%)]	Loss: 25.350477
Train Epoch: 12 [51136/60000 (85%)]	Loss: 24.181726
Train Epoch: 12 [57536/60000 (96%)]	Loss: 24.227139

Test set: Average loss: 23.7092, Accuracy: 1716/10000 (17%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 23.325560
Train Epoch: 13 [12736/60000 (21%)]	Loss: 24.889910
Train Epoch: 13 [19136/60000 (32%)]	Loss: 26.337448
Train Epoch: 13 [25536/60000 (43%)]	Loss: 28.237255
Train Epoch: 13 [31936/60000 (53%)]	Loss: 24.763258
Train Epoch: 13 [38336/60000 (64%)]	Loss: 25.429819
Train Epoch: 13 [44736/60000 (75%)]	Loss: 22.395519
Train Epoch: 13 [51136/60000 (85%)]	Loss: 24.880152
Train Epoch: 13 [57536/60000 (96%)]	Loss: 23.262281

Test set: Average loss: 24.1578, Accuracy: 1764/10000 (18%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 22.754871
Train Epoch: 14 [12736/60000 (21%)]	Loss: 21.661816
Train Epoch: 14 [19136/60000 (32%)]	Loss: 23.239805
Train Epoch: 14 [25536/60000 (43%)]	Loss: 19.548346
Train Epoch: 14 [31936/60000 (53%)]	Loss: 23.976618
Train Epoch: 14 [38336/60000 (64%)]	Loss: 20.567656
Train Epoch: 14 [44736/60000 (75%)]	Loss: 24.654896
Train Epoch: 14 [51136/60000 (85%)]	Loss: 23.421768
Train Epoch: 14 [57536/60000 (96%)]	Loss: 24.431425

Test set: Average loss: 23.4337, Accuracy: 1748/10000 (17%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 24.424335
Train Epoch: 15 [12736/60000 (21%)]	Loss: 24.669594
Train Epoch: 15 [19136/60000 (32%)]	Loss: 24.432018
Train Epoch: 15 [25536/60000 (43%)]	Loss: 20.920799
Train Epoch: 15 [31936/60000 (53%)]	Loss: 21.601509
Train Epoch: 15 [38336/60000 (64%)]	Loss: 22.868452
Train Epoch: 15 [44736/60000 (75%)]	Loss: 22.389809
Train Epoch: 15 [51136/60000 (85%)]	Loss: 18.868238
Train Epoch: 15 [57536/60000 (96%)]	Loss: 21.479736

Test set: Average loss: 22.7367, Accuracy: 1893/10000 (19%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 22.554909
Train Epoch: 16 [12736/60000 (21%)]	Loss: 17.338102
Train Epoch: 16 [19136/60000 (32%)]	Loss: 20.947855
Train Epoch: 16 [25536/60000 (43%)]	Loss: 19.219170
Train Epoch: 16 [31936/60000 (53%)]	Loss: 23.444736
Train Epoch: 16 [38336/60000 (64%)]	Loss: 21.259373
Train Epoch: 16 [44736/60000 (75%)]	Loss: 25.112537
Train Epoch: 16 [51136/60000 (85%)]	Loss: 22.453234
Train Epoch: 16 [57536/60000 (96%)]	Loss: 19.566380

Test set: Average loss: 21.5866, Accuracy: 1808/10000 (18%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 23.580406
Train Epoch: 17 [12736/60000 (21%)]	Loss: 19.895355
Train Epoch: 17 [19136/60000 (32%)]	Loss: 16.978703
Train Epoch: 17 [25536/60000 (43%)]	Loss: 22.129223
Train Epoch: 17 [31936/60000 (53%)]	Loss: 18.166466
Train Epoch: 17 [38336/60000 (64%)]	Loss: 22.327810
Train Epoch: 17 [44736/60000 (75%)]	Loss: 23.661167
Train Epoch: 17 [51136/60000 (85%)]	Loss: 21.557703
Train Epoch: 17 [57536/60000 (96%)]	Loss: 22.606258

Test set: Average loss: 21.2958, Accuracy: 1740/10000 (17%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005)


Total time spent pruning/training: 3.39 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4406491
