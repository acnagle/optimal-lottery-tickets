Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 7.931054
Train Epoch: 1 [12736/60000 (21%)]	Loss: 4.265900
Train Epoch: 1 [19136/60000 (32%)]	Loss: 4.155206
Train Epoch: 1 [25536/60000 (43%)]	Loss: 3.430566
Train Epoch: 1 [31936/60000 (53%)]	Loss: 7.702818
Train Epoch: 1 [38336/60000 (64%)]	Loss: 6.903853
Train Epoch: 1 [44736/60000 (75%)]	Loss: 7.440998
Train Epoch: 1 [51136/60000 (85%)]	Loss: 8.445874
Train Epoch: 1 [57536/60000 (96%)]	Loss: 7.460360

Test set: Average loss: 9.1489, Accuracy: 7426/10000 (74%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 18.578342
Train Epoch: 2 [12736/60000 (21%)]	Loss: 7.838633
Train Epoch: 2 [19136/60000 (32%)]	Loss: 13.775181
Train Epoch: 2 [25536/60000 (43%)]	Loss: 12.308616
Train Epoch: 2 [31936/60000 (53%)]	Loss: 12.566097
Train Epoch: 2 [38336/60000 (64%)]	Loss: 19.617292
Train Epoch: 2 [44736/60000 (75%)]	Loss: 15.241932
Train Epoch: 2 [51136/60000 (85%)]	Loss: 13.542486
Train Epoch: 2 [57536/60000 (96%)]	Loss: 12.975111

Test set: Average loss: 12.7236, Accuracy: 7013/10000 (70%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 12.741647
Train Epoch: 3 [12736/60000 (21%)]	Loss: 14.447889
Train Epoch: 3 [19136/60000 (32%)]	Loss: 9.021352
Train Epoch: 3 [25536/60000 (43%)]	Loss: 16.231117
Train Epoch: 3 [31936/60000 (53%)]	Loss: 10.940636
Train Epoch: 3 [38336/60000 (64%)]	Loss: 15.146843
Train Epoch: 3 [44736/60000 (75%)]	Loss: 13.590031
Train Epoch: 3 [51136/60000 (85%)]	Loss: 11.396770
Train Epoch: 3 [57536/60000 (96%)]	Loss: 15.644441

Test set: Average loss: 19.6535, Accuracy: 6554/10000 (66%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 16.655188
Train Epoch: 4 [12736/60000 (21%)]	Loss: 28.297134
Train Epoch: 4 [19136/60000 (32%)]	Loss: 16.798510
Train Epoch: 4 [25536/60000 (43%)]	Loss: 22.337030
Train Epoch: 4 [31936/60000 (53%)]	Loss: 24.397726
Train Epoch: 4 [38336/60000 (64%)]	Loss: 16.321714
Train Epoch: 4 [44736/60000 (75%)]	Loss: 10.995480
Train Epoch: 4 [51136/60000 (85%)]	Loss: 25.820232
Train Epoch: 4 [57536/60000 (96%)]	Loss: 15.995928

Test set: Average loss: 20.6084, Accuracy: 6271/10000 (63%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 19.440401
Train Epoch: 5 [12736/60000 (21%)]	Loss: 12.792259
Train Epoch: 5 [19136/60000 (32%)]	Loss: 28.284496
Train Epoch: 5 [25536/60000 (43%)]	Loss: 20.100494
Train Epoch: 5 [31936/60000 (53%)]	Loss: 22.826365
Train Epoch: 5 [38336/60000 (64%)]	Loss: 31.009365
Train Epoch: 5 [44736/60000 (75%)]	Loss: 15.603639
Train Epoch: 5 [51136/60000 (85%)]	Loss: 12.462785
Train Epoch: 5 [57536/60000 (96%)]	Loss: 23.022223

Test set: Average loss: 22.3103, Accuracy: 5837/10000 (58%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 24.194674
Train Epoch: 6 [12736/60000 (21%)]	Loss: 22.069691
Train Epoch: 6 [19136/60000 (32%)]	Loss: 35.391815
Train Epoch: 6 [25536/60000 (43%)]	Loss: 31.652428
Train Epoch: 6 [31936/60000 (53%)]	Loss: 26.045782
Train Epoch: 6 [38336/60000 (64%)]	Loss: 38.891705
Train Epoch: 6 [44736/60000 (75%)]	Loss: 31.252136
Train Epoch: 6 [51136/60000 (85%)]	Loss: 25.660667
Train Epoch: 6 [57536/60000 (96%)]	Loss: 35.338673

Test set: Average loss: 27.7951, Accuracy: 5629/10000 (56%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 36.741371
Train Epoch: 7 [12736/60000 (21%)]	Loss: 23.745028
Train Epoch: 7 [19136/60000 (32%)]	Loss: 25.897533
Train Epoch: 7 [25536/60000 (43%)]	Loss: 31.538935
Train Epoch: 7 [31936/60000 (53%)]	Loss: 25.414087
Train Epoch: 7 [38336/60000 (64%)]	Loss: 21.182360
Train Epoch: 7 [44736/60000 (75%)]	Loss: 28.122803
Train Epoch: 7 [51136/60000 (85%)]	Loss: 22.938557
Train Epoch: 7 [57536/60000 (96%)]	Loss: 26.287039

Test set: Average loss: 25.7365, Accuracy: 5414/10000 (54%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 22.795334
Train Epoch: 8 [12736/60000 (21%)]	Loss: 17.312298
Train Epoch: 8 [19136/60000 (32%)]	Loss: 20.288860
Train Epoch: 8 [25536/60000 (43%)]	Loss: 21.276283
Train Epoch: 8 [31936/60000 (53%)]	Loss: 24.290236
Train Epoch: 8 [38336/60000 (64%)]	Loss: 27.355145
Train Epoch: 8 [44736/60000 (75%)]	Loss: 33.958561
Train Epoch: 8 [51136/60000 (85%)]	Loss: 21.760773
Train Epoch: 8 [57536/60000 (96%)]	Loss: 27.647675

Test set: Average loss: 24.8275, Accuracy: 5408/10000 (54%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 23.576813
Train Epoch: 9 [12736/60000 (21%)]	Loss: 23.639423
Train Epoch: 9 [19136/60000 (32%)]	Loss: 25.030611
Train Epoch: 9 [25536/60000 (43%)]	Loss: 26.032095
Train Epoch: 9 [31936/60000 (53%)]	Loss: 19.286161
Train Epoch: 9 [38336/60000 (64%)]	Loss: 28.894117
Train Epoch: 9 [44736/60000 (75%)]	Loss: 27.496853
Train Epoch: 9 [51136/60000 (85%)]	Loss: 26.839901
Train Epoch: 9 [57536/60000 (96%)]	Loss: 28.211132

Test set: Average loss: 26.2142, Accuracy: 5151/10000 (52%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 21.969431
Train Epoch: 10 [12736/60000 (21%)]	Loss: 25.130106
Train Epoch: 10 [19136/60000 (32%)]	Loss: 22.239714
Train Epoch: 10 [25536/60000 (43%)]	Loss: 35.326355
Train Epoch: 10 [31936/60000 (53%)]	Loss: 34.468452
Train Epoch: 10 [38336/60000 (64%)]	Loss: 35.127594
Train Epoch: 10 [44736/60000 (75%)]	Loss: 23.991238
Train Epoch: 10 [51136/60000 (85%)]	Loss: 36.358959
Train Epoch: 10 [57536/60000 (96%)]	Loss: 20.638330

Test set: Average loss: 27.8351, Accuracy: 5308/10000 (53%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 25.812950
Train Epoch: 11 [12736/60000 (21%)]	Loss: 30.389530
Train Epoch: 11 [19136/60000 (32%)]	Loss: 39.393414
Train Epoch: 11 [25536/60000 (43%)]	Loss: 37.840191
Train Epoch: 11 [31936/60000 (53%)]	Loss: 26.563587
Train Epoch: 11 [38336/60000 (64%)]	Loss: 26.387487
Train Epoch: 11 [44736/60000 (75%)]	Loss: 21.479193
Train Epoch: 11 [51136/60000 (85%)]	Loss: 24.534084
Train Epoch: 11 [57536/60000 (96%)]	Loss: 18.693218

Test set: Average loss: 28.5188, Accuracy: 5429/10000 (54%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 29.393084
Train Epoch: 12 [12736/60000 (21%)]	Loss: 34.374924
Train Epoch: 12 [19136/60000 (32%)]	Loss: 27.992260
Train Epoch: 12 [25536/60000 (43%)]	Loss: 36.259499
Train Epoch: 12 [31936/60000 (53%)]	Loss: 25.733381
Train Epoch: 12 [38336/60000 (64%)]	Loss: 18.484661
Train Epoch: 12 [44736/60000 (75%)]	Loss: 25.390081
Train Epoch: 12 [51136/60000 (85%)]	Loss: 28.858244
Train Epoch: 12 [57536/60000 (96%)]	Loss: 25.915718

Test set: Average loss: 23.8659, Accuracy: 5758/10000 (58%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 29.856548
Train Epoch: 13 [12736/60000 (21%)]	Loss: 11.837568
Train Epoch: 13 [19136/60000 (32%)]	Loss: 40.938267
Train Epoch: 13 [25536/60000 (43%)]	Loss: 19.344883
Train Epoch: 13 [31936/60000 (53%)]	Loss: 19.814909
Train Epoch: 13 [38336/60000 (64%)]	Loss: 22.530445
Train Epoch: 13 [44736/60000 (75%)]	Loss: 23.390333
Train Epoch: 13 [51136/60000 (85%)]	Loss: 19.157166
Train Epoch: 13 [57536/60000 (96%)]	Loss: 24.992443

Test set: Average loss: 25.4121, Accuracy: 5634/10000 (56%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 19.507410
Train Epoch: 14 [12736/60000 (21%)]	Loss: 30.630287
Train Epoch: 14 [19136/60000 (32%)]	Loss: 21.767506
Train Epoch: 14 [25536/60000 (43%)]	Loss: 19.733173
Train Epoch: 14 [31936/60000 (53%)]	Loss: 22.683298
Train Epoch: 14 [38336/60000 (64%)]	Loss: 15.607433
Train Epoch: 14 [44736/60000 (75%)]	Loss: 19.533148
Train Epoch: 14 [51136/60000 (85%)]	Loss: 21.028437
Train Epoch: 14 [57536/60000 (96%)]	Loss: 18.942818

Test set: Average loss: 33.9173, Accuracy: 5431/10000 (54%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 13.307945
Train Epoch: 15 [12736/60000 (21%)]	Loss: 21.934994
Train Epoch: 15 [19136/60000 (32%)]	Loss: 14.655161
Train Epoch: 15 [25536/60000 (43%)]	Loss: 24.031229
Train Epoch: 15 [31936/60000 (53%)]	Loss: 24.672853
Train Epoch: 15 [38336/60000 (64%)]	Loss: 38.108185
Train Epoch: 15 [44736/60000 (75%)]	Loss: 23.253176
Train Epoch: 15 [51136/60000 (85%)]	Loss: 20.779600
Train Epoch: 15 [57536/60000 (96%)]	Loss: 16.975973

Test set: Average loss: 19.9377, Accuracy: 6460/10000 (65%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.97 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4271599
