Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.513897
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.426654
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.389319
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.504161
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.208077
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.357248
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.254479
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.572163
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.447524

Test set: Average loss: 0.3221, Accuracy: 8920/10000 (89%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.478222
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.241083
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.294936
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.118318
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.273862
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.534187
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.270970
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.220522
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.165983

Test set: Average loss: 0.2507, Accuracy: 9237/10000 (92%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.355950
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.173681
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.035698
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.211043
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.281498
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.198188
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.631797
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.136997
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.270067

Test set: Average loss: 0.2921, Accuracy: 9052/10000 (91%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.407556
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.335011
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.465889
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.332113
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.377057
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.188641
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.401797
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.273966
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.236517

Test set: Average loss: 0.3343, Accuracy: 8912/10000 (89%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.550178
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.208544
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.535432
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.146434
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.420873
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.505345
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.193839
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.189137
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.294216

Test set: Average loss: 0.4185, Accuracy: 8659/10000 (87%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.237834
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.275731
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.528362
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.452685
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.525269
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.201390
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.305816
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.299952
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.270576

Test set: Average loss: 0.4146, Accuracy: 8598/10000 (86%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.440318
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.408493
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.406558
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.340121
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.295896
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.421794
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.309143
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.359163
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.400298

Test set: Average loss: 0.3855, Accuracy: 8727/10000 (87%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.156625
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.300845
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.387969
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.397983
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.438764
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.376533
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.265090
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.285079
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.171821

Test set: Average loss: 0.4262, Accuracy: 8633/10000 (86%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.371204
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.545346
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.397873
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.536044
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.183313
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.435716
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.372049
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.343990
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.324160

Test set: Average loss: 0.3864, Accuracy: 8727/10000 (87%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.483626
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.342600
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.249236
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.538329
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.222916
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.222742
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.324894
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.480077
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.543075

Test set: Average loss: 0.4040, Accuracy: 8717/10000 (87%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.300257
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.156340
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.248238
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.337240
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.521566
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.146829
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.353500
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.249028
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.267530

Test set: Average loss: 0.3649, Accuracy: 8825/10000 (88%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.218386
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.366631
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.222980
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.327376
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.479862
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.231974
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.317048
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.104559
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.422441

Test set: Average loss: 0.3655, Accuracy: 8817/10000 (88%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.110456
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.390358
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.212649
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.147548
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.168789
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.218481
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.200905
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.229736
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.440367

Test set: Average loss: 0.2443, Accuracy: 9242/10000 (92%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.171662
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.236323
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.178912
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.197267
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.211044
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.158145
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.219846
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.095161
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.126141

Test set: Average loss: 0.1804, Accuracy: 9442/10000 (94%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.066425
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.131303
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.109255
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.193193
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.060768
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.229552
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.054940
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.090178
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.186989

Test set: Average loss: 0.1428, Accuracy: 9556/10000 (96%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=True, wd=0.0005)


Total time spent pruning/training: 3.01 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4046778
