Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.25, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.947687
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.479536
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.393960
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.431756
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.251921
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.333686
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.134160
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.586530
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.438262

Test set: Average loss: 0.2589, Accuracy: 9247/10000 (92%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.452780
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.156763
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.278518
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.204558
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.237686
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.386703
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.191174
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.347230
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.280908

Test set: Average loss: 0.2613, Accuracy: 9208/10000 (92%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.173284
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.180922
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.024274
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.241267
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.149944
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.436472
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.372675
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.138936
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.202047

Test set: Average loss: 0.3158, Accuracy: 9014/10000 (90%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.313775
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.386753
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.587417
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.451344
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.358322
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.577670
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.311641
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.301307
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.112966

Test set: Average loss: 0.3735, Accuracy: 8887/10000 (89%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.674275
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.160094
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.461783
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.135080
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.407860
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.373561
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.327875
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.257925
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.489452

Test set: Average loss: 0.4669, Accuracy: 8601/10000 (86%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.254846
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.357793
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.350942
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.372271
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.520193
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.284159
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.426671
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.375561
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.525786

Test set: Average loss: 0.4249, Accuracy: 8828/10000 (88%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.206394
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.279582
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.345051
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.590295
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.393550
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.299802
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.324886
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.440274
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.393548

Test set: Average loss: 0.2942, Accuracy: 9089/10000 (91%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.110480
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.267509
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.277011
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.218073
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.264147
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.375056
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.309134
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.355852
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.175496

Test set: Average loss: 0.4515, Accuracy: 8841/10000 (88%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.137982
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.392423
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.438736
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.633516
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.272045
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.493349
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.311316
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.144197
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.237152

Test set: Average loss: 0.3034, Accuracy: 9193/10000 (92%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.173190
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.153601
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.125918
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.606111
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.193660
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.068089
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.256117
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.282215
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.357831

Test set: Average loss: 0.1983, Accuracy: 9429/10000 (94%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.071717
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.110223
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.153263
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.191861
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.360917
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.138419
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.351466
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.126194
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.043441

Test set: Average loss: 0.1839, Accuracy: 9442/10000 (94%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.136626
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.065427
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.103784
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.072518
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.192966
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.124009
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.151918
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.043296
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.230154

Test set: Average loss: 0.1590, Accuracy: 9519/10000 (95%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.046574
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.128524
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.044066
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.030869
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.064930
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.067841
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.019146
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.059141
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.109301

Test set: Average loss: 0.0926, Accuracy: 9718/10000 (97%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.044140
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.026106
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.051458
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.024647
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.066733
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.045577
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.048711
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.016669
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.025242

Test set: Average loss: 0.0821, Accuracy: 9765/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.25, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.81 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 3372315
