Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.25, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.947687
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.479536
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.393960
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.431756
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.251921
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.333686
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.134160
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.586530
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.438262

Test set: Average loss: 0.2589, Accuracy: 9247/10000 (92%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.269796
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.134085
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.297701
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.108483
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.186345
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.288259
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.189425
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.226691
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.382549

Test set: Average loss: 0.2869, Accuracy: 9165/10000 (92%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.448507
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.105910
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.085708
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.344032
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.115300
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.211849
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.251837
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.232546
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.280658

Test set: Average loss: 0.2823, Accuracy: 9132/10000 (91%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.293921
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.217226
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.424723
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.656247
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.353870
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.473824
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.274973
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.120521
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.182393

Test set: Average loss: 0.3896, Accuracy: 8799/10000 (88%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.515358
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.152355
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.275591
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.150908
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.219572
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.356391
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.398139
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.229209
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.313566

Test set: Average loss: 0.4320, Accuracy: 8766/10000 (88%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.427103
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.324585
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.494323
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.366990
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.630227
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.399994
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.279745
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.343529
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.398679

Test set: Average loss: 0.3275, Accuracy: 9078/10000 (91%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.191765
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.379207
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.403863
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.761600
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.167556
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.308307
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.325218
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.940222
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.376327

Test set: Average loss: 0.4027, Accuracy: 8786/10000 (88%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.326663
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.151660
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.235818
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.311840
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.170383
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.456815
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.229015
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.199749
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.180555

Test set: Average loss: 0.3349, Accuracy: 9024/10000 (90%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.222632
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.458521
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.381322
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.384522
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.355541
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.498227
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.672853
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.165041
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.260106

Test set: Average loss: 0.3577, Accuracy: 8977/10000 (90%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.116928
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.154533
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.218986
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.487791
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.244303
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.222243
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.229797
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.314879
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.268801

Test set: Average loss: 0.2536, Accuracy: 9231/10000 (92%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.230218
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.097880
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.168698
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.253852
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.429029
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.117133
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.236519
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.123745
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.186289

Test set: Average loss: 0.2301, Accuracy: 9364/10000 (94%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.331534
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.202873
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.231027
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.057692
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.581607
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.152599
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.397632
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.069533
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.459122

Test set: Average loss: 0.2241, Accuracy: 9346/10000 (93%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.060986
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.290888
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.073851
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.068215
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.089042
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.070604
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.043728
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.008887
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.141331

Test set: Average loss: 0.1398, Accuracy: 9606/10000 (96%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.134024
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.091814
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.156946
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.110294
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.039323
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.054157
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.174149
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.021329
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.038589

Test set: Average loss: 0.0972, Accuracy: 9718/10000 (97%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.012556
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.023916
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.057314
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.022969
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.019275
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.063812
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.016889
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.002635
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.064626

Test set: Average loss: 0.0835, Accuracy: 9770/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.25, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.99 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 3372315
