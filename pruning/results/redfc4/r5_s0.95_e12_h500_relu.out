Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.95, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.302583
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.302449
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.302224
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.302287
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.301998
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.299843
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.300602
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.295126
Train Epoch: 1 [57536/60000 (96%)]	Loss: 2.287957

Test set: Average loss: 2.2887, Accuracy: 1160/10000 (12%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.275890
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.284632
Train Epoch: 2 [19136/60000 (32%)]	Loss: 2.293797
Train Epoch: 2 [25536/60000 (43%)]	Loss: 2.248423
Train Epoch: 2 [31936/60000 (53%)]	Loss: 2.239750
Train Epoch: 2 [38336/60000 (64%)]	Loss: 2.260386
Train Epoch: 2 [44736/60000 (75%)]	Loss: 2.243901
Train Epoch: 2 [51136/60000 (85%)]	Loss: 2.194215
Train Epoch: 2 [57536/60000 (96%)]	Loss: 2.146650

Test set: Average loss: 2.1798, Accuracy: 1698/10000 (17%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 2.121244
Train Epoch: 3 [12736/60000 (21%)]	Loss: 2.039180
Train Epoch: 3 [19136/60000 (32%)]	Loss: 2.099234
Train Epoch: 3 [25536/60000 (43%)]	Loss: 2.043800
Train Epoch: 3 [31936/60000 (53%)]	Loss: 2.039935
Train Epoch: 3 [38336/60000 (64%)]	Loss: 2.057913
Train Epoch: 3 [44736/60000 (75%)]	Loss: 2.033829
Train Epoch: 3 [51136/60000 (85%)]	Loss: 2.018052
Train Epoch: 3 [57536/60000 (96%)]	Loss: 2.005213

Test set: Average loss: 2.0132, Accuracy: 3196/10000 (32%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.982880
Train Epoch: 4 [12736/60000 (21%)]	Loss: 2.045121
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.965003
Train Epoch: 4 [25536/60000 (43%)]	Loss: 2.010097
Train Epoch: 4 [31936/60000 (53%)]	Loss: 2.008868
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.935939
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.989491
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.962797
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.923822

Test set: Average loss: 1.9592, Accuracy: 3128/10000 (31%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.984282
Train Epoch: 5 [12736/60000 (21%)]	Loss: 2.019938
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.930526
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.913806
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.893831
Train Epoch: 5 [38336/60000 (64%)]	Loss: 2.008278
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.904477
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.918786
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.969204

Test set: Average loss: 1.9377, Accuracy: 3371/10000 (34%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.961908
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.906601
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.919683
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.942391
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.894327
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.993055
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.924167
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.921579
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.944721

Test set: Average loss: 1.9234, Accuracy: 3145/10000 (31%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.907698
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.912803
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.940922
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.904892
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.955758
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.959097
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.877522
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.928133
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.954021

Test set: Average loss: 1.9296, Accuracy: 3360/10000 (34%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.881141
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.974330
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.898439
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.951814
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.884805
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.895586
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.912728
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.954955
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.911905

Test set: Average loss: 1.8989, Accuracy: 3440/10000 (34%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.941666
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.900323
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.892292
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.960048
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.974708
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.921730
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.947882
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.857077
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.954692

Test set: Average loss: 1.9082, Accuracy: 3363/10000 (34%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.858503
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.912131
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.902107
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.948780
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.903762
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.899055
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.966393
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.884247
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.850720

Test set: Average loss: 1.8905, Accuracy: 3861/10000 (39%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.872583
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.834982
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.884539
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.950182
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.930355
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.915756
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.908466
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.808830
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.943815

Test set: Average loss: 1.8864, Accuracy: 3639/10000 (36%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 2.016634
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.912054
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.899431
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.862198
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.855737
Train Epoch: 12 [38336/60000 (64%)]	Loss: 1.864239
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.906939
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.876440
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.875482

Test set: Average loss: 1.8849, Accuracy: 3717/10000 (37%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.95, use_relu=True, wd=0.0005)


Total time spent pruning/training: 2.42 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 224821
