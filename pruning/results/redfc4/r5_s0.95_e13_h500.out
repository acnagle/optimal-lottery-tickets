Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.95, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.298167
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.287295
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.186305
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.034493
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.749243
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.236690
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.036706
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.009497
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.973488

Test set: Average loss: 0.6870, Accuracy: 7873/10000 (79%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.778810
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.383937
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.728218
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.357860
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.399457
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.664598
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.523599
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.529276
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.450411

Test set: Average loss: 0.4118, Accuracy: 8745/10000 (87%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.454887
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.378432
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.190739
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.378346
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.375702
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.261384
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.422083
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.238582
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.329931

Test set: Average loss: 0.4179, Accuracy: 8759/10000 (88%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.305833
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.503543
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.541616
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.535293
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.463541
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.434299
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.485221
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.487631
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.262547

Test set: Average loss: 0.3810, Accuracy: 8821/10000 (88%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.765718
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.332953
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.458577
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.306109
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.612589
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.485601
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.387447
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.421076
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.585225

Test set: Average loss: 0.4414, Accuracy: 8716/10000 (87%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.356757
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.469989
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.449062
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.571322
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.654207
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.316941
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.446119
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.557789
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.448174

Test set: Average loss: 0.3827, Accuracy: 8855/10000 (89%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.287279
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.316953
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.364802
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.438527
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.378773
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.459626
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.418520
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.445858
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.382569

Test set: Average loss: 0.4957, Accuracy: 8499/10000 (85%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.378434
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.335236
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.400892
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.376546
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.394192
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.521319
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.437666
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.314908
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.431114

Test set: Average loss: 0.3650, Accuracy: 8932/10000 (89%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.261768
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.404498
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.445804
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.456822
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.311027
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.527686
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.315386
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.349911
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.413663

Test set: Average loss: 0.4163, Accuracy: 8700/10000 (87%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.286003
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.366436
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.153505
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.424066
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.395848
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.301495
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.496307
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.555388
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.312739

Test set: Average loss: 0.3427, Accuracy: 8974/10000 (90%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.156349
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.194216
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.202708
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.228584
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.520427
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.322586
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.362578
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.301800
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.164888

Test set: Average loss: 0.2820, Accuracy: 9176/10000 (92%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.260616
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.260237
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.222296
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.190681
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.251122
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.183320
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.335285
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.134473
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.415485

Test set: Average loss: 0.2526, Accuracy: 9217/10000 (92%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.157171
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.312902
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.186556
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.189071
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.120272
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.177897
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.136196
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.171596
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.354805

Test set: Average loss: 0.2183, Accuracy: 9333/10000 (93%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.95, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.60 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 224821
