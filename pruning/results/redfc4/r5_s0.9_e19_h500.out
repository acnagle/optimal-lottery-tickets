Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.913958
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.817320
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.377304
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.623030
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.357349
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.364885
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.281615
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.378537
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.531738

Test set: Average loss: 0.3071, Accuracy: 9072/10000 (91%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.299471
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.192645
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.265599
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.212121
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.253986
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.377518
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.259026
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.253672
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.162715

Test set: Average loss: 0.2917, Accuracy: 9064/10000 (91%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.190105
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.188276
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.062809
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.240966
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.145811
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.210255
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.204114
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.138901
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.245821

Test set: Average loss: 0.2063, Accuracy: 9356/10000 (94%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.325341
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.209884
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.271137
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.408853
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.340504
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.315063
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.284009
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.158378
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.201527

Test set: Average loss: 0.2231, Accuracy: 9287/10000 (93%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.478412
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.156831
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.238722
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.182600
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.319285
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.289574
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.193303
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.186295
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.337692

Test set: Average loss: 0.2915, Accuracy: 9078/10000 (91%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.145333
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.206236
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.369316
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.320279
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.535187
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.191125
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.324499
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.332158
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.182638

Test set: Average loss: 0.2530, Accuracy: 9223/10000 (92%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.125830
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.226415
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.214048
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.308631
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.370250
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.383097
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.171043
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.294951
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.286980

Test set: Average loss: 0.3331, Accuracy: 8916/10000 (89%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.153371
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.352819
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.360801
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.204344
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.229407
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.345127
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.286449
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.236105
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.161613

Test set: Average loss: 0.2604, Accuracy: 9176/10000 (92%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.340559
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.342020
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.346663
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.469431
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.337221
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.460659
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.312305
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.226089
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.229472

Test set: Average loss: 0.3161, Accuracy: 9013/10000 (90%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.235828
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.153633
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.215543
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.484743
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.235461
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.268698
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.333279
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.388220
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.232037

Test set: Average loss: 0.3050, Accuracy: 9013/10000 (90%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.295823
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.183274
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.181582
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.259780
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.445716
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.177540
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.288452
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.341854
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.195054

Test set: Average loss: 0.3052, Accuracy: 9081/10000 (91%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.284251
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.234927
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.230488
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.376234
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.419938
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.182485
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.274717
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.214711
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.432230

Test set: Average loss: 0.3156, Accuracy: 8982/10000 (90%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.207892
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.480371
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.271421
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.261274
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.203671
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.219555
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.108886
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.216999
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.295757

Test set: Average loss: 0.2946, Accuracy: 9069/10000 (91%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.162695
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.242726
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.350351
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.340363
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.474538
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.217860
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.347787
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.172095
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.160816

Test set: Average loss: 0.2380, Accuracy: 9258/10000 (93%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.249425
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.176333
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.229942
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.220481
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.309581
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.574410
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.306655
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.195506
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.335067

Test set: Average loss: 0.2098, Accuracy: 9366/10000 (94%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.090643
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.421328
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.256773
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.239041
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.201256
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.103463
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.106533
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.132485
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.144853

Test set: Average loss: 0.1793, Accuracy: 9432/10000 (94%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.129643
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.219686
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.125504
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.264303
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.130355
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.048792
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.078152
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.180267
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.041727

Test set: Average loss: 0.1465, Accuracy: 9522/10000 (95%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.195468
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.107789
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.134318
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.180446
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.074320
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.071941
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.169257
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.133374
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.035557

Test set: Average loss: 0.1253, Accuracy: 9623/10000 (96%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.132387
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.046678
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.187259
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.150602
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.050234
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.080692
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.044998
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.131587
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.017235

Test set: Average loss: 0.1101, Accuracy: 9641/10000 (96%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.77 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 449641
