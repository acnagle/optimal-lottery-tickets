Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.0, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 38.691383
Train Epoch: 1 [12736/60000 (21%)]	Loss: 47.710945
Train Epoch: 1 [19136/60000 (32%)]	Loss: 43.611263
Train Epoch: 1 [25536/60000 (43%)]	Loss: 41.637352
Train Epoch: 1 [31936/60000 (53%)]	Loss: 39.589924
Train Epoch: 1 [38336/60000 (64%)]	Loss: 45.375179
Train Epoch: 1 [44736/60000 (75%)]	Loss: 43.226616
Train Epoch: 1 [51136/60000 (85%)]	Loss: 37.791367
Train Epoch: 1 [57536/60000 (96%)]	Loss: 40.037407

Test set: Average loss: 41.6253, Accuracy: 1340/10000 (13%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 30.151495
Train Epoch: 2 [12736/60000 (21%)]	Loss: 44.133835
Train Epoch: 2 [19136/60000 (32%)]	Loss: 45.287285
Train Epoch: 2 [25536/60000 (43%)]	Loss: 39.701027
Train Epoch: 2 [31936/60000 (53%)]	Loss: 42.230289
Train Epoch: 2 [38336/60000 (64%)]	Loss: 37.854401
Train Epoch: 2 [44736/60000 (75%)]	Loss: 46.130058
Train Epoch: 2 [51136/60000 (85%)]	Loss: 40.037510
Train Epoch: 2 [57536/60000 (96%)]	Loss: 42.865688

Test set: Average loss: 41.5690, Accuracy: 1340/10000 (13%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 32.218151
Train Epoch: 3 [12736/60000 (21%)]	Loss: 37.723251
Train Epoch: 3 [19136/60000 (32%)]	Loss: 37.545769
Train Epoch: 3 [25536/60000 (43%)]	Loss: 38.415375
Train Epoch: 3 [31936/60000 (53%)]	Loss: 41.311199
Train Epoch: 3 [38336/60000 (64%)]	Loss: 46.224094
Train Epoch: 3 [44736/60000 (75%)]	Loss: 39.438995
Train Epoch: 3 [51136/60000 (85%)]	Loss: 32.623119
Train Epoch: 3 [57536/60000 (96%)]	Loss: 39.728981

Test set: Average loss: 41.6480, Accuracy: 1340/10000 (13%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 38.117096
Train Epoch: 4 [12736/60000 (21%)]	Loss: 44.204456
Train Epoch: 4 [19136/60000 (32%)]	Loss: 45.616474
Train Epoch: 4 [25536/60000 (43%)]	Loss: 45.118916
Train Epoch: 4 [31936/60000 (53%)]	Loss: 44.130817
Train Epoch: 4 [38336/60000 (64%)]	Loss: 38.249641
Train Epoch: 4 [44736/60000 (75%)]	Loss: 40.857487
Train Epoch: 4 [51136/60000 (85%)]	Loss: 35.202278
Train Epoch: 4 [57536/60000 (96%)]	Loss: 30.805527

Test set: Average loss: 41.5773, Accuracy: 1340/10000 (13%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 42.207470
Train Epoch: 5 [12736/60000 (21%)]	Loss: 38.744415
Train Epoch: 5 [19136/60000 (32%)]	Loss: 38.280228
Train Epoch: 5 [25536/60000 (43%)]	Loss: 40.385723
Train Epoch: 5 [31936/60000 (53%)]	Loss: 42.233936
Train Epoch: 5 [38336/60000 (64%)]	Loss: 37.202766
Train Epoch: 5 [44736/60000 (75%)]	Loss: 42.943741
Train Epoch: 5 [51136/60000 (85%)]	Loss: 39.723515
Train Epoch: 5 [57536/60000 (96%)]	Loss: 44.337925

Test set: Average loss: 41.6588, Accuracy: 1340/10000 (13%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 40.289455
Train Epoch: 6 [12736/60000 (21%)]	Loss: 43.168259
Train Epoch: 6 [19136/60000 (32%)]	Loss: 45.074673
Train Epoch: 6 [25536/60000 (43%)]	Loss: 36.071583
Train Epoch: 6 [31936/60000 (53%)]	Loss: 42.538395
Train Epoch: 6 [38336/60000 (64%)]	Loss: 37.386185
Train Epoch: 6 [44736/60000 (75%)]	Loss: 46.771503
Train Epoch: 6 [51136/60000 (85%)]	Loss: 45.115723
Train Epoch: 6 [57536/60000 (96%)]	Loss: 46.670910

Test set: Average loss: 41.6051, Accuracy: 1340/10000 (13%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 39.691013
Train Epoch: 7 [12736/60000 (21%)]	Loss: 34.145679
Train Epoch: 7 [19136/60000 (32%)]	Loss: 38.804119
Train Epoch: 7 [25536/60000 (43%)]	Loss: 44.557415
Train Epoch: 7 [31936/60000 (53%)]	Loss: 49.149063
Train Epoch: 7 [38336/60000 (64%)]	Loss: 38.798851
Train Epoch: 7 [44736/60000 (75%)]	Loss: 43.338017
Train Epoch: 7 [51136/60000 (85%)]	Loss: 39.195656
Train Epoch: 7 [57536/60000 (96%)]	Loss: 42.252975

Test set: Average loss: 41.5563, Accuracy: 1340/10000 (13%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 45.701252
Train Epoch: 8 [12736/60000 (21%)]	Loss: 32.689445
Train Epoch: 8 [19136/60000 (32%)]	Loss: 43.249306
Train Epoch: 8 [25536/60000 (43%)]	Loss: 39.543957
Train Epoch: 8 [31936/60000 (53%)]	Loss: 36.735332
Train Epoch: 8 [38336/60000 (64%)]	Loss: 45.479553
Train Epoch: 8 [44736/60000 (75%)]	Loss: 41.141125
Train Epoch: 8 [51136/60000 (85%)]	Loss: 42.413235
Train Epoch: 8 [57536/60000 (96%)]	Loss: 40.028271

Test set: Average loss: 41.6277, Accuracy: 1340/10000 (13%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 42.648685
Train Epoch: 9 [12736/60000 (21%)]	Loss: 40.560318
Train Epoch: 9 [19136/60000 (32%)]	Loss: 46.512337
Train Epoch: 9 [25536/60000 (43%)]	Loss: 35.418667
Train Epoch: 9 [31936/60000 (53%)]	Loss: 37.772678
Train Epoch: 9 [38336/60000 (64%)]	Loss: 42.320972
Train Epoch: 9 [44736/60000 (75%)]	Loss: 38.990665
Train Epoch: 9 [51136/60000 (85%)]	Loss: 37.793594
Train Epoch: 9 [57536/60000 (96%)]	Loss: 46.046917

Test set: Average loss: 41.6441, Accuracy: 1340/10000 (13%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 44.711491
Train Epoch: 10 [12736/60000 (21%)]	Loss: 42.102371
Train Epoch: 10 [19136/60000 (32%)]	Loss: 44.911480
Train Epoch: 10 [25536/60000 (43%)]	Loss: 36.382637
Train Epoch: 10 [31936/60000 (53%)]	Loss: 45.601555
Train Epoch: 10 [38336/60000 (64%)]	Loss: 41.333118
Train Epoch: 10 [44736/60000 (75%)]	Loss: 47.188972
Train Epoch: 10 [51136/60000 (85%)]	Loss: 43.831806
Train Epoch: 10 [57536/60000 (96%)]	Loss: 38.299744

Test set: Average loss: 41.6412, Accuracy: 1340/10000 (13%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 42.983494
Train Epoch: 11 [12736/60000 (21%)]	Loss: 44.843460
Train Epoch: 11 [19136/60000 (32%)]	Loss: 42.490513
Train Epoch: 11 [25536/60000 (43%)]	Loss: 41.448914
Train Epoch: 11 [31936/60000 (53%)]	Loss: 39.176868
Train Epoch: 11 [38336/60000 (64%)]	Loss: 40.185520
Train Epoch: 11 [44736/60000 (75%)]	Loss: 43.545071
Train Epoch: 11 [51136/60000 (85%)]	Loss: 43.020306
Train Epoch: 11 [57536/60000 (96%)]	Loss: 48.686794

Test set: Average loss: 41.6678, Accuracy: 1340/10000 (13%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 41.392262
Train Epoch: 12 [12736/60000 (21%)]	Loss: 34.876820
Train Epoch: 12 [19136/60000 (32%)]	Loss: 43.857307
Train Epoch: 12 [25536/60000 (43%)]	Loss: 41.334377
Train Epoch: 12 [31936/60000 (53%)]	Loss: 39.017361
Train Epoch: 12 [38336/60000 (64%)]	Loss: 43.294979
Train Epoch: 12 [44736/60000 (75%)]	Loss: 43.107330
Train Epoch: 12 [51136/60000 (85%)]	Loss: 42.363270
Train Epoch: 12 [57536/60000 (96%)]	Loss: 40.895039

Test set: Average loss: 41.6078, Accuracy: 1340/10000 (13%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 42.541855
Train Epoch: 13 [12736/60000 (21%)]	Loss: 42.242382
Train Epoch: 13 [19136/60000 (32%)]	Loss: 46.845306
Train Epoch: 13 [25536/60000 (43%)]	Loss: 50.618172
Train Epoch: 13 [31936/60000 (53%)]	Loss: 44.528412
Train Epoch: 13 [38336/60000 (64%)]	Loss: 43.992100
Train Epoch: 13 [44736/60000 (75%)]	Loss: 38.286922
Train Epoch: 13 [51136/60000 (85%)]	Loss: 46.258495
Train Epoch: 13 [57536/60000 (96%)]	Loss: 39.647629

Test set: Average loss: 41.6259, Accuracy: 1340/10000 (13%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 45.617016
Train Epoch: 14 [12736/60000 (21%)]	Loss: 39.627136
Train Epoch: 14 [19136/60000 (32%)]	Loss: 41.547012
Train Epoch: 14 [25536/60000 (43%)]	Loss: 35.440289
Train Epoch: 14 [31936/60000 (53%)]	Loss: 46.463997
Train Epoch: 14 [38336/60000 (64%)]	Loss: 36.157093
Train Epoch: 14 [44736/60000 (75%)]	Loss: 46.432148
Train Epoch: 14 [51136/60000 (85%)]	Loss: 40.761086
Train Epoch: 14 [57536/60000 (96%)]	Loss: 46.193291

Test set: Average loss: 41.5942, Accuracy: 1340/10000 (13%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 41.895184
Train Epoch: 15 [12736/60000 (21%)]	Loss: 42.903091
Train Epoch: 15 [19136/60000 (32%)]	Loss: 44.218533
Train Epoch: 15 [25536/60000 (43%)]	Loss: 43.051075
Train Epoch: 15 [31936/60000 (53%)]	Loss: 42.109432
Train Epoch: 15 [38336/60000 (64%)]	Loss: 39.473541
Train Epoch: 15 [44736/60000 (75%)]	Loss: 46.394569
Train Epoch: 15 [51136/60000 (85%)]	Loss: 37.909367
Train Epoch: 15 [57536/60000 (96%)]	Loss: 40.822708

Test set: Average loss: 41.6280, Accuracy: 1340/10000 (13%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 46.567535
Train Epoch: 16 [12736/60000 (21%)]	Loss: 37.857452
Train Epoch: 16 [19136/60000 (32%)]	Loss: 41.200253
Train Epoch: 16 [25536/60000 (43%)]	Loss: 39.549259
Train Epoch: 16 [31936/60000 (53%)]	Loss: 41.710117
Train Epoch: 16 [38336/60000 (64%)]	Loss: 41.568745
Train Epoch: 16 [44736/60000 (75%)]	Loss: 44.243668
Train Epoch: 16 [51136/60000 (85%)]	Loss: 45.711811
Train Epoch: 16 [57536/60000 (96%)]	Loss: 38.109406

Test set: Average loss: 41.5973, Accuracy: 1340/10000 (13%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 46.810204
Train Epoch: 17 [12736/60000 (21%)]	Loss: 41.435665
Train Epoch: 17 [19136/60000 (32%)]	Loss: 43.156693
Train Epoch: 17 [25536/60000 (43%)]	Loss: 42.954357
Train Epoch: 17 [31936/60000 (53%)]	Loss: 45.643391
Train Epoch: 17 [38336/60000 (64%)]	Loss: 44.141899
Train Epoch: 17 [44736/60000 (75%)]	Loss: 44.611576
Train Epoch: 17 [51136/60000 (85%)]	Loss: 42.604374
Train Epoch: 17 [57536/60000 (96%)]	Loss: 44.531307

Test set: Average loss: 41.6454, Accuracy: 1340/10000 (13%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.0, use_relu=True, wd=0.0005)


Total time spent pruning/training: 3.38 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4496420
