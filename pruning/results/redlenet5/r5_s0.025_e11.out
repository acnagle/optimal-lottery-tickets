Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=11, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.989872
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.321030
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.402905
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.442956
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.775225
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.762251
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.573199
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.682401
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.307486

Test set: Average loss: 0.8221, Accuracy: 7502/10000 (75%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.715564
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.901906
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.789593
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.199502
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.783457
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.213282
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.237722
Train Epoch: 2 [51136/60000 (85%)]	Loss: 2.570677
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.394244

Test set: Average loss: 1.7815, Accuracy: 5523/10000 (55%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 2.204285
Train Epoch: 3 [12736/60000 (21%)]	Loss: 2.011317
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.658808
Train Epoch: 3 [25536/60000 (43%)]	Loss: 3.815648
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.519119
Train Epoch: 3 [38336/60000 (64%)]	Loss: 2.999418
Train Epoch: 3 [44736/60000 (75%)]	Loss: 2.311946
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.582492
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.607070

Test set: Average loss: 2.9936, Accuracy: 3916/10000 (39%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 3.151531
Train Epoch: 4 [12736/60000 (21%)]	Loss: 2.731594
Train Epoch: 4 [19136/60000 (32%)]	Loss: 2.722341
Train Epoch: 4 [25536/60000 (43%)]	Loss: 2.390789
Train Epoch: 4 [31936/60000 (53%)]	Loss: 4.187641
Train Epoch: 4 [38336/60000 (64%)]	Loss: 2.527938
Train Epoch: 4 [44736/60000 (75%)]	Loss: 3.185560
Train Epoch: 4 [51136/60000 (85%)]	Loss: 2.720701
Train Epoch: 4 [57536/60000 (96%)]	Loss: 3.785797

Test set: Average loss: 3.1797, Accuracy: 4254/10000 (43%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 3.563577
Train Epoch: 5 [12736/60000 (21%)]	Loss: 3.426993
Train Epoch: 5 [19136/60000 (32%)]	Loss: 3.596391
Train Epoch: 5 [25536/60000 (43%)]	Loss: 2.487031
Train Epoch: 5 [31936/60000 (53%)]	Loss: 3.200731
Train Epoch: 5 [38336/60000 (64%)]	Loss: 3.879357
Train Epoch: 5 [44736/60000 (75%)]	Loss: 3.770582
Train Epoch: 5 [51136/60000 (85%)]	Loss: 3.593599
Train Epoch: 5 [57536/60000 (96%)]	Loss: 4.005146

Test set: Average loss: 4.0501, Accuracy: 3757/10000 (38%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 3.840322
Train Epoch: 6 [12736/60000 (21%)]	Loss: 3.728055
Train Epoch: 6 [19136/60000 (32%)]	Loss: 4.296055
Train Epoch: 6 [25536/60000 (43%)]	Loss: 4.215394
Train Epoch: 6 [31936/60000 (53%)]	Loss: 3.849622
Train Epoch: 6 [38336/60000 (64%)]	Loss: 3.816560
Train Epoch: 6 [44736/60000 (75%)]	Loss: 4.648007
Train Epoch: 6 [51136/60000 (85%)]	Loss: 5.715985
Train Epoch: 6 [57536/60000 (96%)]	Loss: 4.790885

Test set: Average loss: 4.6444, Accuracy: 3807/10000 (38%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 4.605018
Train Epoch: 7 [12736/60000 (21%)]	Loss: 5.175494
Train Epoch: 7 [19136/60000 (32%)]	Loss: 4.059628
Train Epoch: 7 [25536/60000 (43%)]	Loss: 5.026306
Train Epoch: 7 [31936/60000 (53%)]	Loss: 5.311595
Train Epoch: 7 [38336/60000 (64%)]	Loss: 5.317371
Train Epoch: 7 [44736/60000 (75%)]	Loss: 6.326024
Train Epoch: 7 [51136/60000 (85%)]	Loss: 6.094058
Train Epoch: 7 [57536/60000 (96%)]	Loss: 4.691663

Test set: Average loss: 6.2013, Accuracy: 2526/10000 (25%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 7.480152
Train Epoch: 8 [12736/60000 (21%)]	Loss: 4.010343
Train Epoch: 8 [19136/60000 (32%)]	Loss: 4.586006
Train Epoch: 8 [25536/60000 (43%)]	Loss: 5.501211
Train Epoch: 8 [31936/60000 (53%)]	Loss: 5.777504
Train Epoch: 8 [38336/60000 (64%)]	Loss: 5.593366
Train Epoch: 8 [44736/60000 (75%)]	Loss: 4.487014
Train Epoch: 8 [51136/60000 (85%)]	Loss: 4.784186
Train Epoch: 8 [57536/60000 (96%)]	Loss: 5.107746

Test set: Average loss: 5.5016, Accuracy: 2735/10000 (27%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 4.422853
Train Epoch: 9 [12736/60000 (21%)]	Loss: 5.718688
Train Epoch: 9 [19136/60000 (32%)]	Loss: 5.007164
Train Epoch: 9 [25536/60000 (43%)]	Loss: 6.078659
Train Epoch: 9 [31936/60000 (53%)]	Loss: 5.100798
Train Epoch: 9 [38336/60000 (64%)]	Loss: 7.477763
Train Epoch: 9 [44736/60000 (75%)]	Loss: 6.103911
Train Epoch: 9 [51136/60000 (85%)]	Loss: 5.127413
Train Epoch: 9 [57536/60000 (96%)]	Loss: 5.274638

Test set: Average loss: 5.2762, Accuracy: 2839/10000 (28%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 4.568899
Train Epoch: 10 [12736/60000 (21%)]	Loss: 4.501196
Train Epoch: 10 [19136/60000 (32%)]	Loss: 5.274358
Train Epoch: 10 [25536/60000 (43%)]	Loss: 6.604257
Train Epoch: 10 [31936/60000 (53%)]	Loss: 5.922788
Train Epoch: 10 [38336/60000 (64%)]	Loss: 5.912802
Train Epoch: 10 [44736/60000 (75%)]	Loss: 4.995214
Train Epoch: 10 [51136/60000 (85%)]	Loss: 4.782094
Train Epoch: 10 [57536/60000 (96%)]	Loss: 6.208038

Test set: Average loss: 5.6386, Accuracy: 2637/10000 (26%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 4.775970
Train Epoch: 11 [12736/60000 (21%)]	Loss: 5.001044
Train Epoch: 11 [19136/60000 (32%)]	Loss: 5.780189
Train Epoch: 11 [25536/60000 (43%)]	Loss: 4.253605
Train Epoch: 11 [31936/60000 (53%)]	Loss: 5.575314
Train Epoch: 11 [38336/60000 (64%)]	Loss: 4.152186
Train Epoch: 11 [44736/60000 (75%)]	Loss: 5.898227
Train Epoch: 11 [51136/60000 (85%)]	Loss: 4.882740
Train Epoch: 11 [57536/60000 (96%)]	Loss: 5.124075

Test set: Average loss: 5.1964, Accuracy: 2990/10000 (30%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=11, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.20 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 292730
