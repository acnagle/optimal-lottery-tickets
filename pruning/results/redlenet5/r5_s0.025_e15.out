Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=15, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.989872
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.321030
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.402905
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.442956
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.775225
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.762251
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.573199
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.682401
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.307486

Test set: Average loss: 0.8221, Accuracy: 7502/10000 (75%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.868228
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.892588
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.552985
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.314653
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.129502
Train Epoch: 2 [38336/60000 (64%)]	Loss: 2.418658
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.690579
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.751385
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.509697

Test set: Average loss: 1.4016, Accuracy: 6258/10000 (63%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 2.184955
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.647098
Train Epoch: 3 [19136/60000 (32%)]	Loss: 2.348986
Train Epoch: 3 [25536/60000 (43%)]	Loss: 2.401411
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.467870
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.987875
Train Epoch: 3 [44736/60000 (75%)]	Loss: 3.352053
Train Epoch: 3 [51136/60000 (85%)]	Loss: 2.206362
Train Epoch: 3 [57536/60000 (96%)]	Loss: 2.398069

Test set: Average loss: 2.0460, Accuracy: 5154/10000 (52%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 2.861881
Train Epoch: 4 [12736/60000 (21%)]	Loss: 3.135544
Train Epoch: 4 [19136/60000 (32%)]	Loss: 2.880599
Train Epoch: 4 [25536/60000 (43%)]	Loss: 2.189463
Train Epoch: 4 [31936/60000 (53%)]	Loss: 3.980824
Train Epoch: 4 [38336/60000 (64%)]	Loss: 2.511613
Train Epoch: 4 [44736/60000 (75%)]	Loss: 2.846437
Train Epoch: 4 [51136/60000 (85%)]	Loss: 2.933277
Train Epoch: 4 [57536/60000 (96%)]	Loss: 3.591594

Test set: Average loss: 3.2531, Accuracy: 4079/10000 (41%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 2.698624
Train Epoch: 5 [12736/60000 (21%)]	Loss: 4.492651
Train Epoch: 5 [19136/60000 (32%)]	Loss: 2.825160
Train Epoch: 5 [25536/60000 (43%)]	Loss: 2.929470
Train Epoch: 5 [31936/60000 (53%)]	Loss: 4.135563
Train Epoch: 5 [38336/60000 (64%)]	Loss: 4.678625
Train Epoch: 5 [44736/60000 (75%)]	Loss: 3.387567
Train Epoch: 5 [51136/60000 (85%)]	Loss: 3.944987
Train Epoch: 5 [57536/60000 (96%)]	Loss: 4.625906

Test set: Average loss: 4.7100, Accuracy: 3444/10000 (34%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 3.835934
Train Epoch: 6 [12736/60000 (21%)]	Loss: 5.008676
Train Epoch: 6 [19136/60000 (32%)]	Loss: 4.623665
Train Epoch: 6 [25536/60000 (43%)]	Loss: 5.956290
Train Epoch: 6 [31936/60000 (53%)]	Loss: 4.527020
Train Epoch: 6 [38336/60000 (64%)]	Loss: 4.802151
Train Epoch: 6 [44736/60000 (75%)]	Loss: 5.075916
Train Epoch: 6 [51136/60000 (85%)]	Loss: 6.135822
Train Epoch: 6 [57536/60000 (96%)]	Loss: 5.724462

Test set: Average loss: 5.2208, Accuracy: 3232/10000 (32%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 5.699935
Train Epoch: 7 [12736/60000 (21%)]	Loss: 6.190452
Train Epoch: 7 [19136/60000 (32%)]	Loss: 4.750836
Train Epoch: 7 [25536/60000 (43%)]	Loss: 5.247303
Train Epoch: 7 [31936/60000 (53%)]	Loss: 5.643744
Train Epoch: 7 [38336/60000 (64%)]	Loss: 6.913182
Train Epoch: 7 [44736/60000 (75%)]	Loss: 6.688202
Train Epoch: 7 [51136/60000 (85%)]	Loss: 7.663810
Train Epoch: 7 [57536/60000 (96%)]	Loss: 7.085293

Test set: Average loss: 5.5143, Accuracy: 2556/10000 (26%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 5.754167
Train Epoch: 8 [12736/60000 (21%)]	Loss: 3.868494
Train Epoch: 8 [19136/60000 (32%)]	Loss: 4.913083
Train Epoch: 8 [25536/60000 (43%)]	Loss: 5.452403
Train Epoch: 8 [31936/60000 (53%)]	Loss: 6.198654
Train Epoch: 8 [38336/60000 (64%)]	Loss: 6.398876
Train Epoch: 8 [44736/60000 (75%)]	Loss: 5.805662
Train Epoch: 8 [51136/60000 (85%)]	Loss: 7.087906
Train Epoch: 8 [57536/60000 (96%)]	Loss: 6.672540

Test set: Average loss: 6.8279, Accuracy: 2407/10000 (24%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 6.370895
Train Epoch: 9 [12736/60000 (21%)]	Loss: 5.690801
Train Epoch: 9 [19136/60000 (32%)]	Loss: 5.884517
Train Epoch: 9 [25536/60000 (43%)]	Loss: 8.456293
Train Epoch: 9 [31936/60000 (53%)]	Loss: 6.274576
Train Epoch: 9 [38336/60000 (64%)]	Loss: 7.804965
Train Epoch: 9 [44736/60000 (75%)]	Loss: 6.472236
Train Epoch: 9 [51136/60000 (85%)]	Loss: 5.667912
Train Epoch: 9 [57536/60000 (96%)]	Loss: 6.350187

Test set: Average loss: 6.3968, Accuracy: 2390/10000 (24%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 6.041578
Train Epoch: 10 [12736/60000 (21%)]	Loss: 6.126901
Train Epoch: 10 [19136/60000 (32%)]	Loss: 6.626631
Train Epoch: 10 [25536/60000 (43%)]	Loss: 8.478435
Train Epoch: 10 [31936/60000 (53%)]	Loss: 7.624767
Train Epoch: 10 [38336/60000 (64%)]	Loss: 7.223306
Train Epoch: 10 [44736/60000 (75%)]	Loss: 5.871115
Train Epoch: 10 [51136/60000 (85%)]	Loss: 6.500138
Train Epoch: 10 [57536/60000 (96%)]	Loss: 5.829077

Test set: Average loss: 6.6893, Accuracy: 2372/10000 (24%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 6.592003
Train Epoch: 11 [12736/60000 (21%)]	Loss: 6.911191
Train Epoch: 11 [19136/60000 (32%)]	Loss: 5.831538
Train Epoch: 11 [25536/60000 (43%)]	Loss: 6.167889
Train Epoch: 11 [31936/60000 (53%)]	Loss: 8.181008
Train Epoch: 11 [38336/60000 (64%)]	Loss: 6.276675
Train Epoch: 11 [44736/60000 (75%)]	Loss: 7.884166
Train Epoch: 11 [51136/60000 (85%)]	Loss: 5.659859
Train Epoch: 11 [57536/60000 (96%)]	Loss: 6.825481

Test set: Average loss: 6.8424, Accuracy: 2076/10000 (21%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 6.935272
Train Epoch: 12 [12736/60000 (21%)]	Loss: 5.639484
Train Epoch: 12 [19136/60000 (32%)]	Loss: 6.816939
Train Epoch: 12 [25536/60000 (43%)]	Loss: 6.626502
Train Epoch: 12 [31936/60000 (53%)]	Loss: 6.389374
Train Epoch: 12 [38336/60000 (64%)]	Loss: 6.946882
Train Epoch: 12 [44736/60000 (75%)]	Loss: 5.250885
Train Epoch: 12 [51136/60000 (85%)]	Loss: 6.753438
Train Epoch: 12 [57536/60000 (96%)]	Loss: 8.666610

Test set: Average loss: 7.2786, Accuracy: 2240/10000 (22%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 7.864792
Train Epoch: 13 [12736/60000 (21%)]	Loss: 7.625183
Train Epoch: 13 [19136/60000 (32%)]	Loss: 6.058256
Train Epoch: 13 [25536/60000 (43%)]	Loss: 7.509417
Train Epoch: 13 [31936/60000 (53%)]	Loss: 6.749000
Train Epoch: 13 [38336/60000 (64%)]	Loss: 6.399633
Train Epoch: 13 [44736/60000 (75%)]	Loss: 6.057249
Train Epoch: 13 [51136/60000 (85%)]	Loss: 6.990762
Train Epoch: 13 [57536/60000 (96%)]	Loss: 7.311841

Test set: Average loss: 8.0826, Accuracy: 1808/10000 (18%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 7.264678
Train Epoch: 14 [12736/60000 (21%)]	Loss: 5.629450
Train Epoch: 14 [19136/60000 (32%)]	Loss: 7.572999
Train Epoch: 14 [25536/60000 (43%)]	Loss: 7.760202
Train Epoch: 14 [31936/60000 (53%)]	Loss: 7.044203
Train Epoch: 14 [38336/60000 (64%)]	Loss: 6.931594
Train Epoch: 14 [44736/60000 (75%)]	Loss: 6.959701
Train Epoch: 14 [51136/60000 (85%)]	Loss: 7.269451
Train Epoch: 14 [57536/60000 (96%)]	Loss: 7.502498

Test set: Average loss: 7.5306, Accuracy: 2167/10000 (22%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 7.133900
Train Epoch: 15 [12736/60000 (21%)]	Loss: 7.513147
Train Epoch: 15 [19136/60000 (32%)]	Loss: 7.283292
Train Epoch: 15 [25536/60000 (43%)]	Loss: 9.346793
Train Epoch: 15 [31936/60000 (53%)]	Loss: 6.605873
Train Epoch: 15 [38336/60000 (64%)]	Loss: 7.034886
Train Epoch: 15 [44736/60000 (75%)]	Loss: 8.028779
Train Epoch: 15 [51136/60000 (85%)]	Loss: 6.754564
Train Epoch: 15 [57536/60000 (96%)]	Loss: 7.258500

Test set: Average loss: 7.0205, Accuracy: 2548/10000 (25%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=15, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.66 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 292730
