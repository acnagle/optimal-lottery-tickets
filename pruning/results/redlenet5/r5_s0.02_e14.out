Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=14, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.589047
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.203286
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.767450
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.981925
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.849517
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.697098
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.336214
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.568365
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.212293

Test set: Average loss: 1.8664, Accuracy: 5650/10000 (56%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.165735
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.760453
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.745503
Train Epoch: 2 [25536/60000 (43%)]	Loss: 2.483219
Train Epoch: 2 [31936/60000 (53%)]	Loss: 4.279560
Train Epoch: 2 [38336/60000 (64%)]	Loss: 3.173364
Train Epoch: 2 [44736/60000 (75%)]	Loss: 2.752521
Train Epoch: 2 [51136/60000 (85%)]	Loss: 3.576939
Train Epoch: 2 [57536/60000 (96%)]	Loss: 3.074972

Test set: Average loss: 3.7093, Accuracy: 4426/10000 (44%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 3.202549
Train Epoch: 3 [12736/60000 (21%)]	Loss: 3.672635
Train Epoch: 3 [19136/60000 (32%)]	Loss: 4.327084
Train Epoch: 3 [25536/60000 (43%)]	Loss: 5.124990
Train Epoch: 3 [31936/60000 (53%)]	Loss: 4.737895
Train Epoch: 3 [38336/60000 (64%)]	Loss: 4.814920
Train Epoch: 3 [44736/60000 (75%)]	Loss: 4.918453
Train Epoch: 3 [51136/60000 (85%)]	Loss: 5.858027
Train Epoch: 3 [57536/60000 (96%)]	Loss: 4.914676

Test set: Average loss: 4.9903, Accuracy: 2858/10000 (29%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 5.258826
Train Epoch: 4 [12736/60000 (21%)]	Loss: 5.738814
Train Epoch: 4 [19136/60000 (32%)]	Loss: 6.086108
Train Epoch: 4 [25536/60000 (43%)]	Loss: 4.758021
Train Epoch: 4 [31936/60000 (53%)]	Loss: 5.671005
Train Epoch: 4 [38336/60000 (64%)]	Loss: 6.736317
Train Epoch: 4 [44736/60000 (75%)]	Loss: 5.629004
Train Epoch: 4 [51136/60000 (85%)]	Loss: 5.317935
Train Epoch: 4 [57536/60000 (96%)]	Loss: 6.349417

Test set: Average loss: 6.5069, Accuracy: 2319/10000 (23%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 6.816995
Train Epoch: 5 [12736/60000 (21%)]	Loss: 6.672434
Train Epoch: 5 [19136/60000 (32%)]	Loss: 6.756713
Train Epoch: 5 [25536/60000 (43%)]	Loss: 6.730631
Train Epoch: 5 [31936/60000 (53%)]	Loss: 6.735317
Train Epoch: 5 [38336/60000 (64%)]	Loss: 8.101782
Train Epoch: 5 [44736/60000 (75%)]	Loss: 7.942870
Train Epoch: 5 [51136/60000 (85%)]	Loss: 7.529187
Train Epoch: 5 [57536/60000 (96%)]	Loss: 7.884294

Test set: Average loss: 7.1633, Accuracy: 2184/10000 (22%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 7.203043
Train Epoch: 6 [12736/60000 (21%)]	Loss: 7.668077
Train Epoch: 6 [19136/60000 (32%)]	Loss: 8.439927
Train Epoch: 6 [25536/60000 (43%)]	Loss: 8.181688
Train Epoch: 6 [31936/60000 (53%)]	Loss: 7.491840
Train Epoch: 6 [38336/60000 (64%)]	Loss: 8.467579
Train Epoch: 6 [44736/60000 (75%)]	Loss: 8.855191
Train Epoch: 6 [51136/60000 (85%)]	Loss: 8.345359
Train Epoch: 6 [57536/60000 (96%)]	Loss: 8.235394

Test set: Average loss: 8.1450, Accuracy: 2083/10000 (21%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 7.814421
Train Epoch: 7 [12736/60000 (21%)]	Loss: 8.506483
Train Epoch: 7 [19136/60000 (32%)]	Loss: 8.889233
Train Epoch: 7 [25536/60000 (43%)]	Loss: 7.806081
Train Epoch: 7 [31936/60000 (53%)]	Loss: 7.006123
Train Epoch: 7 [38336/60000 (64%)]	Loss: 8.823208
Train Epoch: 7 [44736/60000 (75%)]	Loss: 9.552005
Train Epoch: 7 [51136/60000 (85%)]	Loss: 9.937010
Train Epoch: 7 [57536/60000 (96%)]	Loss: 8.727106

Test set: Average loss: 8.8474, Accuracy: 1816/10000 (18%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 8.512862
Train Epoch: 8 [12736/60000 (21%)]	Loss: 6.342993
Train Epoch: 8 [19136/60000 (32%)]	Loss: 7.560277
Train Epoch: 8 [25536/60000 (43%)]	Loss: 8.791748
Train Epoch: 8 [31936/60000 (53%)]	Loss: 6.999766
Train Epoch: 8 [38336/60000 (64%)]	Loss: 9.840854
Train Epoch: 8 [44736/60000 (75%)]	Loss: 8.665284
Train Epoch: 8 [51136/60000 (85%)]	Loss: 7.372808
Train Epoch: 8 [57536/60000 (96%)]	Loss: 9.124294

Test set: Average loss: 8.8121, Accuracy: 1519/10000 (15%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 9.410175
Train Epoch: 9 [12736/60000 (21%)]	Loss: 9.289622
Train Epoch: 9 [19136/60000 (32%)]	Loss: 8.563030
Train Epoch: 9 [25536/60000 (43%)]	Loss: 11.827209
Train Epoch: 9 [31936/60000 (53%)]	Loss: 9.012391
Train Epoch: 9 [38336/60000 (64%)]	Loss: 9.902144
Train Epoch: 9 [44736/60000 (75%)]	Loss: 10.147441
Train Epoch: 9 [51136/60000 (85%)]	Loss: 8.340463
Train Epoch: 9 [57536/60000 (96%)]	Loss: 9.505591

Test set: Average loss: 9.0704, Accuracy: 1590/10000 (16%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 8.289763
Train Epoch: 10 [12736/60000 (21%)]	Loss: 10.022490
Train Epoch: 10 [19136/60000 (32%)]	Loss: 8.090311
Train Epoch: 10 [25536/60000 (43%)]	Loss: 10.808155
Train Epoch: 10 [31936/60000 (53%)]	Loss: 10.098001
Train Epoch: 10 [38336/60000 (64%)]	Loss: 9.558907
Train Epoch: 10 [44736/60000 (75%)]	Loss: 8.323181
Train Epoch: 10 [51136/60000 (85%)]	Loss: 8.794826
Train Epoch: 10 [57536/60000 (96%)]	Loss: 9.176885

Test set: Average loss: 9.4500, Accuracy: 1588/10000 (16%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 10.429351
Train Epoch: 11 [12736/60000 (21%)]	Loss: 9.803033
Train Epoch: 11 [19136/60000 (32%)]	Loss: 8.059108
Train Epoch: 11 [25536/60000 (43%)]	Loss: 7.399821
Train Epoch: 11 [31936/60000 (53%)]	Loss: 9.715309
Train Epoch: 11 [38336/60000 (64%)]	Loss: 8.956092
Train Epoch: 11 [44736/60000 (75%)]	Loss: 10.041165
Train Epoch: 11 [51136/60000 (85%)]	Loss: 8.873693
Train Epoch: 11 [57536/60000 (96%)]	Loss: 9.328211

Test set: Average loss: 9.8320, Accuracy: 1425/10000 (14%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 9.317750
Train Epoch: 12 [12736/60000 (21%)]	Loss: 7.662145
Train Epoch: 12 [19136/60000 (32%)]	Loss: 8.959259
Train Epoch: 12 [25536/60000 (43%)]	Loss: 8.712793
Train Epoch: 12 [31936/60000 (53%)]	Loss: 8.511142
Train Epoch: 12 [38336/60000 (64%)]	Loss: 8.609012
Train Epoch: 12 [44736/60000 (75%)]	Loss: 7.747976
Train Epoch: 12 [51136/60000 (85%)]	Loss: 8.632282
Train Epoch: 12 [57536/60000 (96%)]	Loss: 11.210494

Test set: Average loss: 9.5813, Accuracy: 1655/10000 (17%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 11.023618
Train Epoch: 13 [12736/60000 (21%)]	Loss: 10.112470
Train Epoch: 13 [19136/60000 (32%)]	Loss: 8.710665
Train Epoch: 13 [25536/60000 (43%)]	Loss: 10.532424
Train Epoch: 13 [31936/60000 (53%)]	Loss: 9.141534
Train Epoch: 13 [38336/60000 (64%)]	Loss: 8.093705
Train Epoch: 13 [44736/60000 (75%)]	Loss: 9.454902
Train Epoch: 13 [51136/60000 (85%)]	Loss: 9.144908
Train Epoch: 13 [57536/60000 (96%)]	Loss: 8.215514

Test set: Average loss: 10.3081, Accuracy: 1275/10000 (13%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 8.833155
Train Epoch: 14 [12736/60000 (21%)]	Loss: 8.791203
Train Epoch: 14 [19136/60000 (32%)]	Loss: 10.274973
Train Epoch: 14 [25536/60000 (43%)]	Loss: 10.706667
Train Epoch: 14 [31936/60000 (53%)]	Loss: 9.943952
Train Epoch: 14 [38336/60000 (64%)]	Loss: 9.599820
Train Epoch: 14 [44736/60000 (75%)]	Loss: 9.021371
Train Epoch: 14 [51136/60000 (85%)]	Loss: 9.078331
Train Epoch: 14 [57536/60000 (96%)]	Loss: 9.621935

Test set: Average loss: 9.9032, Accuracy: 1445/10000 (14%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=14, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.50 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 294218
