Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=19, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=True, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.028424
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.083251
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.579357
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.564039
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.724923
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.709330
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.448144
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.427508
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.446449

Test set: Average loss: 0.4540, Accuracy: 8621/10000 (86%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.456510
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.422086
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.451626
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.489412
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.625620
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.593872
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.150062
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.418526
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.304578

Test set: Average loss: 0.3352, Accuracy: 8997/10000 (90%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.458494
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.542643
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.354768
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.197323
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.415108
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.287895
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.314660
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.258697
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.245566

Test set: Average loss: 0.2854, Accuracy: 9133/10000 (91%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.540176
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.247764
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.501038
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.357279
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.287179
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.476735
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.436092
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.302384
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.396827

Test set: Average loss: 0.2700, Accuracy: 9190/10000 (92%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.359090
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.322660
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.239178
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.317941
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.236851
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.186841
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.300975
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.195837
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.251493

Test set: Average loss: 0.2531, Accuracy: 9201/10000 (92%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.192638
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.259389
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.192936
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.365449
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.305770
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.384554
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.172940
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.303593
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.196669

Test set: Average loss: 0.2593, Accuracy: 9278/10000 (93%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.293318
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.108387
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.379309
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.161443
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.329732
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.132730
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.295456
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.346256
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.170332

Test set: Average loss: 0.2581, Accuracy: 9223/10000 (92%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.160639
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.457084
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.300192
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.230225
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.102669
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.252740
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.101909
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.207148
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.156909

Test set: Average loss: 0.2252, Accuracy: 9343/10000 (93%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.240006
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.295976
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.284069
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.194865
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.089542
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.121914
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.404023
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.432101
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.268050

Test set: Average loss: 0.2200, Accuracy: 9322/10000 (93%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.090067
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.232350
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.183882
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.186453
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.207568
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.182677
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.158543
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.246144
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.127322

Test set: Average loss: 0.1840, Accuracy: 9444/10000 (94%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.057096
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.118771
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.202744
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.077186
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.163172
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.189870
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.182181
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.093910
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.352853

Test set: Average loss: 0.1835, Accuracy: 9455/10000 (95%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.165701
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.222743
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.200758
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.238578
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.186782
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.151889
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.267754
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.166922
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.182480

Test set: Average loss: 0.1788, Accuracy: 9476/10000 (95%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.274617
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.094483
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.189512
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.148762
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.329854
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.086399
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.177574
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.347921
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.287167

Test set: Average loss: 0.1646, Accuracy: 9502/10000 (95%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.141914
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.056481
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.258921
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.179663
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.261259
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.159550
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.059933
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.179892
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.173890

Test set: Average loss: 0.1708, Accuracy: 9490/10000 (95%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.167528
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.114032
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.135288
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.210531
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.183347
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.213213
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.155879
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.216220
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.099609

Test set: Average loss: 0.1607, Accuracy: 9521/10000 (95%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.265360
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.205497
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.156363
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.164637
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.257538
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.156309
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.132694
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.199659
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.136989

Test set: Average loss: 0.1666, Accuracy: 9516/10000 (95%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.308464
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.253477
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.087968
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.150399
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.123743
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.107933
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.247359
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.105796
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.213695

Test set: Average loss: 0.1508, Accuracy: 9559/10000 (96%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.049421
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.171357
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.115342
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.077340
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.159607
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.181387
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.148295
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.088286
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.222349

Test set: Average loss: 0.1423, Accuracy: 9603/10000 (96%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.136008
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.180136
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.059694
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.191468
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.204885
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.124582
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.131423
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.096389
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.203788

Test set: Average loss: 0.1404, Accuracy: 9592/10000 (96%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=19, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=True, wd=0.0005)


Total time spent pruning/training: 2.12 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 285289
