Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=12, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.25, use_relu=False, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.056318
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.685629
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.394015
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.240289
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.418858
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.448060
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.229406
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.296065
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.469141

Test set: Average loss: 0.2803, Accuracy: 9091/10000 (91%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.198539
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.237568
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.279270
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.308752
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.582881
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.465597
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.093068
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.393455
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.245607

Test set: Average loss: 0.2050, Accuracy: 9333/10000 (93%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.309230
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.350387
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.161100
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.093418
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.168907
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.189424
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.094529
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.083351
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.250380

Test set: Average loss: 0.1938, Accuracy: 9376/10000 (94%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.210723
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.092054
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.224667
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.272380
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.236574
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.233109
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.160744
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.176751
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.354565

Test set: Average loss: 0.1734, Accuracy: 9464/10000 (95%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.087317
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.171393
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.249336
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.149680
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.256595
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.114375
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.159364
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.103403
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.160364

Test set: Average loss: 0.1548, Accuracy: 9505/10000 (95%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.270512
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.123194
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.253225
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.091442
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.139333
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.196099
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.066452
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.123612
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.159546

Test set: Average loss: 0.1541, Accuracy: 9531/10000 (95%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.146714
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.126525
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.187134
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.110790
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.124974
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.041187
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.157495
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.094919
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.140110

Test set: Average loss: 0.1384, Accuracy: 9543/10000 (95%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.072868
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.376803
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.274793
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.202682
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.017887
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.189270
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.070829
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.134709
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.161215

Test set: Average loss: 0.1553, Accuracy: 9510/10000 (95%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.085396
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.161941
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.143421
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.088539
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.046662
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.058749
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.239695
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.149666
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.142918

Test set: Average loss: 0.1330, Accuracy: 9585/10000 (96%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.028678
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.189381
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.067787
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.088513
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.198124
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.119853
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.086082
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.084089
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.104109

Test set: Average loss: 0.1243, Accuracy: 9596/10000 (96%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.030105
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.085123
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.179520
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.073498
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.098554
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.110295
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.085627
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.115345
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.133899

Test set: Average loss: 0.1209, Accuracy: 9601/10000 (96%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.088905
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.065368
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.155391
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.165962
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.049620
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.046199
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.109891
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.054184
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.072193

Test set: Average loss: 0.1138, Accuracy: 9645/10000 (96%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=12, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.25, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.34 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 225765
