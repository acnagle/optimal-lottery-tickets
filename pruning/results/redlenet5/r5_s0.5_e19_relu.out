Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=19, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=True, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.928482
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.544259
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.911311
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.696201
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.851145
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.988208
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.712000
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.769431
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.587024

Test set: Average loss: 0.5910, Accuracy: 8313/10000 (83%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.567915
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.454973
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.527543
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.560837
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.643546
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.686699
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.309310
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.452811
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.453495

Test set: Average loss: 0.4324, Accuracy: 8899/10000 (89%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.490332
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.473347
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.405599
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.289135
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.385786
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.461545
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.376202
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.355384
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.456080

Test set: Average loss: 0.3919, Accuracy: 8971/10000 (90%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.474759
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.466839
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.396749
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.365970
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.539147
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.464020
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.380926
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.399490
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.413338

Test set: Average loss: 0.3460, Accuracy: 9078/10000 (91%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.304687
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.495260
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.347472
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.362779
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.431637
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.184880
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.411315
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.281504
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.378381

Test set: Average loss: 0.3493, Accuracy: 9007/10000 (90%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.292337
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.265575
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.301374
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.341016
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.384356
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.379840
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.294938
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.388001
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.398415

Test set: Average loss: 0.3500, Accuracy: 9032/10000 (90%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.355261
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.332014
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.481387
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.288287
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.403345
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.240714
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.336040
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.351851
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.251014

Test set: Average loss: 0.3497, Accuracy: 8981/10000 (90%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.254030
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.353458
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.397188
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.373117
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.209849
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.318192
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.166805
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.336305
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.313167

Test set: Average loss: 0.3176, Accuracy: 9122/10000 (91%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.294643
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.313153
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.386281
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.289033
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.177306
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.186599
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.404247
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.404281
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.299001

Test set: Average loss: 0.2873, Accuracy: 9234/10000 (92%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.157024
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.445340
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.280095
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.384697
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.454839
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.301363
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.355205
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.176593
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.266948

Test set: Average loss: 0.2862, Accuracy: 9234/10000 (92%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.206023
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.211635
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.301228
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.230044
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.269984
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.242506
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.244524
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.229602
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.380478

Test set: Average loss: 0.2830, Accuracy: 9220/10000 (92%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.267614
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.283761
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.403395
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.309231
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.235653
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.237578
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.312883
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.273718
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.285410

Test set: Average loss: 0.2721, Accuracy: 9279/10000 (93%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.316803
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.303740
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.240615
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.370294
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.431474
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.160594
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.394236
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.346408
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.362763

Test set: Average loss: 0.3170, Accuracy: 9052/10000 (91%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.199396
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.191500
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.419715
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.242417
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.381544
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.335382
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.140964
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.232995
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.318407

Test set: Average loss: 0.2707, Accuracy: 9274/10000 (93%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.266188
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.226934
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.256411
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.359801
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.321146
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.312680
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.263813
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.317815
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.265129

Test set: Average loss: 0.2711, Accuracy: 9279/10000 (93%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.423775
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.304553
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.230120
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.235970
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.316677
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.276537
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.214521
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.295151
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.245561

Test set: Average loss: 0.2775, Accuracy: 9268/10000 (93%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.579991
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.340713
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.326459
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.264877
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.271762
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.185595
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.296426
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.173097
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.351890

Test set: Average loss: 0.3065, Accuracy: 9140/10000 (91%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.197371
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.277246
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.220797
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.198018
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.292478
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.313058
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.335350
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.201313
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.322072

Test set: Average loss: 0.2616, Accuracy: 9305/10000 (93%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.166378
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.292205
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.230827
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.331151
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.343554
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.192803
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.222276
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.237734
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.377872

Test set: Average loss: 0.2651, Accuracy: 9305/10000 (93%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=19, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=True, wd=0.0005)


Total time spent pruning/training: 2.12 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 151360
