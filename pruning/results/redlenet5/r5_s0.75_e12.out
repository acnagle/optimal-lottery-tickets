Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=12, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.936540
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.777198
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.321549
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.108186
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.060496
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.942801
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.897477
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.758695
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.794110

Test set: Average loss: 0.7087, Accuracy: 8011/10000 (80%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.645559
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.472524
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.540380
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.544536
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.838347
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.682498
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.280217
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.441412
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.412803

Test set: Average loss: 0.4811, Accuracy: 8529/10000 (85%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.477717
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.437448
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.403529
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.305417
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.629302
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.353535
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.282498
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.343668
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.463395

Test set: Average loss: 0.3353, Accuracy: 9062/10000 (91%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.525467
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.413548
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.433223
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.468034
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.420251
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.304117
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.261459
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.273177
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.530847

Test set: Average loss: 0.2986, Accuracy: 9155/10000 (92%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.246309
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.359207
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.248602
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.364525
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.447897
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.214396
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.293142
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.205473
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.259062

Test set: Average loss: 0.2725, Accuracy: 9159/10000 (92%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.334083
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.216927
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.234018
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.314963
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.335039
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.347825
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.204470
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.302064
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.342457

Test set: Average loss: 0.2905, Accuracy: 9170/10000 (92%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.351853
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.270421
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.364712
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.241508
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.318733
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.123673
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.438670
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.238438
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.308353

Test set: Average loss: 0.2483, Accuracy: 9263/10000 (93%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.195034
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.329631
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.359336
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.313395
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.158437
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.295485
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.131731
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.307854
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.236892

Test set: Average loss: 0.2538, Accuracy: 9284/10000 (93%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.261650
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.197651
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.222308
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.223186
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.093910
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.104106
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.345432
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.358069
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.197754

Test set: Average loss: 0.2289, Accuracy: 9329/10000 (93%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.123096
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.321455
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.273238
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.245280
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.325403
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.290329
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.205914
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.201108
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.185402

Test set: Average loss: 0.2421, Accuracy: 9287/10000 (93%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.091277
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.142931
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.297380
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.206468
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.238898
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.212341
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.132562
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.206917
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.309885

Test set: Average loss: 0.2389, Accuracy: 9320/10000 (93%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.176198
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.255392
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.351495
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.199748
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.191103
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.167068
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.322191
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.171741
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.224359

Test set: Average loss: 0.2231, Accuracy: 9339/10000 (93%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=12, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.32 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 76955
