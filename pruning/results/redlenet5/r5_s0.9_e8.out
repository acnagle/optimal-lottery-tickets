Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=8, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.301238
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.294530
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.290821
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.258794
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.265475
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.273849
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.245946
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.204273
Train Epoch: 1 [57536/60000 (96%)]	Loss: 2.089131

Test set: Average loss: 2.0859, Accuracy: 2683/10000 (27%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.032574
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.027633
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.964299
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.995834
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.926668
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.837840
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.694933
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.773233
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.682527

Test set: Average loss: 1.6677, Accuracy: 4673/10000 (47%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.739384
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.649624
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.608735
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.526391
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.466847
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.521825
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.467221
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.498454
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.453043

Test set: Average loss: 1.4075, Accuracy: 5614/10000 (56%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.603173
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.462828
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.517535
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.297922
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.386539
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.323330
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.354159
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.323993
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.343807

Test set: Average loss: 1.2160, Accuracy: 6739/10000 (67%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.134636
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.141915
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.020481
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.119997
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.405839
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.947991
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.153836
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.097121
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.199235

Test set: Average loss: 1.1189, Accuracy: 6740/10000 (67%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.964855
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.012952
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.010662
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.219747
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.143333
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.086401
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.059709
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.080489
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.124277

Test set: Average loss: 1.0602, Accuracy: 6770/10000 (68%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.114332
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.090216
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.971581
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.975253
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.107169
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.055858
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.225780
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.939078
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.991509

Test set: Average loss: 1.0132, Accuracy: 7155/10000 (72%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.042186
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.160322
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.990947
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.913207
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.999687
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.110426
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.883834
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.063447
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.918311

Test set: Average loss: 1.0562, Accuracy: 6802/10000 (68%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=8, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005)


Total time spent pruning/training: 0.87 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 32312
