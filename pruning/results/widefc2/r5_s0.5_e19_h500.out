Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=False, wd=0.0005) 

Pruning a Wide Two-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.407745
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.351249
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.274962
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.288066
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.233345
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.135031
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.314829
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.300489
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.148695

Test set: Average loss: 0.1637, Accuracy: 9531/10000 (95%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.185366
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.112688
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.120651
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.202198
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.191730
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.105388
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.164604
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.106278
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.059977

Test set: Average loss: 0.1266, Accuracy: 9640/10000 (96%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.098895
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.048331
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.051655
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.078305
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.171600
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.062308
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.096080
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.297595
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.057755

Test set: Average loss: 0.1104, Accuracy: 9667/10000 (97%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.077605
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.182152
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.054901
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.087425
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.110932
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.110708
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.131234
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.084628
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.064354

Test set: Average loss: 0.1158, Accuracy: 9651/10000 (97%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.027895
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.026055
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.035023
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.120126
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.140432
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.116524
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.051649
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.029203
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.037602

Test set: Average loss: 0.1157, Accuracy: 9653/10000 (97%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.106524
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.032779
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.054077
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.133456
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.037068
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.093864
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.085342
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.122771
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.056716

Test set: Average loss: 0.0985, Accuracy: 9712/10000 (97%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.030397
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.037168
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.112570
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.063190
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.126379
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.145475
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.145530
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.057110
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.042778

Test set: Average loss: 0.1013, Accuracy: 9684/10000 (97%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.110366
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.052207
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.044397
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.135766
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.147890
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.050197
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.063786
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.054257
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.135993

Test set: Average loss: 0.1066, Accuracy: 9648/10000 (96%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.068283
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.046837
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.036961
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.052855
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.066659
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.035530
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.049088
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.093819
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.146299

Test set: Average loss: 0.1174, Accuracy: 9618/10000 (96%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.104315
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.044887
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.057765
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.056163
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.255981
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.048445
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.115309
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.045108
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.057860

Test set: Average loss: 0.1300, Accuracy: 9567/10000 (96%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.046602
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.027111
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.038395
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.032701
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.085656
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.108290
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.051920
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.054678
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.027003

Test set: Average loss: 0.0966, Accuracy: 9716/10000 (97%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.035232
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.084577
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.071309
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.024254
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.048644
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.106227
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.043048
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.133882
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.065950

Test set: Average loss: 0.1020, Accuracy: 9683/10000 (97%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.082333
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.023043
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.104833
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.100087
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.057409
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.197184
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.030920
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.156338
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.163207

Test set: Average loss: 0.0884, Accuracy: 9731/10000 (97%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.064141
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.027823
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.066426
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.029522
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.047344
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.020966
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.032923
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.126184
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.100950

Test set: Average loss: 0.0798, Accuracy: 9765/10000 (98%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.040758
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.035336
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.026394
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.038267
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.111647
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.028563
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.018783
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.040538
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.031662

Test set: Average loss: 0.0718, Accuracy: 9790/10000 (98%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.020767
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.069579
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.015696
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.013658
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.019114
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.013677
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.009797
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.054616
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.020240

Test set: Average loss: 0.0657, Accuracy: 9795/10000 (98%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.024720
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.035027
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.006391
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.010024
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.023272
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.016421
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.021062
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.037133
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.011355

Test set: Average loss: 0.0664, Accuracy: 9802/10000 (98%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.022601
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.012311
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.009790
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.009875
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.012299
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.037350
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.018035
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.009313
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.010897

Test set: Average loss: 0.0617, Accuracy: 9816/10000 (98%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.013200
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.013594
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.013169
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.006872
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.013338
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.012484
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.009667
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.008242
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.012166

Test set: Average loss: 0.0604, Accuracy: 9814/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.01 minutes
Total number of parameters in model: 1991352
Number of parameters in pruned model: 995676
