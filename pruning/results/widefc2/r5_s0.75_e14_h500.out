Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005) 

Pruning a Wide Two-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.459534
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.404926
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.302269
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.323539
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.278083
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.173084
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.316158
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.315274
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.173689

Test set: Average loss: 0.1899, Accuracy: 9467/10000 (95%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.229783
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.115608
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.151866
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.230824
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.238265
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.107946
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.156022
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.113695
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.089083

Test set: Average loss: 0.1497, Accuracy: 9575/10000 (96%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.134181
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.053358
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.063295
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.096294
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.195890
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.077894
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.132974
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.303879
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.082804

Test set: Average loss: 0.1210, Accuracy: 9652/10000 (97%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.106214
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.198202
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.086798
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.117143
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.129012
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.127982
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.134671
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.102148
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.070205

Test set: Average loss: 0.1249, Accuracy: 9640/10000 (96%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.034235
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.030728
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.043751
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.132821
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.134780
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.143727
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.063116
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.032120
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.059806

Test set: Average loss: 0.1096, Accuracy: 9693/10000 (97%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.137865
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.057675
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.072213
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.128953
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.043843
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.098830
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.056064
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.118677
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.049313

Test set: Average loss: 0.0997, Accuracy: 9713/10000 (97%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.034540
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.055385
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.079179
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.064051
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.120289
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.131292
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.129635
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.025236
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.053868

Test set: Average loss: 0.0934, Accuracy: 9720/10000 (97%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.100416
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.063617
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.042170
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.114361
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.181168
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.078749
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.068038
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.041490
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.133396

Test set: Average loss: 0.0907, Accuracy: 9733/10000 (97%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.075340
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.031019
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.034247
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.041311
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.039834
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.029188
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.047554
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.066115
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.126069

Test set: Average loss: 0.0838, Accuracy: 9753/10000 (98%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.093252
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.033805
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.049498
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.050340
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.112777
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.029275
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.064845
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.026859
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.064458

Test set: Average loss: 0.0827, Accuracy: 9750/10000 (98%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.039742
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.013575
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.028671
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.030937
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.047479
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.064969
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.040637
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.017690
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.035297

Test set: Average loss: 0.0788, Accuracy: 9773/10000 (98%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.028053
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.041743
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.050294
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.016380
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.032122
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.084909
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.028608
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.070207
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.071069

Test set: Average loss: 0.0772, Accuracy: 9781/10000 (98%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.074399
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.021423
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.054679
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.065809
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.040964
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.106284
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.027429
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.075585
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.092991

Test set: Average loss: 0.0762, Accuracy: 9782/10000 (98%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.048655
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.041543
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.057986
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.040418
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.041941
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.023737
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.024672
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.079851
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.066596

Test set: Average loss: 0.0749, Accuracy: 9784/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.48 minutes
Total number of parameters in model: 1991352
Number of parameters in pruned model: 497838
