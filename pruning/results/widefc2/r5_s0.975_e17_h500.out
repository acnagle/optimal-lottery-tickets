Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005) 

Pruning a Wide Two-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.905182
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.724479
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.568863
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.556393
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.468835
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.412400
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.494015
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.489236
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.449041

Test set: Average loss: 0.4002, Accuracy: 8998/10000 (90%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.435970
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.324481
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.409678
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.465359
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.454618
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.267459
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.328731
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.278619
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.373782

Test set: Average loss: 0.3523, Accuracy: 9096/10000 (91%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.273105
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.214640
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.248125
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.335836
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.340190
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.269994
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.362485
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.497005
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.281490

Test set: Average loss: 0.3341, Accuracy: 9161/10000 (92%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.414549
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.397261
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.431017
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.371705
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.369833
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.362467
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.305682
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.308430
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.320578

Test set: Average loss: 0.3256, Accuracy: 9168/10000 (92%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.220507
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.250907
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.306563
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.346729
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.349045
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.548027
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.290796
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.277163
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.292340

Test set: Average loss: 0.3222, Accuracy: 9184/10000 (92%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.368715
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.341881
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.347971
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.340039
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.332899
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.289289
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.247074
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.342006
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.279903

Test set: Average loss: 0.3226, Accuracy: 9179/10000 (92%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.231701
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.275076
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.371316
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.233799
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.358558
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.333443
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.353772
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.274383
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.361309

Test set: Average loss: 0.3168, Accuracy: 9190/10000 (92%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.597598
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.293606
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.232779
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.369571
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.401751
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.209780
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.263086
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.295917
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.377003

Test set: Average loss: 0.3133, Accuracy: 9191/10000 (92%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.258340
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.266906
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.241083
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.212093
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.328618
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.300593
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.345942
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.411188
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.454054

Test set: Average loss: 0.3140, Accuracy: 9186/10000 (92%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.308254
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.302723
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.247024
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.290330
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.412903
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.223546
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.383863
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.248412
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.364923

Test set: Average loss: 0.3114, Accuracy: 9219/10000 (92%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.329126
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.219676
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.204541
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.273074
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.390636
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.287431
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.219635
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.267762
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.265091

Test set: Average loss: 0.3105, Accuracy: 9213/10000 (92%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.285502
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.319866
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.368411
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.217542
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.337083
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.416843
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.256101
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.335843
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.346569

Test set: Average loss: 0.3116, Accuracy: 9210/10000 (92%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.335455
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.215914
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.280825
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.337792
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.355781
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.510345
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.205469
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.351686
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.340871

Test set: Average loss: 0.3105, Accuracy: 9219/10000 (92%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.337912
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.356278
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.336993
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.344185
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.399547
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.315368
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.269298
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.317838
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.333699

Test set: Average loss: 0.3098, Accuracy: 9223/10000 (92%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.369186
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.309367
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.381854
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.229528
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.432895
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.372152
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.272044
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.318544
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.341731

Test set: Average loss: 0.3123, Accuracy: 9218/10000 (92%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.361165
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.429977
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.245927
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.326635
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.313022
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.241695
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.217748
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.351071
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.351069

Test set: Average loss: 0.3091, Accuracy: 9220/10000 (92%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.378103
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.245184
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.194906
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.186606
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.370966
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.378188
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.331388
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.331986
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.276973

Test set: Average loss: 0.3111, Accuracy: 9226/10000 (92%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.79 minutes
Total number of parameters in model: 1991352
Number of parameters in pruned model: 49783
