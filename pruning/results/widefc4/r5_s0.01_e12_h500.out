Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.460646
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.325525
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.622307
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.544986
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.545340
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.554977
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.576526
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.543963
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.877355

Test set: Average loss: 0.6750, Accuracy: 8073/10000 (81%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.541250
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.940038
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.840641
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.808210
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.944081
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.879654
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.031271
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.066736
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.111376

Test set: Average loss: 1.1407, Accuracy: 6532/10000 (65%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.206658
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.203356
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.060849
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.383282
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.319166
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.623779
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.324903
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.606468
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.600169

Test set: Average loss: 1.4694, Accuracy: 5520/10000 (55%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.705024
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.562378
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.658633
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.689356
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.525633
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.704528
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.680336
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.667035
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.772469

Test set: Average loss: 1.7140, Accuracy: 4363/10000 (44%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.820387
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.649580
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.874918
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.670279
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.708316
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.703664
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.813134
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.837132
Train Epoch: 5 [57536/60000 (96%)]	Loss: 2.056814

Test set: Average loss: 1.8765, Accuracy: 3674/10000 (37%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.799543
Train Epoch: 6 [12736/60000 (21%)]	Loss: 2.021853
Train Epoch: 6 [19136/60000 (32%)]	Loss: 2.119689
Train Epoch: 6 [25536/60000 (43%)]	Loss: 2.000404
Train Epoch: 6 [31936/60000 (53%)]	Loss: 2.018914
Train Epoch: 6 [38336/60000 (64%)]	Loss: 2.027906
Train Epoch: 6 [44736/60000 (75%)]	Loss: 2.026376
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.892446
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.824448

Test set: Average loss: 1.9475, Accuracy: 3443/10000 (34%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 2.098194
Train Epoch: 7 [12736/60000 (21%)]	Loss: 2.019691
Train Epoch: 7 [19136/60000 (32%)]	Loss: 2.098669
Train Epoch: 7 [25536/60000 (43%)]	Loss: 2.095518
Train Epoch: 7 [31936/60000 (53%)]	Loss: 2.037578
Train Epoch: 7 [38336/60000 (64%)]	Loss: 2.197133
Train Epoch: 7 [44736/60000 (75%)]	Loss: 2.111314
Train Epoch: 7 [51136/60000 (85%)]	Loss: 2.142200
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.948868

Test set: Average loss: 2.0581, Accuracy: 2819/10000 (28%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.920449
Train Epoch: 8 [12736/60000 (21%)]	Loss: 2.052346
Train Epoch: 8 [19136/60000 (32%)]	Loss: 2.052780
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.896710
Train Epoch: 8 [31936/60000 (53%)]	Loss: 2.042086
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.922125
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.860576
Train Epoch: 8 [51136/60000 (85%)]	Loss: 2.158037
Train Epoch: 8 [57536/60000 (96%)]	Loss: 2.125995

Test set: Average loss: 2.0376, Accuracy: 3041/10000 (30%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.959220
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.976477
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.975331
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.865993
Train Epoch: 9 [31936/60000 (53%)]	Loss: 2.019303
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.942250
Train Epoch: 9 [44736/60000 (75%)]	Loss: 2.026998
Train Epoch: 9 [51136/60000 (85%)]	Loss: 2.130816
Train Epoch: 9 [57536/60000 (96%)]	Loss: 2.238127

Test set: Average loss: 2.0588, Accuracy: 2915/10000 (29%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 2.192019
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.999258
Train Epoch: 10 [19136/60000 (32%)]	Loss: 2.049198
Train Epoch: 10 [25536/60000 (43%)]	Loss: 2.188336
Train Epoch: 10 [31936/60000 (53%)]	Loss: 2.006473
Train Epoch: 10 [38336/60000 (64%)]	Loss: 2.084468
Train Epoch: 10 [44736/60000 (75%)]	Loss: 2.192670
Train Epoch: 10 [51136/60000 (85%)]	Loss: 2.160226
Train Epoch: 10 [57536/60000 (96%)]	Loss: 2.254098

Test set: Average loss: 2.0757, Accuracy: 2924/10000 (29%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.879916
Train Epoch: 11 [12736/60000 (21%)]	Loss: 2.049194
Train Epoch: 11 [19136/60000 (32%)]	Loss: 2.030226
Train Epoch: 11 [25536/60000 (43%)]	Loss: 2.154884
Train Epoch: 11 [31936/60000 (53%)]	Loss: 2.061149
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.855625
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.991336
Train Epoch: 11 [51136/60000 (85%)]	Loss: 2.191185
Train Epoch: 11 [57536/60000 (96%)]	Loss: 2.120078

Test set: Average loss: 2.0774, Accuracy: 2835/10000 (28%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 2.122664
Train Epoch: 12 [12736/60000 (21%)]	Loss: 2.061389
Train Epoch: 12 [19136/60000 (32%)]	Loss: 2.040045
Train Epoch: 12 [25536/60000 (43%)]	Loss: 2.292820
Train Epoch: 12 [31936/60000 (53%)]	Loss: 2.160078
Train Epoch: 12 [38336/60000 (64%)]	Loss: 2.075179
Train Epoch: 12 [44736/60000 (75%)]	Loss: 2.043763
Train Epoch: 12 [51136/60000 (85%)]	Loss: 2.247576
Train Epoch: 12 [57536/60000 (96%)]	Loss: 2.111664

Test set: Average loss: 2.0768, Accuracy: 2892/10000 (29%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.13 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 4451542
