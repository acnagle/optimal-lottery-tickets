Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.438271
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.193287
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.502275
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.234330
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.281237
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.501562
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.129462
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.174747
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.240347

Test set: Average loss: 0.3205, Accuracy: 8956/10000 (90%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.131983
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.258394
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.325358
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.166751
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.331152
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.227387
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.535230
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.305113
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.204788

Test set: Average loss: 0.2961, Accuracy: 9063/10000 (91%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.383355
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.167008
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.240236
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.309967
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.204190
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.463625
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.452310
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.493303
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.328696

Test set: Average loss: 0.3691, Accuracy: 8896/10000 (89%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.832648
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.252644
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.560550
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.867361
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.409565
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.376417
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.687555
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.467755
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.739617

Test set: Average loss: 0.6974, Accuracy: 7508/10000 (75%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.567632
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.468242
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.391281
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.390988
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.481493
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.620229
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.579211
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.584713
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.080765

Test set: Average loss: 0.6030, Accuracy: 8176/10000 (82%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.476446
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.808108
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.801985
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.720775
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.724484
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.749357
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.882900
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.676807
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.805442

Test set: Average loss: 0.8398, Accuracy: 7362/10000 (74%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.992708
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.906846
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.876190
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.811691
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.233943
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.908187
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.962086
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.043896
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.829835

Test set: Average loss: 0.9985, Accuracy: 6754/10000 (68%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.752654
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.030946
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.053926
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.957263
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.967109
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.973110
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.940705
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.062153
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.893832

Test set: Average loss: 1.0011, Accuracy: 7144/10000 (71%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.068011
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.028457
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.022105
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.914980
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.125448
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.988909
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.122672
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.161914
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.213746

Test set: Average loss: 1.1464, Accuracy: 6473/10000 (65%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.192062
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.128843
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.081814
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.199968
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.220395
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.097129
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.174124
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.176324
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.311526

Test set: Average loss: 1.1182, Accuracy: 6765/10000 (68%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.031056
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.125011
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.037655
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.193923
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.062515
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.078200
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.097591
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.225100
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.353661

Test set: Average loss: 1.1854, Accuracy: 6505/10000 (65%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 1.157804
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.096593
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.063899
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.204152
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.275897
Train Epoch: 12 [38336/60000 (64%)]	Loss: 1.206962
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.286018
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.223064
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.182374

Test set: Average loss: 1.2220, Accuracy: 6277/10000 (63%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.258089
Train Epoch: 13 [12736/60000 (21%)]	Loss: 1.031572
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.273835
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.220466
Train Epoch: 13 [31936/60000 (53%)]	Loss: 1.216646
Train Epoch: 13 [38336/60000 (64%)]	Loss: 1.409691
Train Epoch: 13 [44736/60000 (75%)]	Loss: 1.148966
Train Epoch: 13 [51136/60000 (85%)]	Loss: 1.143445
Train Epoch: 13 [57536/60000 (96%)]	Loss: 1.348698

Test set: Average loss: 1.2245, Accuracy: 6382/10000 (64%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.303974
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.274562
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.327290
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.281081
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.237362
Train Epoch: 14 [38336/60000 (64%)]	Loss: 1.222469
Train Epoch: 14 [44736/60000 (75%)]	Loss: 1.220187
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.207528
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.053653

Test set: Average loss: 1.2376, Accuracy: 6316/10000 (63%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 1.204522
Train Epoch: 15 [12736/60000 (21%)]	Loss: 1.227175
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.991971
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.201884
Train Epoch: 15 [31936/60000 (53%)]	Loss: 1.282930
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.272767
Train Epoch: 15 [44736/60000 (75%)]	Loss: 1.129085
Train Epoch: 15 [51136/60000 (85%)]	Loss: 1.303945
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.319579

Test set: Average loss: 1.2247, Accuracy: 6492/10000 (65%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 1.245120
Train Epoch: 16 [12736/60000 (21%)]	Loss: 1.093472
Train Epoch: 16 [19136/60000 (32%)]	Loss: 1.165861
Train Epoch: 16 [25536/60000 (43%)]	Loss: 1.251302
Train Epoch: 16 [31936/60000 (53%)]	Loss: 1.300068
Train Epoch: 16 [38336/60000 (64%)]	Loss: 1.250546
Train Epoch: 16 [44736/60000 (75%)]	Loss: 1.257137
Train Epoch: 16 [51136/60000 (85%)]	Loss: 1.303202
Train Epoch: 16 [57536/60000 (96%)]	Loss: 1.187808

Test set: Average loss: 1.3675, Accuracy: 5437/10000 (54%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 1.127210
Train Epoch: 17 [12736/60000 (21%)]	Loss: 1.046935
Train Epoch: 17 [19136/60000 (32%)]	Loss: 1.322297
Train Epoch: 17 [25536/60000 (43%)]	Loss: 1.224776
Train Epoch: 17 [31936/60000 (53%)]	Loss: 1.008925
Train Epoch: 17 [38336/60000 (64%)]	Loss: 1.372200
Train Epoch: 17 [44736/60000 (75%)]	Loss: 1.287495
Train Epoch: 17 [51136/60000 (85%)]	Loss: 1.436728
Train Epoch: 17 [57536/60000 (96%)]	Loss: 1.137148

Test set: Average loss: 1.2773, Accuracy: 6043/10000 (60%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 1.278379
Train Epoch: 18 [12736/60000 (21%)]	Loss: 1.352581
Train Epoch: 18 [19136/60000 (32%)]	Loss: 1.357446
Train Epoch: 18 [25536/60000 (43%)]	Loss: 1.317082
Train Epoch: 18 [31936/60000 (53%)]	Loss: 1.209568
Train Epoch: 18 [38336/60000 (64%)]	Loss: 1.339876
Train Epoch: 18 [44736/60000 (75%)]	Loss: 1.283947
Train Epoch: 18 [51136/60000 (85%)]	Loss: 1.291933
Train Epoch: 18 [57536/60000 (96%)]	Loss: 1.314926

Test set: Average loss: 1.2272, Accuracy: 6338/10000 (63%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 1.372698
Train Epoch: 19 [12736/60000 (21%)]	Loss: 1.148860
Train Epoch: 19 [19136/60000 (32%)]	Loss: 1.185772
Train Epoch: 19 [25536/60000 (43%)]	Loss: 1.354388
Train Epoch: 19 [31936/60000 (53%)]	Loss: 1.116506
Train Epoch: 19 [38336/60000 (64%)]	Loss: 1.255758
Train Epoch: 19 [44736/60000 (75%)]	Loss: 1.225906
Train Epoch: 19 [51136/60000 (85%)]	Loss: 1.529866
Train Epoch: 19 [57536/60000 (96%)]	Loss: 1.165339

Test set: Average loss: 1.2473, Accuracy: 6201/10000 (62%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.38 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 4384095
