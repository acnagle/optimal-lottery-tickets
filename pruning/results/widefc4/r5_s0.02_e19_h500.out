Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.434348
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.213677
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.455440
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.205159
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.281525
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.444896
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.154133
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.210653
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.346843

Test set: Average loss: 0.2798, Accuracy: 9135/10000 (91%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.128860
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.285972
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.417466
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.204645
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.375781
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.382767
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.526753
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.309502
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.246793

Test set: Average loss: 0.3856, Accuracy: 8753/10000 (88%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.366712
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.324602
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.290462
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.451239
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.315783
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.728795
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.500851
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.759301
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.510452

Test set: Average loss: 0.5368, Accuracy: 8341/10000 (83%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.242881
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.506102
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.728369
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.690785
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.600117
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.646937
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.738889
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.642176
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.709192

Test set: Average loss: 0.8566, Accuracy: 6914/10000 (69%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.808103
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.744354
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.775877
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.543548
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.740470
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.800786
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.900017
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.895274
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.199152

Test set: Average loss: 0.9212, Accuracy: 7230/10000 (72%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.808634
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.979116
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.110061
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.056161
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.062972
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.020004
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.133477
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.976492
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.046601

Test set: Average loss: 1.0881, Accuracy: 6700/10000 (67%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.175290
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.193187
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.178544
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.173149
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.429619
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.304595
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.303667
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.400857
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.156230

Test set: Average loss: 1.3205, Accuracy: 5791/10000 (58%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.052930
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.295705
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.399903
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.269307
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.319217
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.251529
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.185803
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.360736
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.273041

Test set: Average loss: 1.3284, Accuracy: 6067/10000 (61%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.375773
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.368399
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.326810
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.212825
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.426901
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.319337
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.367109
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.457341
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.575523

Test set: Average loss: 1.4332, Accuracy: 5398/10000 (54%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.556021
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.398669
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.348814
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.498671
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.457664
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.429021
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.507160
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.495719
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.629820

Test set: Average loss: 1.4425, Accuracy: 5628/10000 (56%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.354388
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.436974
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.378759
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.462630
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.384321
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.310795
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.387470
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.516463
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.602771

Test set: Average loss: 1.4699, Accuracy: 5465/10000 (55%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 1.495313
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.428735
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.337150
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.530802
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.540527
Train Epoch: 12 [38336/60000 (64%)]	Loss: 1.513079
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.519823
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.593877
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.500244

Test set: Average loss: 1.5196, Accuracy: 5069/10000 (51%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.503357
Train Epoch: 13 [12736/60000 (21%)]	Loss: 1.360926
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.556886
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.542359
Train Epoch: 13 [31936/60000 (53%)]	Loss: 1.496042
Train Epoch: 13 [38336/60000 (64%)]	Loss: 1.756265
Train Epoch: 13 [44736/60000 (75%)]	Loss: 1.458227
Train Epoch: 13 [51136/60000 (85%)]	Loss: 1.401319
Train Epoch: 13 [57536/60000 (96%)]	Loss: 1.646825

Test set: Average loss: 1.5252, Accuracy: 5176/10000 (52%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.615471
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.548860
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.636047
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.583062
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.569770
Train Epoch: 14 [38336/60000 (64%)]	Loss: 1.535233
Train Epoch: 14 [44736/60000 (75%)]	Loss: 1.518563
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.474598
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.336688

Test set: Average loss: 1.5314, Accuracy: 5120/10000 (51%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 1.578201
Train Epoch: 15 [12736/60000 (21%)]	Loss: 1.604157
Train Epoch: 15 [19136/60000 (32%)]	Loss: 1.232488
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.506664
Train Epoch: 15 [31936/60000 (53%)]	Loss: 1.565513
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.505837
Train Epoch: 15 [44736/60000 (75%)]	Loss: 1.434065
Train Epoch: 15 [51136/60000 (85%)]	Loss: 1.532800
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.525635

Test set: Average loss: 1.5309, Accuracy: 5192/10000 (52%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 1.515663
Train Epoch: 16 [12736/60000 (21%)]	Loss: 1.402400
Train Epoch: 16 [19136/60000 (32%)]	Loss: 1.490217
Train Epoch: 16 [25536/60000 (43%)]	Loss: 1.591032
Train Epoch: 16 [31936/60000 (53%)]	Loss: 1.575155
Train Epoch: 16 [38336/60000 (64%)]	Loss: 1.575585
Train Epoch: 16 [44736/60000 (75%)]	Loss: 1.504394
Train Epoch: 16 [51136/60000 (85%)]	Loss: 1.630665
Train Epoch: 16 [57536/60000 (96%)]	Loss: 1.498775

Test set: Average loss: 1.6184, Accuracy: 4727/10000 (47%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 1.462853
Train Epoch: 17 [12736/60000 (21%)]	Loss: 1.297774
Train Epoch: 17 [19136/60000 (32%)]	Loss: 1.636585
Train Epoch: 17 [25536/60000 (43%)]	Loss: 1.597947
Train Epoch: 17 [31936/60000 (53%)]	Loss: 1.328575
Train Epoch: 17 [38336/60000 (64%)]	Loss: 1.642972
Train Epoch: 17 [44736/60000 (75%)]	Loss: 1.620414
Train Epoch: 17 [51136/60000 (85%)]	Loss: 1.756596
Train Epoch: 17 [57536/60000 (96%)]	Loss: 1.409979

Test set: Average loss: 1.5537, Accuracy: 5044/10000 (50%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 1.614729
Train Epoch: 18 [12736/60000 (21%)]	Loss: 1.600399
Train Epoch: 18 [19136/60000 (32%)]	Loss: 1.662582
Train Epoch: 18 [25536/60000 (43%)]	Loss: 1.601447
Train Epoch: 18 [31936/60000 (53%)]	Loss: 1.479025
Train Epoch: 18 [38336/60000 (64%)]	Loss: 1.563201
Train Epoch: 18 [44736/60000 (75%)]	Loss: 1.519951
Train Epoch: 18 [51136/60000 (85%)]	Loss: 1.564486
Train Epoch: 18 [57536/60000 (96%)]	Loss: 1.614299

Test set: Average loss: 1.5204, Accuracy: 5254/10000 (53%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 1.699173
Train Epoch: 19 [12736/60000 (21%)]	Loss: 1.433186
Train Epoch: 19 [19136/60000 (32%)]	Loss: 1.498119
Train Epoch: 19 [25536/60000 (43%)]	Loss: 1.650869
Train Epoch: 19 [31936/60000 (53%)]	Loss: 1.420210
Train Epoch: 19 [38336/60000 (64%)]	Loss: 1.541130
Train Epoch: 19 [44736/60000 (75%)]	Loss: 1.576738
Train Epoch: 19 [51136/60000 (85%)]	Loss: 1.784398
Train Epoch: 19 [57536/60000 (96%)]	Loss: 1.495482

Test set: Average loss: 1.5366, Accuracy: 5189/10000 (52%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.37 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 4406577
