Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.383277
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.147681
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.411475
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.174934
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.252086
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.377365
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.078369
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.150619
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.109401

Test set: Average loss: 0.2038, Accuracy: 9383/10000 (94%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.081059
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.126169
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.135105
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.142006
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.280160
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.138092
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.316641
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.140926
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.132777

Test set: Average loss: 0.1501, Accuracy: 9523/10000 (95%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.232228
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.094487
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.151139
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.139910
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.121224
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.186757
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.168728
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.086399
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.141406

Test set: Average loss: 0.1857, Accuracy: 9416/10000 (94%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.092673
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.158614
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.125623
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.296034
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.222459
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.321744
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.410690
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.230375
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.153080

Test set: Average loss: 0.1825, Accuracy: 9441/10000 (94%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.181316
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.165667
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.164081
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.273862
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.263908
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.189511
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.264216
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.273969
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.514414

Test set: Average loss: 0.3610, Accuracy: 8822/10000 (88%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.217121
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.390677
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.311052
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.323602
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.291753
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.167638
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.416771
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.248572
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.322062

Test set: Average loss: 0.2838, Accuracy: 9128/10000 (91%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.445851
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.377923
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.466869
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.236443
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.415652
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.257137
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.323310
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.438674
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.360353

Test set: Average loss: 0.3816, Accuracy: 8789/10000 (88%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.266155
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.517481
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.471129
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.271037
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.527061
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.553917
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.545064
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.462004
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.462607

Test set: Average loss: 0.4237, Accuracy: 8632/10000 (86%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.409779
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.381199
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.329847
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.336870
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.586560
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.420513
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.499458
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.498440
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.545886

Test set: Average loss: 0.7376, Accuracy: 7360/10000 (74%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.377571
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.617360
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.675943
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.510184
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.752943
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.341597
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.559934
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.017172
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.398534

Test set: Average loss: 0.4388, Accuracy: 8686/10000 (87%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.372341
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.563367
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.546978
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.519100
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.388529
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.498269
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.412646
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.443906
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.524897

Test set: Average loss: 0.7176, Accuracy: 7637/10000 (76%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.512661
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.449512
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.367367
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.431543
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.897546
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.558702
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.586421
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.637134
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.501980

Test set: Average loss: 0.5369, Accuracy: 8332/10000 (83%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.805172
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.307032
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.489833
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.534118
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.453629
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.497980
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.354284
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.576536
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.593425

Test set: Average loss: 0.4186, Accuracy: 8786/10000 (88%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.623071
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.658733
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.455645
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.641093
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.484732
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.529720
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.484596
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.566229
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.695485

Test set: Average loss: 0.6717, Accuracy: 7788/10000 (78%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.441253
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.458432
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.425204
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.412692
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.591350
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.598311
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.634193
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.775385
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.507512

Test set: Average loss: 0.5173, Accuracy: 8390/10000 (84%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.449448
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.405485
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.503571
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.740939
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.796595
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.489043
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.779578
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.691401
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.435822

Test set: Average loss: 0.8709, Accuracy: 6827/10000 (68%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.440558
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.551004
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.605562
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.412407
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.530157
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.720225
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.590883
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.919689
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.671171

Test set: Average loss: 1.0511, Accuracy: 6562/10000 (66%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.530221
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.551655
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.562761
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.489483
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.510466
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.882505
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.994317
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.613333
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.800544

Test set: Average loss: 0.6518, Accuracy: 7636/10000 (76%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.586149
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.437032
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.617947
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.653113
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.332027
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.556338
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.402177
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.985362
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.409066

Test set: Average loss: 0.7059, Accuracy: 7690/10000 (77%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.38 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 4271682
