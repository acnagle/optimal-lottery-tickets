Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.809920
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.548499
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.609535
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.491973
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.494373
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.408616
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.241437
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.215838
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.226073

Test set: Average loss: 0.2312, Accuracy: 9317/10000 (93%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.099312
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.290703
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.206606
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.177943
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.273767
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.172171
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.248528
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.152334
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.073613

Test set: Average loss: 0.1672, Accuracy: 9484/10000 (95%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.142909
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.106458
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.196614
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.100469
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.071263
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.068012
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.061338
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.054824
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.104971

Test set: Average loss: 0.1080, Accuracy: 9668/10000 (97%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.078846
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.073441
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.030719
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.142521
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.061394
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.130618
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.110467
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.117169
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.045376

Test set: Average loss: 0.0991, Accuracy: 9689/10000 (97%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.113116
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.045308
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.025375
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.142629
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.037541
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.028725
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.206031
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.129818
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.245128

Test set: Average loss: 0.0912, Accuracy: 9719/10000 (97%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.041072
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.071961
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.083937
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.051253
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.115887
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.038662
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.085175
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.056271
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.103024

Test set: Average loss: 0.1114, Accuracy: 9639/10000 (96%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.052961
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.088192
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.073949
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.027937
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.078731
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.098318
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.055001
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.256170
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.090791

Test set: Average loss: 0.0914, Accuracy: 9702/10000 (97%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.067436
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.033678
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.025993
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.086651
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.089784
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.046125
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.010952
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.065629
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.088321

Test set: Average loss: 0.0914, Accuracy: 9692/10000 (97%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.053292
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.036121
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.037890
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.111462
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.083302
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.027031
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.012696
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.097613
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.038581

Test set: Average loss: 0.0972, Accuracy: 9681/10000 (97%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.008533
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.050080
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.016714
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.059516
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.127915
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.013697
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.013347
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.069899
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.088031

Test set: Average loss: 0.0712, Accuracy: 9757/10000 (98%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.018328
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.011141
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.004453
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.018967
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.055686
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.010640
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.021281
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.003150
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.001574

Test set: Average loss: 0.0666, Accuracy: 9794/10000 (98%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.027242
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.014017
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.012816
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.001664
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.003463
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.023495
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.033593
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.024083
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.011270

Test set: Average loss: 0.0610, Accuracy: 9807/10000 (98%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.003691
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.004202
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.004388
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.005516
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.009585
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.018462
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.002083
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.013060
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.001087

Test set: Average loss: 0.0540, Accuracy: 9847/10000 (98%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.000990
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.004612
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.002747
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.003455
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.003743
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.003319
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.006874
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.004412
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.002261

Test set: Average loss: 0.0521, Accuracy: 9851/10000 (99%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.000922
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.003167
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.001336
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.003817
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.010098
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.001014
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.002856
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.002240
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.023680

Test set: Average loss: 0.0512, Accuracy: 9844/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.66 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 449650
