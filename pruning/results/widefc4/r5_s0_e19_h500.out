Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.0, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.890604
Train Epoch: 1 [12736/60000 (21%)]	Loss: 3.306627
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.961906
Train Epoch: 1 [25536/60000 (43%)]	Loss: 3.337920
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.992595
Train Epoch: 1 [38336/60000 (64%)]	Loss: 3.236472
Train Epoch: 1 [44736/60000 (75%)]	Loss: 3.309953
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.902178
Train Epoch: 1 [57536/60000 (96%)]	Loss: 3.050505

Test set: Average loss: 3.1105, Accuracy: 1088/10000 (11%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 3.052861
Train Epoch: 2 [12736/60000 (21%)]	Loss: 3.167525
Train Epoch: 2 [19136/60000 (32%)]	Loss: 2.810747
Train Epoch: 2 [25536/60000 (43%)]	Loss: 3.063129
Train Epoch: 2 [31936/60000 (53%)]	Loss: 3.040724
Train Epoch: 2 [38336/60000 (64%)]	Loss: 3.016094
Train Epoch: 2 [44736/60000 (75%)]	Loss: 3.127393
Train Epoch: 2 [51136/60000 (85%)]	Loss: 3.014799
Train Epoch: 2 [57536/60000 (96%)]	Loss: 2.874671

Test set: Average loss: 3.1119, Accuracy: 1088/10000 (11%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 3.299753
Train Epoch: 3 [12736/60000 (21%)]	Loss: 2.941037
Train Epoch: 3 [19136/60000 (32%)]	Loss: 3.199888
Train Epoch: 3 [25536/60000 (43%)]	Loss: 2.819001
Train Epoch: 3 [31936/60000 (53%)]	Loss: 2.988006
Train Epoch: 3 [38336/60000 (64%)]	Loss: 3.351072
Train Epoch: 3 [44736/60000 (75%)]	Loss: 3.018368
Train Epoch: 3 [51136/60000 (85%)]	Loss: 3.123496
Train Epoch: 3 [57536/60000 (96%)]	Loss: 3.098567

Test set: Average loss: 3.1092, Accuracy: 1088/10000 (11%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 3.356498
Train Epoch: 4 [12736/60000 (21%)]	Loss: 2.877124
Train Epoch: 4 [19136/60000 (32%)]	Loss: 3.136876
Train Epoch: 4 [25536/60000 (43%)]	Loss: 3.502617
Train Epoch: 4 [31936/60000 (53%)]	Loss: 2.675396
Train Epoch: 4 [38336/60000 (64%)]	Loss: 3.246242
Train Epoch: 4 [44736/60000 (75%)]	Loss: 3.121435
Train Epoch: 4 [51136/60000 (85%)]	Loss: 3.030435
Train Epoch: 4 [57536/60000 (96%)]	Loss: 3.119285

Test set: Average loss: 3.1102, Accuracy: 1088/10000 (11%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 3.253878
Train Epoch: 5 [12736/60000 (21%)]	Loss: 2.965487
Train Epoch: 5 [19136/60000 (32%)]	Loss: 3.323240
Train Epoch: 5 [25536/60000 (43%)]	Loss: 3.029007
Train Epoch: 5 [31936/60000 (53%)]	Loss: 3.076811
Train Epoch: 5 [38336/60000 (64%)]	Loss: 3.050129
Train Epoch: 5 [44736/60000 (75%)]	Loss: 2.996722
Train Epoch: 5 [51136/60000 (85%)]	Loss: 3.145604
Train Epoch: 5 [57536/60000 (96%)]	Loss: 3.276089

Test set: Average loss: 3.1103, Accuracy: 1088/10000 (11%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 3.113677
Train Epoch: 6 [12736/60000 (21%)]	Loss: 3.267266
Train Epoch: 6 [19136/60000 (32%)]	Loss: 3.371512
Train Epoch: 6 [25536/60000 (43%)]	Loss: 3.190714
Train Epoch: 6 [31936/60000 (53%)]	Loss: 3.306130
Train Epoch: 6 [38336/60000 (64%)]	Loss: 3.358490
Train Epoch: 6 [44736/60000 (75%)]	Loss: 3.396879
Train Epoch: 6 [51136/60000 (85%)]	Loss: 3.123076
Train Epoch: 6 [57536/60000 (96%)]	Loss: 2.992071

Test set: Average loss: 3.1116, Accuracy: 1088/10000 (11%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 3.179302
Train Epoch: 7 [12736/60000 (21%)]	Loss: 3.187133
Train Epoch: 7 [19136/60000 (32%)]	Loss: 3.349948
Train Epoch: 7 [25536/60000 (43%)]	Loss: 3.379159
Train Epoch: 7 [31936/60000 (53%)]	Loss: 2.990527
Train Epoch: 7 [38336/60000 (64%)]	Loss: 3.295546
Train Epoch: 7 [44736/60000 (75%)]	Loss: 3.134535
Train Epoch: 7 [51136/60000 (85%)]	Loss: 3.161203
Train Epoch: 7 [57536/60000 (96%)]	Loss: 2.949591

Test set: Average loss: 3.1084, Accuracy: 1088/10000 (11%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 3.034835
Train Epoch: 8 [12736/60000 (21%)]	Loss: 3.151002
Train Epoch: 8 [19136/60000 (32%)]	Loss: 3.120466
Train Epoch: 8 [25536/60000 (43%)]	Loss: 2.793351
Train Epoch: 8 [31936/60000 (53%)]	Loss: 2.989094
Train Epoch: 8 [38336/60000 (64%)]	Loss: 2.919614
Train Epoch: 8 [44736/60000 (75%)]	Loss: 2.805399
Train Epoch: 8 [51136/60000 (85%)]	Loss: 3.184379
Train Epoch: 8 [57536/60000 (96%)]	Loss: 3.300290

Test set: Average loss: 3.1093, Accuracy: 1088/10000 (11%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 2.728292
Train Epoch: 9 [12736/60000 (21%)]	Loss: 2.762524
Train Epoch: 9 [19136/60000 (32%)]	Loss: 2.979743
Train Epoch: 9 [25536/60000 (43%)]	Loss: 2.842098
Train Epoch: 9 [31936/60000 (53%)]	Loss: 2.932774
Train Epoch: 9 [38336/60000 (64%)]	Loss: 2.962451
Train Epoch: 9 [44736/60000 (75%)]	Loss: 2.952568
Train Epoch: 9 [51136/60000 (85%)]	Loss: 3.135445
Train Epoch: 9 [57536/60000 (96%)]	Loss: 3.307639

Test set: Average loss: 3.1081, Accuracy: 1088/10000 (11%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 3.171813
Train Epoch: 10 [12736/60000 (21%)]	Loss: 2.881419
Train Epoch: 10 [19136/60000 (32%)]	Loss: 3.255730
Train Epoch: 10 [25536/60000 (43%)]	Loss: 3.223170
Train Epoch: 10 [31936/60000 (53%)]	Loss: 2.891474
Train Epoch: 10 [38336/60000 (64%)]	Loss: 3.077639
Train Epoch: 10 [44736/60000 (75%)]	Loss: 3.210352
Train Epoch: 10 [51136/60000 (85%)]	Loss: 3.111979
Train Epoch: 10 [57536/60000 (96%)]	Loss: 3.283236

Test set: Average loss: 3.1136, Accuracy: 1088/10000 (11%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 2.818173
Train Epoch: 11 [12736/60000 (21%)]	Loss: 3.112475
Train Epoch: 11 [19136/60000 (32%)]	Loss: 3.226396
Train Epoch: 11 [25536/60000 (43%)]	Loss: 3.182768
Train Epoch: 11 [31936/60000 (53%)]	Loss: 3.091532
Train Epoch: 11 [38336/60000 (64%)]	Loss: 2.742217
Train Epoch: 11 [44736/60000 (75%)]	Loss: 3.150518
Train Epoch: 11 [51136/60000 (85%)]	Loss: 3.357259
Train Epoch: 11 [57536/60000 (96%)]	Loss: 3.047930

Test set: Average loss: 3.1111, Accuracy: 1088/10000 (11%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 3.237492
Train Epoch: 12 [12736/60000 (21%)]	Loss: 3.167534
Train Epoch: 12 [19136/60000 (32%)]	Loss: 3.175384
Train Epoch: 12 [25536/60000 (43%)]	Loss: 3.483990
Train Epoch: 12 [31936/60000 (53%)]	Loss: 3.218608
Train Epoch: 12 [38336/60000 (64%)]	Loss: 3.071489
Train Epoch: 12 [44736/60000 (75%)]	Loss: 2.944338
Train Epoch: 12 [51136/60000 (85%)]	Loss: 3.396907
Train Epoch: 12 [57536/60000 (96%)]	Loss: 3.256596

Test set: Average loss: 3.1123, Accuracy: 1088/10000 (11%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 2.977280
Train Epoch: 13 [12736/60000 (21%)]	Loss: 2.956790
Train Epoch: 13 [19136/60000 (32%)]	Loss: 3.168284
Train Epoch: 13 [25536/60000 (43%)]	Loss: 3.178581
Train Epoch: 13 [31936/60000 (53%)]	Loss: 3.341942
Train Epoch: 13 [38336/60000 (64%)]	Loss: 3.418300
Train Epoch: 13 [44736/60000 (75%)]	Loss: 3.089649
Train Epoch: 13 [51136/60000 (85%)]	Loss: 2.941168
Train Epoch: 13 [57536/60000 (96%)]	Loss: 3.279520

Test set: Average loss: 3.1131, Accuracy: 1088/10000 (11%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 3.305424
Train Epoch: 14 [12736/60000 (21%)]	Loss: 2.967428
Train Epoch: 14 [19136/60000 (32%)]	Loss: 3.103388
Train Epoch: 14 [25536/60000 (43%)]	Loss: 3.462707
Train Epoch: 14 [31936/60000 (53%)]	Loss: 3.116115
Train Epoch: 14 [38336/60000 (64%)]	Loss: 2.999681
Train Epoch: 14 [44736/60000 (75%)]	Loss: 3.259124
Train Epoch: 14 [51136/60000 (85%)]	Loss: 3.133180
Train Epoch: 14 [57536/60000 (96%)]	Loss: 3.118049

Test set: Average loss: 3.1107, Accuracy: 1088/10000 (11%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 3.278896
Train Epoch: 15 [12736/60000 (21%)]	Loss: 3.334928
Train Epoch: 15 [19136/60000 (32%)]	Loss: 2.763882
Train Epoch: 15 [25536/60000 (43%)]	Loss: 3.164937
Train Epoch: 15 [31936/60000 (53%)]	Loss: 3.004651
Train Epoch: 15 [38336/60000 (64%)]	Loss: 2.978061
Train Epoch: 15 [44736/60000 (75%)]	Loss: 2.836469
Train Epoch: 15 [51136/60000 (85%)]	Loss: 2.957749
Train Epoch: 15 [57536/60000 (96%)]	Loss: 2.788336

Test set: Average loss: 3.1103, Accuracy: 1088/10000 (11%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 2.962826
Train Epoch: 16 [12736/60000 (21%)]	Loss: 2.934962
Train Epoch: 16 [19136/60000 (32%)]	Loss: 2.984910
Train Epoch: 16 [25536/60000 (43%)]	Loss: 3.317697
Train Epoch: 16 [31936/60000 (53%)]	Loss: 2.760295
Train Epoch: 16 [38336/60000 (64%)]	Loss: 3.180835
Train Epoch: 16 [44736/60000 (75%)]	Loss: 2.989823
Train Epoch: 16 [51136/60000 (85%)]	Loss: 3.283522
Train Epoch: 16 [57536/60000 (96%)]	Loss: 3.086132

Test set: Average loss: 3.1141, Accuracy: 1088/10000 (11%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 2.933061
Train Epoch: 17 [12736/60000 (21%)]	Loss: 2.875865
Train Epoch: 17 [19136/60000 (32%)]	Loss: 3.181155
Train Epoch: 17 [25536/60000 (43%)]	Loss: 3.167340
Train Epoch: 17 [31936/60000 (53%)]	Loss: 2.819300
Train Epoch: 17 [38336/60000 (64%)]	Loss: 3.306871
Train Epoch: 17 [44736/60000 (75%)]	Loss: 3.377458
Train Epoch: 17 [51136/60000 (85%)]	Loss: 3.222284
Train Epoch: 17 [57536/60000 (96%)]	Loss: 2.809873

Test set: Average loss: 3.1141, Accuracy: 1088/10000 (11%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 3.355715
Train Epoch: 18 [12736/60000 (21%)]	Loss: 3.113426
Train Epoch: 18 [19136/60000 (32%)]	Loss: 3.079060
Train Epoch: 18 [25536/60000 (43%)]	Loss: 2.855631
Train Epoch: 18 [31936/60000 (53%)]	Loss: 2.913612
Train Epoch: 18 [38336/60000 (64%)]	Loss: 3.053930
Train Epoch: 18 [44736/60000 (75%)]	Loss: 3.014430
Train Epoch: 18 [51136/60000 (85%)]	Loss: 3.232474
Train Epoch: 18 [57536/60000 (96%)]	Loss: 2.947714

Test set: Average loss: 3.1107, Accuracy: 1088/10000 (11%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 3.161299
Train Epoch: 19 [12736/60000 (21%)]	Loss: 3.088513
Train Epoch: 19 [19136/60000 (32%)]	Loss: 3.181040
Train Epoch: 19 [25536/60000 (43%)]	Loss: 3.225994
Train Epoch: 19 [31936/60000 (53%)]	Loss: 2.929121
Train Epoch: 19 [38336/60000 (64%)]	Loss: 2.982117
Train Epoch: 19 [44736/60000 (75%)]	Loss: 3.298134
Train Epoch: 19 [51136/60000 (85%)]	Loss: 3.261566
Train Epoch: 19 [57536/60000 (96%)]	Loss: 3.150298

Test set: Average loss: 3.1118, Accuracy: 1088/10000 (11%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.0, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.35 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 4496508
