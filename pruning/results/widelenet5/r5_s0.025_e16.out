Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=16, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Pruning a Wide LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.913022
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.648698
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.386873
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.195027
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.141619
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.929965
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.932596
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.918575
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.957327

Test set: Average loss: 0.9901, Accuracy: 8182/10000 (82%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.108460
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.047924
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.101107
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.216258
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.294746
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.202969
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.363403
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.220659
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.147501

Test set: Average loss: 1.3754, Accuracy: 6141/10000 (61%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.416653
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.459027
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.399751
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.559728
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.335286
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.471408
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.481081
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.472386
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.588444

Test set: Average loss: 1.5092, Accuracy: 6514/10000 (65%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.553127
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.537974
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.623744
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.490584
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.677719
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.599941
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.640581
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.794324
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.659236

Test set: Average loss: 1.6815, Accuracy: 4943/10000 (49%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.588805
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.550734
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.675902
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.585515
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.608195
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.794446
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.762106
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.956513
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.789704

Test set: Average loss: 1.7211, Accuracy: 5741/10000 (57%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.727226
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.764877
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.846056
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.761321
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.729635
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.828371
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.703587
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.707154
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.625047

Test set: Average loss: 1.8185, Accuracy: 4270/10000 (43%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.858528
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.815832
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.837691
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.795940
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.837479
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.785242
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.892817
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.836939
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.796940

Test set: Average loss: 1.7951, Accuracy: 5547/10000 (55%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.692605
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.827145
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.755525
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.881265
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.813006
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.831041
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.911735
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.798222
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.820327

Test set: Average loss: 1.8634, Accuracy: 4669/10000 (47%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.898023
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.907659
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.816890
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.951986
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.902813
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.876711
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.875260
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.909891
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.986484

Test set: Average loss: 1.8822, Accuracy: 5170/10000 (52%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.923960
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.920283
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.896120
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.953146
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.903864
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.849833
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.815419
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.893962
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.957596

Test set: Average loss: 1.9370, Accuracy: 4477/10000 (45%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.816888
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.963874
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.985681
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.940170
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.945837
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.948230
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.922939
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.940713
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.928758

Test set: Average loss: 1.9146, Accuracy: 4527/10000 (45%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 1.958162
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.943164
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.946514
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.951749
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.935262
Train Epoch: 12 [38336/60000 (64%)]	Loss: 2.005244
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.919892
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.979428
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.977611

Test set: Average loss: 1.9254, Accuracy: 4587/10000 (46%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.976559
Train Epoch: 13 [12736/60000 (21%)]	Loss: 1.938624
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.801044
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.858280
Train Epoch: 13 [31936/60000 (53%)]	Loss: 2.029583
Train Epoch: 13 [38336/60000 (64%)]	Loss: 1.927574
Train Epoch: 13 [44736/60000 (75%)]	Loss: 1.986213
Train Epoch: 13 [51136/60000 (85%)]	Loss: 1.923169
Train Epoch: 13 [57536/60000 (96%)]	Loss: 2.044956

Test set: Average loss: 1.9448, Accuracy: 4356/10000 (44%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.962193
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.855357
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.925464
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.795015
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.935693
Train Epoch: 14 [38336/60000 (64%)]	Loss: 1.969560
Train Epoch: 14 [44736/60000 (75%)]	Loss: 1.872055
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.882192
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.806848

Test set: Average loss: 1.9402, Accuracy: 4678/10000 (47%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 1.906498
Train Epoch: 15 [12736/60000 (21%)]	Loss: 2.035788
Train Epoch: 15 [19136/60000 (32%)]	Loss: 2.005112
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.893820
Train Epoch: 15 [31936/60000 (53%)]	Loss: 2.018884
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.883773
Train Epoch: 15 [44736/60000 (75%)]	Loss: 1.929047
Train Epoch: 15 [51136/60000 (85%)]	Loss: 1.983863
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.976298

Test set: Average loss: 1.9510, Accuracy: 4217/10000 (42%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 2.037072
Train Epoch: 16 [12736/60000 (21%)]	Loss: 1.979732
Train Epoch: 16 [19136/60000 (32%)]	Loss: 2.019657
Train Epoch: 16 [25536/60000 (43%)]	Loss: 1.860798
Train Epoch: 16 [31936/60000 (53%)]	Loss: 2.006769
Train Epoch: 16 [38336/60000 (64%)]	Loss: 1.874470
Train Epoch: 16 [44736/60000 (75%)]	Loss: 1.924765
Train Epoch: 16 [51136/60000 (85%)]	Loss: 1.903605
Train Epoch: 16 [57536/60000 (96%)]	Loss: 2.009879

Test set: Average loss: 1.9536, Accuracy: 4592/10000 (46%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=16, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.72 minutes
Total number of parameters in model: 300414
Number of parameters in pruned model: 292968
