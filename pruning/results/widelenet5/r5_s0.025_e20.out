Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=20, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Pruning a Wide LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.913022
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.648698
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.386873
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.195027
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.141619
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.929965
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.932596
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.918575
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.957327

Test set: Average loss: 0.9901, Accuracy: 8182/10000 (82%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.091884
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.023105
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.121641
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.228573
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.291456
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.141163
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.334565
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.252428
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.151797

Test set: Average loss: 1.3337, Accuracy: 6591/10000 (66%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.428942
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.444002
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.385588
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.614054
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.331789
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.494105
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.530711
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.428714
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.596334

Test set: Average loss: 1.4908, Accuracy: 6390/10000 (64%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.540904
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.547787
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.608305
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.506847
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.685209
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.594295
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.609073
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.826683
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.682232

Test set: Average loss: 1.6522, Accuracy: 5142/10000 (51%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.605423
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.584859
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.654705
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.596047
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.622336
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.785519
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.749098
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.904656
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.765593

Test set: Average loss: 1.7202, Accuracy: 6093/10000 (61%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.736578
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.782285
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.832539
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.785878
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.741314
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.835733
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.714255
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.719743
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.657701

Test set: Average loss: 1.8571, Accuracy: 3643/10000 (36%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.815756
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.838259
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.878985
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.816234
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.859761
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.819353
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.945178
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.850533
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.831879

Test set: Average loss: 1.8285, Accuracy: 5242/10000 (52%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.739483
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.844851
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.756264
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.927114
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.808613
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.887824
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.965053
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.834199
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.816854

Test set: Average loss: 1.8702, Accuracy: 5068/10000 (51%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.939055
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.942504
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.857933
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.965112
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.932938
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.900802
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.916257
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.911130
Train Epoch: 9 [57536/60000 (96%)]	Loss: 2.015362

Test set: Average loss: 1.9086, Accuracy: 4886/10000 (49%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.944039
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.946152
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.900656
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.926796
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.940986
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.908912
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.863470
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.930642
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.998081

Test set: Average loss: 1.9586, Accuracy: 4427/10000 (44%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.828604
Train Epoch: 11 [12736/60000 (21%)]	Loss: 2.015506
Train Epoch: 11 [19136/60000 (32%)]	Loss: 2.031596
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.963627
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.957332
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.987497
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.981860
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.984663
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.963822

Test set: Average loss: 1.9473, Accuracy: 4195/10000 (42%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 1.958094
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.970169
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.978379
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.986018
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.983039
Train Epoch: 12 [38336/60000 (64%)]	Loss: 2.041354
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.967763
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.999912
Train Epoch: 12 [57536/60000 (96%)]	Loss: 2.003918

Test set: Average loss: 1.9742, Accuracy: 4656/10000 (47%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 2.001271
Train Epoch: 13 [12736/60000 (21%)]	Loss: 1.983297
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.874595
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.909003
Train Epoch: 13 [31936/60000 (53%)]	Loss: 2.068264
Train Epoch: 13 [38336/60000 (64%)]	Loss: 1.974916
Train Epoch: 13 [44736/60000 (75%)]	Loss: 2.007031
Train Epoch: 13 [51136/60000 (85%)]	Loss: 1.970994
Train Epoch: 13 [57536/60000 (96%)]	Loss: 2.075660

Test set: Average loss: 1.9974, Accuracy: 4086/10000 (41%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.987710
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.938569
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.966996
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.845824
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.967697
Train Epoch: 14 [38336/60000 (64%)]	Loss: 2.040696
Train Epoch: 14 [44736/60000 (75%)]	Loss: 1.934675
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.931297
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.865721

Test set: Average loss: 2.0032, Accuracy: 3872/10000 (39%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 1.953356
Train Epoch: 15 [12736/60000 (21%)]	Loss: 2.065382
Train Epoch: 15 [19136/60000 (32%)]	Loss: 2.026245
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.956425
Train Epoch: 15 [31936/60000 (53%)]	Loss: 2.056335
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.970091
Train Epoch: 15 [44736/60000 (75%)]	Loss: 2.013224
Train Epoch: 15 [51136/60000 (85%)]	Loss: 2.069389
Train Epoch: 15 [57536/60000 (96%)]	Loss: 2.038380

Test set: Average loss: 2.0068, Accuracy: 3980/10000 (40%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 2.089872
Train Epoch: 16 [12736/60000 (21%)]	Loss: 2.058674
Train Epoch: 16 [19136/60000 (32%)]	Loss: 2.039758
Train Epoch: 16 [25536/60000 (43%)]	Loss: 1.959194
Train Epoch: 16 [31936/60000 (53%)]	Loss: 2.065437
Train Epoch: 16 [38336/60000 (64%)]	Loss: 1.947692
Train Epoch: 16 [44736/60000 (75%)]	Loss: 2.016300
Train Epoch: 16 [51136/60000 (85%)]	Loss: 1.950884
Train Epoch: 16 [57536/60000 (96%)]	Loss: 2.058641

Test set: Average loss: 2.0037, Accuracy: 4456/10000 (45%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 2.068119
Train Epoch: 17 [12736/60000 (21%)]	Loss: 2.010590
Train Epoch: 17 [19136/60000 (32%)]	Loss: 1.958574
Train Epoch: 17 [25536/60000 (43%)]	Loss: 1.860972
Train Epoch: 17 [31936/60000 (53%)]	Loss: 2.088402
Train Epoch: 17 [38336/60000 (64%)]	Loss: 2.031796
Train Epoch: 17 [44736/60000 (75%)]	Loss: 2.013972
Train Epoch: 17 [51136/60000 (85%)]	Loss: 2.016867
Train Epoch: 17 [57536/60000 (96%)]	Loss: 2.008899

Test set: Average loss: 2.0005, Accuracy: 4410/10000 (44%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 1.922979
Train Epoch: 18 [12736/60000 (21%)]	Loss: 2.079960
Train Epoch: 18 [19136/60000 (32%)]	Loss: 1.988818
Train Epoch: 18 [25536/60000 (43%)]	Loss: 2.010210
Train Epoch: 18 [31936/60000 (53%)]	Loss: 1.946282
Train Epoch: 18 [38336/60000 (64%)]	Loss: 2.014314
Train Epoch: 18 [44736/60000 (75%)]	Loss: 2.050870
Train Epoch: 18 [51136/60000 (85%)]	Loss: 1.970397
Train Epoch: 18 [57536/60000 (96%)]	Loss: 2.049299

Test set: Average loss: 2.0004, Accuracy: 4276/10000 (43%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 2.026609
Train Epoch: 19 [12736/60000 (21%)]	Loss: 2.105727
Train Epoch: 19 [19136/60000 (32%)]	Loss: 1.920548
Train Epoch: 19 [25536/60000 (43%)]	Loss: 1.974253
Train Epoch: 19 [31936/60000 (53%)]	Loss: 2.016276
Train Epoch: 19 [38336/60000 (64%)]	Loss: 2.032593
Train Epoch: 19 [44736/60000 (75%)]	Loss: 1.977521
Train Epoch: 19 [51136/60000 (85%)]	Loss: 2.029600
Train Epoch: 19 [57536/60000 (96%)]	Loss: 1.981020

Test set: Average loss: 2.0234, Accuracy: 4449/10000 (44%)

Train Epoch: 20 [6336/60000 (11%)]	Loss: 1.983560
Train Epoch: 20 [12736/60000 (21%)]	Loss: 2.000237
Train Epoch: 20 [19136/60000 (32%)]	Loss: 1.980314
Train Epoch: 20 [25536/60000 (43%)]	Loss: 2.017920
Train Epoch: 20 [31936/60000 (53%)]	Loss: 1.877366
Train Epoch: 20 [38336/60000 (64%)]	Loss: 1.986352
Train Epoch: 20 [44736/60000 (75%)]	Loss: 1.900750
Train Epoch: 20 [51136/60000 (85%)]	Loss: 2.084141
Train Epoch: 20 [57536/60000 (96%)]	Loss: 1.854618

Test set: Average loss: 2.0119, Accuracy: 4007/10000 (40%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=20, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.14 minutes
Total number of parameters in model: 300414
Number of parameters in pruned model: 292968
