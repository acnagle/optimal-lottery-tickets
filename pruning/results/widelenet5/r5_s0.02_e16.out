Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=16, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Pruning a Wide LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.929791
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.686202
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.429822
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.234510
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.212617
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.099264
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.142983
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.243952
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.275224

Test set: Average loss: 1.3239, Accuracy: 6756/10000 (68%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.409013
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.336154
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.399725
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.558773
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.556565
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.406114
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.652422
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.452515
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.444985

Test set: Average loss: 1.6425, Accuracy: 5142/10000 (51%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.661170
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.715102
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.666709
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.682985
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.606912
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.702471
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.732297
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.711872
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.831647

Test set: Average loss: 1.7386, Accuracy: 5820/10000 (58%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.721558
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.797185
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.878532
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.742516
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.891125
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.763374
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.826756
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.963033
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.855323

Test set: Average loss: 1.8384, Accuracy: 5093/10000 (51%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.809523
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.785364
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.837252
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.786265
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.794532
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.956298
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.987151
Train Epoch: 5 [51136/60000 (85%)]	Loss: 2.055860
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.943755

Test set: Average loss: 1.9179, Accuracy: 5297/10000 (53%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.921949
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.912423
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.966819
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.943554
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.885633
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.972691
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.870851
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.878835
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.821546

Test set: Average loss: 1.9657, Accuracy: 3590/10000 (36%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 2.013229
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.966342
Train Epoch: 7 [19136/60000 (32%)]	Loss: 2.004908
Train Epoch: 7 [25536/60000 (43%)]	Loss: 2.002279
Train Epoch: 7 [31936/60000 (53%)]	Loss: 2.004449
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.947043
Train Epoch: 7 [44736/60000 (75%)]	Loss: 2.098436
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.990861
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.935015

Test set: Average loss: 1.9684, Accuracy: 4691/10000 (47%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.851192
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.988475
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.933756
Train Epoch: 8 [25536/60000 (43%)]	Loss: 2.027009
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.966297
Train Epoch: 8 [38336/60000 (64%)]	Loss: 2.020785
Train Epoch: 8 [44736/60000 (75%)]	Loss: 2.082472
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.970488
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.943544

Test set: Average loss: 2.0118, Accuracy: 4146/10000 (41%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 2.030402
Train Epoch: 9 [12736/60000 (21%)]	Loss: 2.045077
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.979163
Train Epoch: 9 [25536/60000 (43%)]	Loss: 2.060243
Train Epoch: 9 [31936/60000 (53%)]	Loss: 2.068108
Train Epoch: 9 [38336/60000 (64%)]	Loss: 2.018910
Train Epoch: 9 [44736/60000 (75%)]	Loss: 2.051049
Train Epoch: 9 [51136/60000 (85%)]	Loss: 2.064748
Train Epoch: 9 [57536/60000 (96%)]	Loss: 2.123579

Test set: Average loss: 2.0301, Accuracy: 3777/10000 (38%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 2.049023
Train Epoch: 10 [12736/60000 (21%)]	Loss: 2.040658
Train Epoch: 10 [19136/60000 (32%)]	Loss: 2.016946
Train Epoch: 10 [25536/60000 (43%)]	Loss: 2.055068
Train Epoch: 10 [31936/60000 (53%)]	Loss: 2.072713
Train Epoch: 10 [38336/60000 (64%)]	Loss: 2.014763
Train Epoch: 10 [44736/60000 (75%)]	Loss: 2.009234
Train Epoch: 10 [51136/60000 (85%)]	Loss: 2.038303
Train Epoch: 10 [57536/60000 (96%)]	Loss: 2.083582

Test set: Average loss: 2.0313, Accuracy: 4097/10000 (41%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.967091
Train Epoch: 11 [12736/60000 (21%)]	Loss: 2.098599
Train Epoch: 11 [19136/60000 (32%)]	Loss: 2.076925
Train Epoch: 11 [25536/60000 (43%)]	Loss: 2.075266
Train Epoch: 11 [31936/60000 (53%)]	Loss: 2.069742
Train Epoch: 11 [38336/60000 (64%)]	Loss: 2.102644
Train Epoch: 11 [44736/60000 (75%)]	Loss: 2.023605
Train Epoch: 11 [51136/60000 (85%)]	Loss: 2.103623
Train Epoch: 11 [57536/60000 (96%)]	Loss: 2.063675

Test set: Average loss: 2.0756, Accuracy: 3632/10000 (36%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 2.076612
Train Epoch: 12 [12736/60000 (21%)]	Loss: 2.071851
Train Epoch: 12 [19136/60000 (32%)]	Loss: 2.108170
Train Epoch: 12 [25536/60000 (43%)]	Loss: 2.068892
Train Epoch: 12 [31936/60000 (53%)]	Loss: 2.098115
Train Epoch: 12 [38336/60000 (64%)]	Loss: 2.109167
Train Epoch: 12 [44736/60000 (75%)]	Loss: 2.095132
Train Epoch: 12 [51136/60000 (85%)]	Loss: 2.085123
Train Epoch: 12 [57536/60000 (96%)]	Loss: 2.067437

Test set: Average loss: 2.0587, Accuracy: 3541/10000 (35%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 2.100749
Train Epoch: 13 [12736/60000 (21%)]	Loss: 2.055714
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.964575
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.995411
Train Epoch: 13 [31936/60000 (53%)]	Loss: 2.157322
Train Epoch: 13 [38336/60000 (64%)]	Loss: 2.030113
Train Epoch: 13 [44736/60000 (75%)]	Loss: 2.111972
Train Epoch: 13 [51136/60000 (85%)]	Loss: 2.070831
Train Epoch: 13 [57536/60000 (96%)]	Loss: 2.190782

Test set: Average loss: 2.0684, Accuracy: 3379/10000 (34%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 2.058281
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.998698
Train Epoch: 14 [19136/60000 (32%)]	Loss: 2.033418
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.957492
Train Epoch: 14 [31936/60000 (53%)]	Loss: 2.047066
Train Epoch: 14 [38336/60000 (64%)]	Loss: 2.109481
Train Epoch: 14 [44736/60000 (75%)]	Loss: 2.035557
Train Epoch: 14 [51136/60000 (85%)]	Loss: 2.035142
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.974092

Test set: Average loss: 2.0788, Accuracy: 3762/10000 (38%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 2.038696
Train Epoch: 15 [12736/60000 (21%)]	Loss: 2.160463
Train Epoch: 15 [19136/60000 (32%)]	Loss: 2.099926
Train Epoch: 15 [25536/60000 (43%)]	Loss: 2.052393
Train Epoch: 15 [31936/60000 (53%)]	Loss: 2.143164
Train Epoch: 15 [38336/60000 (64%)]	Loss: 2.038926
Train Epoch: 15 [44736/60000 (75%)]	Loss: 2.079625
Train Epoch: 15 [51136/60000 (85%)]	Loss: 2.131030
Train Epoch: 15 [57536/60000 (96%)]	Loss: 2.056059

Test set: Average loss: 2.0998, Accuracy: 3707/10000 (37%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 2.144014
Train Epoch: 16 [12736/60000 (21%)]	Loss: 2.107321
Train Epoch: 16 [19136/60000 (32%)]	Loss: 2.138281
Train Epoch: 16 [25536/60000 (43%)]	Loss: 2.069311
Train Epoch: 16 [31936/60000 (53%)]	Loss: 2.132963
Train Epoch: 16 [38336/60000 (64%)]	Loss: 2.020342
Train Epoch: 16 [44736/60000 (75%)]	Loss: 2.082712
Train Epoch: 16 [51136/60000 (85%)]	Loss: 2.058585
Train Epoch: 16 [57536/60000 (96%)]	Loss: 2.120459

Test set: Average loss: 2.0815, Accuracy: 4081/10000 (41%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=16, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.72 minutes
Total number of parameters in model: 300414
Number of parameters in pruned model: 294457
