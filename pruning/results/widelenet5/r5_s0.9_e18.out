Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=18, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005) 

Pruning a Wide LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.291344
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.285773
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.274248
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.244282
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.238991
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.207306
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.171036
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.150077
Train Epoch: 1 [57536/60000 (96%)]	Loss: 2.069627

Test set: Average loss: 2.0883, Accuracy: 3540/10000 (35%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.032515
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.941738
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.912677
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.835824
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.855961
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.656369
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.720707
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.457281
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.388798

Test set: Average loss: 1.5318, Accuracy: 6286/10000 (63%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.475880
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.442113
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.424155
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.392427
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.208588
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.349576
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.259694
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.128218
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.201528

Test set: Average loss: 1.1674, Accuracy: 7342/10000 (73%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.176133
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.101842
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.142112
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.010790
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.119338
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.062756
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.977720
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.055666
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.986757

Test set: Average loss: 0.9654, Accuracy: 7794/10000 (78%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.854446
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.968876
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.006283
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.805842
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.870633
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.975139
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.914415
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.950100
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.825221

Test set: Average loss: 0.8433, Accuracy: 8082/10000 (81%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.785698
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.943294
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.839549
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.785922
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.676897
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.977989
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.734886
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.706150
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.766094

Test set: Average loss: 0.7599, Accuracy: 8225/10000 (82%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.728336
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.836713
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.808747
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.857254
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.707883
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.744357
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.790794
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.696907
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.740525

Test set: Average loss: 0.7048, Accuracy: 8417/10000 (84%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.671593
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.823132
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.637241
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.758125
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.610653
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.634384
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.872610
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.633944
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.625718

Test set: Average loss: 0.6670, Accuracy: 8473/10000 (85%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.760016
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.705666
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.718471
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.725960
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.622221
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.809629
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.602129
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.682411
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.805955

Test set: Average loss: 0.6357, Accuracy: 8531/10000 (85%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.703474
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.696753
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.663745
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.635235
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.702762
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.536357
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.475872
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.671827
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.637473

Test set: Average loss: 0.6115, Accuracy: 8618/10000 (86%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.576737
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.638323
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.629144
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.668957
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.656063
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.619896
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.716949
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.637552
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.609223

Test set: Average loss: 0.5995, Accuracy: 8620/10000 (86%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.682298
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.545000
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.589570
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.569090
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.548893
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.671755
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.585077
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.619493
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.677051

Test set: Average loss: 0.5891, Accuracy: 8634/10000 (86%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.619363
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.576634
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.483373
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.463425
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.585321
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.636598
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.701534
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.579739
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.664673

Test set: Average loss: 0.5782, Accuracy: 8722/10000 (87%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.572125
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.672205
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.608377
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.568065
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.733445
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.635002
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.406127
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.551835
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.701422

Test set: Average loss: 0.5746, Accuracy: 8685/10000 (87%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.727073
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.538115
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.593900
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.653505
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.519805
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.602429
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.552271
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.548179
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.736734

Test set: Average loss: 0.5713, Accuracy: 8714/10000 (87%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.613327
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.597445
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.648271
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.408798
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.688356
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.461230
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.493376
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.525060
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.502061

Test set: Average loss: 0.5716, Accuracy: 8697/10000 (87%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.582885
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.571477
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.534126
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.487373
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.630001
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.562069
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.605328
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.819371
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.532633

Test set: Average loss: 0.5668, Accuracy: 8752/10000 (88%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.497131
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.590481
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.431780
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.481464
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.553363
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.528378
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.652242
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.531749
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.567838

Test set: Average loss: 0.5685, Accuracy: 8710/10000 (87%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=18, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.93 minutes
Total number of parameters in model: 300414
Number of parameters in pruned model: 32337
