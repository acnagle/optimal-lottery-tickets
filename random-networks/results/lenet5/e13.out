Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.01, model='lenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=False, wd=0.0005) 

Training a LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.684696
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.819046
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.456013
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.296115
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.304187
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.514175
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.357549
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.127115
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.184004

Test set: Average loss: 0.1860, Accuracy: 9430/10000 (94%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.159427
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.191892
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.120324
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.170558
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.219786
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.096134
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.289911
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.200695
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.165145

Test set: Average loss: 0.1331, Accuracy: 9595/10000 (96%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.164313
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.150013
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.129554
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.224767
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.085928
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.088854
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.135228
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.246945
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.096134

Test set: Average loss: 0.1092, Accuracy: 9664/10000 (97%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.059195
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.073173
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.108942
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.096910
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.072889
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.224862
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.271112
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.045518
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.090715

Test set: Average loss: 0.1008, Accuracy: 9689/10000 (97%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.157562
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.037227
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.246201
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.078547
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.112797
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.059317
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.146099
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.050538
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.081066

Test set: Average loss: 0.0940, Accuracy: 9712/10000 (97%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.059854
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.039698
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.032820
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.095938
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.071846
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.054727
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.101769
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.126231
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.140878

Test set: Average loss: 0.0845, Accuracy: 9740/10000 (97%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.124315
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.108707
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.023829
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.095162
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.037025
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.121381
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.058490
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.120964
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.072545

Test set: Average loss: 0.0796, Accuracy: 9756/10000 (98%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.062960
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.054477
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.016971
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.018484
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.097827
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.137488
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.062901
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.056944
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.126857

Test set: Average loss: 0.0762, Accuracy: 9773/10000 (98%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.029780
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.076098
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.044750
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.080478
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.056131
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.122799
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.090095
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.071222
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.043688

Test set: Average loss: 0.0748, Accuracy: 9775/10000 (98%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.076047
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.035347
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.106160
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.024315
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.019411
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.078331
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.044516
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.029935
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.067143

Test set: Average loss: 0.0729, Accuracy: 9779/10000 (98%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.070888
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.007257
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.094099
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.076285
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.028246
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.031618
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.057538
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.050214
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.045969

Test set: Average loss: 0.0709, Accuracy: 9784/10000 (98%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.120619
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.137739
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.174432
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.109248
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.030429
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.104041
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.031533
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.029775
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.138403

Test set: Average loss: 0.0698, Accuracy: 9787/10000 (98%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.031883
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.104972
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.058964
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.074183
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.079652
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.015476
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.065473
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.124574
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.049729

Test set: Average loss: 0.0688, Accuracy: 9787/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.01, model='lenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.64 minutes
Total number of parameters in model: 61470
