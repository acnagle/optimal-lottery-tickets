Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 6.319695
Train Epoch: 1 [12736/60000 (21%)]	Loss: 7.282774
Train Epoch: 1 [19136/60000 (32%)]	Loss: 11.757396
Train Epoch: 1 [25536/60000 (43%)]	Loss: 11.550618
Train Epoch: 1 [31936/60000 (53%)]	Loss: 12.442515
Train Epoch: 1 [38336/60000 (64%)]	Loss: 10.038383
Train Epoch: 1 [44736/60000 (75%)]	Loss: 14.018641
Train Epoch: 1 [51136/60000 (85%)]	Loss: 13.866883
Train Epoch: 1 [57536/60000 (96%)]	Loss: 13.986225

Test set: Average loss: 14.9508, Accuracy: 1055/10000 (11%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 13.518645
Train Epoch: 2 [12736/60000 (21%)]	Loss: 15.426971
Train Epoch: 2 [19136/60000 (32%)]	Loss: 16.700556
Train Epoch: 2 [25536/60000 (43%)]	Loss: 16.998302
Train Epoch: 2 [31936/60000 (53%)]	Loss: 16.909140
Train Epoch: 2 [38336/60000 (64%)]	Loss: 16.667633
Train Epoch: 2 [44736/60000 (75%)]	Loss: 15.089745
Train Epoch: 2 [51136/60000 (85%)]	Loss: 16.268557
Train Epoch: 2 [57536/60000 (96%)]	Loss: 16.795710

Test set: Average loss: 16.3093, Accuracy: 981/10000 (10%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 17.030828
Train Epoch: 3 [12736/60000 (21%)]	Loss: 18.416969
Train Epoch: 3 [19136/60000 (32%)]	Loss: 17.501013
Train Epoch: 3 [25536/60000 (43%)]	Loss: 16.400288
Train Epoch: 3 [31936/60000 (53%)]	Loss: 17.423513
Train Epoch: 3 [38336/60000 (64%)]	Loss: 16.937080
Train Epoch: 3 [44736/60000 (75%)]	Loss: 16.819378
Train Epoch: 3 [51136/60000 (85%)]	Loss: 17.757626
Train Epoch: 3 [57536/60000 (96%)]	Loss: 15.525543

Test set: Average loss: 17.1344, Accuracy: 935/10000 (9%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 17.123940
Train Epoch: 4 [12736/60000 (21%)]	Loss: 17.358761
Train Epoch: 4 [19136/60000 (32%)]	Loss: 15.846662
Train Epoch: 4 [25536/60000 (43%)]	Loss: 19.476780
Train Epoch: 4 [31936/60000 (53%)]	Loss: 15.615330
Train Epoch: 4 [38336/60000 (64%)]	Loss: 15.168008
Train Epoch: 4 [44736/60000 (75%)]	Loss: 16.657820
Train Epoch: 4 [51136/60000 (85%)]	Loss: 15.141554
Train Epoch: 4 [57536/60000 (96%)]	Loss: 16.600109

Test set: Average loss: 17.5361, Accuracy: 941/10000 (9%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 16.692490
Train Epoch: 5 [12736/60000 (21%)]	Loss: 18.242777
Train Epoch: 5 [19136/60000 (32%)]	Loss: 18.108463
Train Epoch: 5 [25536/60000 (43%)]	Loss: 17.859388
Train Epoch: 5 [31936/60000 (53%)]	Loss: 15.079699
Train Epoch: 5 [38336/60000 (64%)]	Loss: 16.593077
Train Epoch: 5 [44736/60000 (75%)]	Loss: 21.310143
Train Epoch: 5 [51136/60000 (85%)]	Loss: 20.229258
Train Epoch: 5 [57536/60000 (96%)]	Loss: 16.550673

Test set: Average loss: 17.5767, Accuracy: 892/10000 (9%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 15.995020
Train Epoch: 6 [12736/60000 (21%)]	Loss: 14.752088
Train Epoch: 6 [19136/60000 (32%)]	Loss: 16.487511
Train Epoch: 6 [25536/60000 (43%)]	Loss: 17.241684
Train Epoch: 6 [31936/60000 (53%)]	Loss: 17.170424
Train Epoch: 6 [38336/60000 (64%)]	Loss: 20.051733
Train Epoch: 6 [44736/60000 (75%)]	Loss: 17.772907
Train Epoch: 6 [51136/60000 (85%)]	Loss: 18.722200
Train Epoch: 6 [57536/60000 (96%)]	Loss: 18.957071

Test set: Average loss: 17.3394, Accuracy: 956/10000 (10%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 17.295616
Train Epoch: 7 [12736/60000 (21%)]	Loss: 16.764582
Train Epoch: 7 [19136/60000 (32%)]	Loss: 15.514025
Train Epoch: 7 [25536/60000 (43%)]	Loss: 16.229248
Train Epoch: 7 [31936/60000 (53%)]	Loss: 13.664092
Train Epoch: 7 [38336/60000 (64%)]	Loss: 18.315010
Train Epoch: 7 [44736/60000 (75%)]	Loss: 16.780088
Train Epoch: 7 [51136/60000 (85%)]	Loss: 16.687368
Train Epoch: 7 [57536/60000 (96%)]	Loss: 15.945028

Test set: Average loss: 17.4928, Accuracy: 935/10000 (9%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 18.463707
Train Epoch: 8 [12736/60000 (21%)]	Loss: 18.518133
Train Epoch: 8 [19136/60000 (32%)]	Loss: 15.011257
Train Epoch: 8 [25536/60000 (43%)]	Loss: 17.748325
Train Epoch: 8 [31936/60000 (53%)]	Loss: 17.387251
Train Epoch: 8 [38336/60000 (64%)]	Loss: 17.070436
Train Epoch: 8 [44736/60000 (75%)]	Loss: 17.663925
Train Epoch: 8 [51136/60000 (85%)]	Loss: 15.907818
Train Epoch: 8 [57536/60000 (96%)]	Loss: 16.677393

Test set: Average loss: 17.4342, Accuracy: 966/10000 (10%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 16.171532
Train Epoch: 9 [12736/60000 (21%)]	Loss: 15.732666
Train Epoch: 9 [19136/60000 (32%)]	Loss: 16.401381
Train Epoch: 9 [25536/60000 (43%)]	Loss: 18.151356
Train Epoch: 9 [31936/60000 (53%)]	Loss: 16.233131
Train Epoch: 9 [38336/60000 (64%)]	Loss: 18.722075
Train Epoch: 9 [44736/60000 (75%)]	Loss: 19.188231
Train Epoch: 9 [51136/60000 (85%)]	Loss: 19.144215
Train Epoch: 9 [57536/60000 (96%)]	Loss: 17.022907

Test set: Average loss: 18.1873, Accuracy: 936/10000 (9%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 17.218605
Train Epoch: 10 [12736/60000 (21%)]	Loss: 15.626563
Train Epoch: 10 [19136/60000 (32%)]	Loss: 18.806276
Train Epoch: 10 [25536/60000 (43%)]	Loss: 18.060551
Train Epoch: 10 [31936/60000 (53%)]	Loss: 19.482386
Train Epoch: 10 [38336/60000 (64%)]	Loss: 18.959183
Train Epoch: 10 [44736/60000 (75%)]	Loss: 17.167814
Train Epoch: 10 [51136/60000 (85%)]	Loss: 19.779818
Train Epoch: 10 [57536/60000 (96%)]	Loss: 17.874931

Test set: Average loss: 17.9457, Accuracy: 948/10000 (9%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 16.552094
Train Epoch: 11 [12736/60000 (21%)]	Loss: 14.878615
Train Epoch: 11 [19136/60000 (32%)]	Loss: 13.434780
Train Epoch: 11 [25536/60000 (43%)]	Loss: 17.711077
Train Epoch: 11 [31936/60000 (53%)]	Loss: 16.309345
Train Epoch: 11 [38336/60000 (64%)]	Loss: 17.290596
Train Epoch: 11 [44736/60000 (75%)]	Loss: 18.877838
Train Epoch: 11 [51136/60000 (85%)]	Loss: 15.426235
Train Epoch: 11 [57536/60000 (96%)]	Loss: 17.421577

Test set: Average loss: 18.2091, Accuracy: 922/10000 (9%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 18.782166
Train Epoch: 12 [12736/60000 (21%)]	Loss: 18.400446
Train Epoch: 12 [19136/60000 (32%)]	Loss: 17.974815
Train Epoch: 12 [25536/60000 (43%)]	Loss: 15.416054
Train Epoch: 12 [31936/60000 (53%)]	Loss: 18.021391
Train Epoch: 12 [38336/60000 (64%)]	Loss: 18.588865
Train Epoch: 12 [44736/60000 (75%)]	Loss: 18.435568
Train Epoch: 12 [51136/60000 (85%)]	Loss: 18.599348
Train Epoch: 12 [57536/60000 (96%)]	Loss: 17.477865

Test set: Average loss: 18.0331, Accuracy: 924/10000 (9%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 17.658518
Train Epoch: 13 [12736/60000 (21%)]	Loss: 20.046970
Train Epoch: 13 [19136/60000 (32%)]	Loss: 17.023893
Train Epoch: 13 [25536/60000 (43%)]	Loss: 18.072569
Train Epoch: 13 [31936/60000 (53%)]	Loss: 18.972401
Train Epoch: 13 [38336/60000 (64%)]	Loss: 18.041008
Train Epoch: 13 [44736/60000 (75%)]	Loss: 15.297409
Train Epoch: 13 [51136/60000 (85%)]	Loss: 19.990110
Train Epoch: 13 [57536/60000 (96%)]	Loss: 17.364786

Test set: Average loss: 17.9495, Accuracy: 933/10000 (9%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 14.969309
Train Epoch: 14 [12736/60000 (21%)]	Loss: 17.666189
Train Epoch: 14 [19136/60000 (32%)]	Loss: 21.116800
Train Epoch: 14 [25536/60000 (43%)]	Loss: 15.673118
Train Epoch: 14 [31936/60000 (53%)]	Loss: 17.603344
Train Epoch: 14 [38336/60000 (64%)]	Loss: 22.203018
Train Epoch: 14 [44736/60000 (75%)]	Loss: 17.173302
Train Epoch: 14 [51136/60000 (85%)]	Loss: 19.385248
Train Epoch: 14 [57536/60000 (96%)]	Loss: 17.760332

Test set: Average loss: 17.7410, Accuracy: 938/10000 (9%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.55 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1971505
