Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.659309
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.421875
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.776607
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.598150
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.630796
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.568500
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.402976
Train Epoch: 1 [51136/60000 (85%)]	Loss: 3.034821
Train Epoch: 1 [57536/60000 (96%)]	Loss: 3.336103

Test set: Average loss: 4.6209, Accuracy: 4382/10000 (44%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 4.564120
Train Epoch: 2 [12736/60000 (21%)]	Loss: 4.711876
Train Epoch: 2 [19136/60000 (32%)]	Loss: 5.460888
Train Epoch: 2 [25536/60000 (43%)]	Loss: 8.079644
Train Epoch: 2 [31936/60000 (53%)]	Loss: 7.639970
Train Epoch: 2 [38336/60000 (64%)]	Loss: 7.596057
Train Epoch: 2 [44736/60000 (75%)]	Loss: 7.681776
Train Epoch: 2 [51136/60000 (85%)]	Loss: 8.804428
Train Epoch: 2 [57536/60000 (96%)]	Loss: 9.400787

Test set: Average loss: 7.5415, Accuracy: 2707/10000 (27%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 8.498998
Train Epoch: 3 [12736/60000 (21%)]	Loss: 10.435194
Train Epoch: 3 [19136/60000 (32%)]	Loss: 10.861414
Train Epoch: 3 [25536/60000 (43%)]	Loss: 9.345228
Train Epoch: 3 [31936/60000 (53%)]	Loss: 10.343106
Train Epoch: 3 [38336/60000 (64%)]	Loss: 11.067767
Train Epoch: 3 [44736/60000 (75%)]	Loss: 10.526727
Train Epoch: 3 [51136/60000 (85%)]	Loss: 11.067349
Train Epoch: 3 [57536/60000 (96%)]	Loss: 10.549721

Test set: Average loss: 11.0252, Accuracy: 1520/10000 (15%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 10.380371
Train Epoch: 4 [12736/60000 (21%)]	Loss: 11.700356
Train Epoch: 4 [19136/60000 (32%)]	Loss: 9.693740
Train Epoch: 4 [25536/60000 (43%)]	Loss: 13.682528
Train Epoch: 4 [31936/60000 (53%)]	Loss: 9.668538
Train Epoch: 4 [38336/60000 (64%)]	Loss: 10.510640
Train Epoch: 4 [44736/60000 (75%)]	Loss: 11.802649
Train Epoch: 4 [51136/60000 (85%)]	Loss: 9.901857
Train Epoch: 4 [57536/60000 (96%)]	Loss: 11.885316

Test set: Average loss: 12.3588, Accuracy: 1391/10000 (14%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 13.098379
Train Epoch: 5 [12736/60000 (21%)]	Loss: 12.210524
Train Epoch: 5 [19136/60000 (32%)]	Loss: 14.002625
Train Epoch: 5 [25536/60000 (43%)]	Loss: 12.353362
Train Epoch: 5 [31936/60000 (53%)]	Loss: 11.273471
Train Epoch: 5 [38336/60000 (64%)]	Loss: 12.235307
Train Epoch: 5 [44736/60000 (75%)]	Loss: 15.720987
Train Epoch: 5 [51136/60000 (85%)]	Loss: 14.800673
Train Epoch: 5 [57536/60000 (96%)]	Loss: 12.964981

Test set: Average loss: 13.0241, Accuracy: 1294/10000 (13%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 12.371376
Train Epoch: 6 [12736/60000 (21%)]	Loss: 11.081267
Train Epoch: 6 [19136/60000 (32%)]	Loss: 11.672351
Train Epoch: 6 [25536/60000 (43%)]	Loss: 12.731472
Train Epoch: 6 [31936/60000 (53%)]	Loss: 13.019839
Train Epoch: 6 [38336/60000 (64%)]	Loss: 15.504692
Train Epoch: 6 [44736/60000 (75%)]	Loss: 14.327372
Train Epoch: 6 [51136/60000 (85%)]	Loss: 13.516119
Train Epoch: 6 [57536/60000 (96%)]	Loss: 15.140302

Test set: Average loss: 13.3123, Accuracy: 1197/10000 (12%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 13.054131
Train Epoch: 7 [12736/60000 (21%)]	Loss: 13.050663
Train Epoch: 7 [19136/60000 (32%)]	Loss: 12.744781
Train Epoch: 7 [25536/60000 (43%)]	Loss: 11.543598
Train Epoch: 7 [31936/60000 (53%)]	Loss: 10.802980
Train Epoch: 7 [38336/60000 (64%)]	Loss: 14.458058
Train Epoch: 7 [44736/60000 (75%)]	Loss: 13.171535
Train Epoch: 7 [51136/60000 (85%)]	Loss: 11.770753
Train Epoch: 7 [57536/60000 (96%)]	Loss: 12.022868

Test set: Average loss: 13.2907, Accuracy: 1235/10000 (12%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 13.362658
Train Epoch: 8 [12736/60000 (21%)]	Loss: 14.269286
Train Epoch: 8 [19136/60000 (32%)]	Loss: 11.538616
Train Epoch: 8 [25536/60000 (43%)]	Loss: 13.175949
Train Epoch: 8 [31936/60000 (53%)]	Loss: 13.884095
Train Epoch: 8 [38336/60000 (64%)]	Loss: 12.699896
Train Epoch: 8 [44736/60000 (75%)]	Loss: 13.904401
Train Epoch: 8 [51136/60000 (85%)]	Loss: 12.380240
Train Epoch: 8 [57536/60000 (96%)]	Loss: 12.213558

Test set: Average loss: 13.2262, Accuracy: 1225/10000 (12%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 12.573059
Train Epoch: 9 [12736/60000 (21%)]	Loss: 11.778263
Train Epoch: 9 [19136/60000 (32%)]	Loss: 12.164034
Train Epoch: 9 [25536/60000 (43%)]	Loss: 13.224722
Train Epoch: 9 [31936/60000 (53%)]	Loss: 12.339255
Train Epoch: 9 [38336/60000 (64%)]	Loss: 13.705821
Train Epoch: 9 [44736/60000 (75%)]	Loss: 14.871604
Train Epoch: 9 [51136/60000 (85%)]	Loss: 14.872105
Train Epoch: 9 [57536/60000 (96%)]	Loss: 12.710979

Test set: Average loss: 13.8066, Accuracy: 1173/10000 (12%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 13.710759
Train Epoch: 10 [12736/60000 (21%)]	Loss: 12.329672
Train Epoch: 10 [19136/60000 (32%)]	Loss: 14.880921
Train Epoch: 10 [25536/60000 (43%)]	Loss: 13.282073
Train Epoch: 10 [31936/60000 (53%)]	Loss: 15.669621
Train Epoch: 10 [38336/60000 (64%)]	Loss: 15.037377
Train Epoch: 10 [44736/60000 (75%)]	Loss: 13.762407
Train Epoch: 10 [51136/60000 (85%)]	Loss: 15.569674
Train Epoch: 10 [57536/60000 (96%)]	Loss: 13.898305

Test set: Average loss: 14.0976, Accuracy: 1149/10000 (11%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 13.119808
Train Epoch: 11 [12736/60000 (21%)]	Loss: 11.139052
Train Epoch: 11 [19136/60000 (32%)]	Loss: 10.767430
Train Epoch: 11 [25536/60000 (43%)]	Loss: 13.600658
Train Epoch: 11 [31936/60000 (53%)]	Loss: 12.144554
Train Epoch: 11 [38336/60000 (64%)]	Loss: 13.544862
Train Epoch: 11 [44736/60000 (75%)]	Loss: 14.213305
Train Epoch: 11 [51136/60000 (85%)]	Loss: 11.842014
Train Epoch: 11 [57536/60000 (96%)]	Loss: 13.076055

Test set: Average loss: 14.1146, Accuracy: 1143/10000 (11%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 15.079664
Train Epoch: 12 [12736/60000 (21%)]	Loss: 15.414775
Train Epoch: 12 [19136/60000 (32%)]	Loss: 13.287478
Train Epoch: 12 [25536/60000 (43%)]	Loss: 12.126040
Train Epoch: 12 [31936/60000 (53%)]	Loss: 13.742100
Train Epoch: 12 [38336/60000 (64%)]	Loss: 14.403889
Train Epoch: 12 [44736/60000 (75%)]	Loss: 14.928192
Train Epoch: 12 [51136/60000 (85%)]	Loss: 13.781535
Train Epoch: 12 [57536/60000 (96%)]	Loss: 12.649300

Test set: Average loss: 14.3779, Accuracy: 1087/10000 (11%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 14.348268
Train Epoch: 13 [12736/60000 (21%)]	Loss: 15.016462
Train Epoch: 13 [19136/60000 (32%)]	Loss: 13.665058
Train Epoch: 13 [25536/60000 (43%)]	Loss: 14.001163
Train Epoch: 13 [31936/60000 (53%)]	Loss: 14.552596
Train Epoch: 13 [38336/60000 (64%)]	Loss: 13.822286
Train Epoch: 13 [44736/60000 (75%)]	Loss: 11.509160
Train Epoch: 13 [51136/60000 (85%)]	Loss: 15.215399
Train Epoch: 13 [57536/60000 (96%)]	Loss: 14.068345

Test set: Average loss: 13.8830, Accuracy: 1151/10000 (12%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 10.820538
Train Epoch: 14 [12736/60000 (21%)]	Loss: 13.200154
Train Epoch: 14 [19136/60000 (32%)]	Loss: 16.207178
Train Epoch: 14 [25536/60000 (43%)]	Loss: 11.922975
Train Epoch: 14 [31936/60000 (53%)]	Loss: 13.178488
Train Epoch: 14 [38336/60000 (64%)]	Loss: 17.740940
Train Epoch: 14 [44736/60000 (75%)]	Loss: 13.153843
Train Epoch: 14 [51136/60000 (85%)]	Loss: 14.854508
Train Epoch: 14 [57536/60000 (96%)]	Loss: 14.506756

Test set: Average loss: 13.5241, Accuracy: 1141/10000 (11%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.53 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1941634
