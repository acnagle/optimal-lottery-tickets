Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.147642
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.262311
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.183369
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.792807
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.409176
Train Epoch: 1 [38336/60000 (64%)]	Loss: 4.080945
Train Epoch: 1 [44736/60000 (75%)]	Loss: 5.067652
Train Epoch: 1 [51136/60000 (85%)]	Loss: 5.304578
Train Epoch: 1 [57536/60000 (96%)]	Loss: 6.211132

Test set: Average loss: 6.7495, Accuracy: 3214/10000 (32%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 6.897604
Train Epoch: 2 [12736/60000 (21%)]	Loss: 8.918853
Train Epoch: 2 [19136/60000 (32%)]	Loss: 9.691381
Train Epoch: 2 [25536/60000 (43%)]	Loss: 10.683319
Train Epoch: 2 [31936/60000 (53%)]	Loss: 11.270259
Train Epoch: 2 [38336/60000 (64%)]	Loss: 11.238601
Train Epoch: 2 [44736/60000 (75%)]	Loss: 10.899401
Train Epoch: 2 [51136/60000 (85%)]	Loss: 11.735864
Train Epoch: 2 [57536/60000 (96%)]	Loss: 12.341001

Test set: Average loss: 11.3443, Accuracy: 1443/10000 (14%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 11.148981
Train Epoch: 3 [12736/60000 (21%)]	Loss: 13.708283
Train Epoch: 3 [19136/60000 (32%)]	Loss: 13.282931
Train Epoch: 3 [25536/60000 (43%)]	Loss: 12.415353
Train Epoch: 3 [31936/60000 (53%)]	Loss: 12.652510
Train Epoch: 3 [38336/60000 (64%)]	Loss: 13.713860
Train Epoch: 3 [44736/60000 (75%)]	Loss: 12.916939
Train Epoch: 3 [51136/60000 (85%)]	Loss: 13.917799
Train Epoch: 3 [57536/60000 (96%)]	Loss: 12.658352

Test set: Average loss: 12.8393, Accuracy: 1294/10000 (13%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 12.681428
Train Epoch: 4 [12736/60000 (21%)]	Loss: 14.436441
Train Epoch: 4 [19136/60000 (32%)]	Loss: 12.525902
Train Epoch: 4 [25536/60000 (43%)]	Loss: 16.542360
Train Epoch: 4 [31936/60000 (53%)]	Loss: 12.136627
Train Epoch: 4 [38336/60000 (64%)]	Loss: 11.848813
Train Epoch: 4 [44736/60000 (75%)]	Loss: 13.893123
Train Epoch: 4 [51136/60000 (85%)]	Loss: 11.587763
Train Epoch: 4 [57536/60000 (96%)]	Loss: 13.787144

Test set: Average loss: 14.2598, Accuracy: 1204/10000 (12%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 14.368305
Train Epoch: 5 [12736/60000 (21%)]	Loss: 14.529199
Train Epoch: 5 [19136/60000 (32%)]	Loss: 14.747169
Train Epoch: 5 [25536/60000 (43%)]	Loss: 14.401369
Train Epoch: 5 [31936/60000 (53%)]	Loss: 13.048141
Train Epoch: 5 [38336/60000 (64%)]	Loss: 13.380288
Train Epoch: 5 [44736/60000 (75%)]	Loss: 17.284830
Train Epoch: 5 [51136/60000 (85%)]	Loss: 16.545942
Train Epoch: 5 [57536/60000 (96%)]	Loss: 14.073141

Test set: Average loss: 14.5664, Accuracy: 1093/10000 (11%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 13.306162
Train Epoch: 6 [12736/60000 (21%)]	Loss: 11.896811
Train Epoch: 6 [19136/60000 (32%)]	Loss: 14.008876
Train Epoch: 6 [25536/60000 (43%)]	Loss: 13.673399
Train Epoch: 6 [31936/60000 (53%)]	Loss: 14.751362
Train Epoch: 6 [38336/60000 (64%)]	Loss: 17.086357
Train Epoch: 6 [44736/60000 (75%)]	Loss: 15.156588
Train Epoch: 6 [51136/60000 (85%)]	Loss: 15.667196
Train Epoch: 6 [57536/60000 (96%)]	Loss: 16.553123

Test set: Average loss: 14.8578, Accuracy: 1084/10000 (11%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 14.998786
Train Epoch: 7 [12736/60000 (21%)]	Loss: 14.175992
Train Epoch: 7 [19136/60000 (32%)]	Loss: 12.928963
Train Epoch: 7 [25536/60000 (43%)]	Loss: 12.797712
Train Epoch: 7 [31936/60000 (53%)]	Loss: 11.756402
Train Epoch: 7 [38336/60000 (64%)]	Loss: 15.273482
Train Epoch: 7 [44736/60000 (75%)]	Loss: 14.065512
Train Epoch: 7 [51136/60000 (85%)]	Loss: 13.838671
Train Epoch: 7 [57536/60000 (96%)]	Loss: 13.365948

Test set: Average loss: 15.2108, Accuracy: 1020/10000 (10%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 15.796771
Train Epoch: 8 [12736/60000 (21%)]	Loss: 15.600799
Train Epoch: 8 [19136/60000 (32%)]	Loss: 13.150017
Train Epoch: 8 [25536/60000 (43%)]	Loss: 15.015437
Train Epoch: 8 [31936/60000 (53%)]	Loss: 15.271425
Train Epoch: 8 [38336/60000 (64%)]	Loss: 13.972337
Train Epoch: 8 [44736/60000 (75%)]	Loss: 14.540391
Train Epoch: 8 [51136/60000 (85%)]	Loss: 13.958383
Train Epoch: 8 [57536/60000 (96%)]	Loss: 13.730136

Test set: Average loss: 15.0390, Accuracy: 1046/10000 (10%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 13.636630
Train Epoch: 9 [12736/60000 (21%)]	Loss: 13.367719
Train Epoch: 9 [19136/60000 (32%)]	Loss: 13.765876
Train Epoch: 9 [25536/60000 (43%)]	Loss: 14.423797
Train Epoch: 9 [31936/60000 (53%)]	Loss: 13.881865
Train Epoch: 9 [38336/60000 (64%)]	Loss: 15.514808
Train Epoch: 9 [44736/60000 (75%)]	Loss: 16.234976
Train Epoch: 9 [51136/60000 (85%)]	Loss: 15.690733
Train Epoch: 9 [57536/60000 (96%)]	Loss: 13.802034

Test set: Average loss: 14.7600, Accuracy: 1084/10000 (11%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 15.329975
Train Epoch: 10 [12736/60000 (21%)]	Loss: 13.155345
Train Epoch: 10 [19136/60000 (32%)]	Loss: 16.099590
Train Epoch: 10 [25536/60000 (43%)]	Loss: 14.249341
Train Epoch: 10 [31936/60000 (53%)]	Loss: 16.721025
Train Epoch: 10 [38336/60000 (64%)]	Loss: 16.062019
Train Epoch: 10 [44736/60000 (75%)]	Loss: 14.195297
Train Epoch: 10 [51136/60000 (85%)]	Loss: 16.797352
Train Epoch: 10 [57536/60000 (96%)]	Loss: 15.552884

Test set: Average loss: 14.8775, Accuracy: 1093/10000 (11%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 14.075545
Train Epoch: 11 [12736/60000 (21%)]	Loss: 12.010971
Train Epoch: 11 [19136/60000 (32%)]	Loss: 11.495457
Train Epoch: 11 [25536/60000 (43%)]	Loss: 14.515768
Train Epoch: 11 [31936/60000 (53%)]	Loss: 13.853932
Train Epoch: 11 [38336/60000 (64%)]	Loss: 14.844019
Train Epoch: 11 [44736/60000 (75%)]	Loss: 16.072054
Train Epoch: 11 [51136/60000 (85%)]	Loss: 12.897985
Train Epoch: 11 [57536/60000 (96%)]	Loss: 14.561917

Test set: Average loss: 15.3749, Accuracy: 1072/10000 (11%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 16.019554
Train Epoch: 12 [12736/60000 (21%)]	Loss: 15.958150
Train Epoch: 12 [19136/60000 (32%)]	Loss: 14.124538
Train Epoch: 12 [25536/60000 (43%)]	Loss: 12.811051
Train Epoch: 12 [31936/60000 (53%)]	Loss: 14.993731
Train Epoch: 12 [38336/60000 (64%)]	Loss: 15.232279
Train Epoch: 12 [44736/60000 (75%)]	Loss: 15.478733
Train Epoch: 12 [51136/60000 (85%)]	Loss: 15.167210
Train Epoch: 12 [57536/60000 (96%)]	Loss: 14.541161

Test set: Average loss: 15.1940, Accuracy: 980/10000 (10%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.34 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1951591
