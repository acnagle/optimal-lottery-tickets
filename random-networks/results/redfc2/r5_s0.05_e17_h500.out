Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.241253
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.863802
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.203591
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.565550
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.517444
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.452271
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.543688
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.464651
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.347895

Test set: Average loss: 0.4721, Accuracy: 8679/10000 (87%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.262651
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.738199
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.357518
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.901361
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.498860
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.969372
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.523728
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.866241
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.763953

Test set: Average loss: 0.9035, Accuracy: 7980/10000 (80%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.019907
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.422308
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.790510
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.326667
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.521306
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.570230
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.764871
Train Epoch: 3 [51136/60000 (85%)]	Loss: 3.056186
Train Epoch: 3 [57536/60000 (96%)]	Loss: 3.036650

Test set: Average loss: 3.5622, Accuracy: 5823/10000 (58%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 2.140550
Train Epoch: 4 [12736/60000 (21%)]	Loss: 3.196301
Train Epoch: 4 [19136/60000 (32%)]	Loss: 2.376110
Train Epoch: 4 [25536/60000 (43%)]	Loss: 3.403476
Train Epoch: 4 [31936/60000 (53%)]	Loss: 3.034766
Train Epoch: 4 [38336/60000 (64%)]	Loss: 3.486507
Train Epoch: 4 [44736/60000 (75%)]	Loss: 3.360711
Train Epoch: 4 [51136/60000 (85%)]	Loss: 2.177000
Train Epoch: 4 [57536/60000 (96%)]	Loss: 3.203002

Test set: Average loss: 3.4927, Accuracy: 5314/10000 (53%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 6.108408
Train Epoch: 5 [12736/60000 (21%)]	Loss: 4.865668
Train Epoch: 5 [19136/60000 (32%)]	Loss: 4.300967
Train Epoch: 5 [25536/60000 (43%)]	Loss: 4.343694
Train Epoch: 5 [31936/60000 (53%)]	Loss: 3.276888
Train Epoch: 5 [38336/60000 (64%)]	Loss: 3.842329
Train Epoch: 5 [44736/60000 (75%)]	Loss: 6.213857
Train Epoch: 5 [51136/60000 (85%)]	Loss: 6.112158
Train Epoch: 5 [57536/60000 (96%)]	Loss: 4.666355

Test set: Average loss: 5.3037, Accuracy: 3957/10000 (40%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 4.742432
Train Epoch: 6 [12736/60000 (21%)]	Loss: 5.549301
Train Epoch: 6 [19136/60000 (32%)]	Loss: 5.337255
Train Epoch: 6 [25536/60000 (43%)]	Loss: 4.010047
Train Epoch: 6 [31936/60000 (53%)]	Loss: 5.788305
Train Epoch: 6 [38336/60000 (64%)]	Loss: 7.189909
Train Epoch: 6 [44736/60000 (75%)]	Loss: 5.681677
Train Epoch: 6 [51136/60000 (85%)]	Loss: 5.195335
Train Epoch: 6 [57536/60000 (96%)]	Loss: 7.239223

Test set: Average loss: 5.5255, Accuracy: 4187/10000 (42%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 5.994648
Train Epoch: 7 [12736/60000 (21%)]	Loss: 5.960259
Train Epoch: 7 [19136/60000 (32%)]	Loss: 5.955737
Train Epoch: 7 [25536/60000 (43%)]	Loss: 4.973546
Train Epoch: 7 [31936/60000 (53%)]	Loss: 5.099688
Train Epoch: 7 [38336/60000 (64%)]	Loss: 7.777706
Train Epoch: 7 [44736/60000 (75%)]	Loss: 5.690491
Train Epoch: 7 [51136/60000 (85%)]	Loss: 6.740178
Train Epoch: 7 [57536/60000 (96%)]	Loss: 5.677522

Test set: Average loss: 6.5867, Accuracy: 3258/10000 (33%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 6.482471
Train Epoch: 8 [12736/60000 (21%)]	Loss: 6.860970
Train Epoch: 8 [19136/60000 (32%)]	Loss: 5.842902
Train Epoch: 8 [25536/60000 (43%)]	Loss: 7.250728
Train Epoch: 8 [31936/60000 (53%)]	Loss: 6.950057
Train Epoch: 8 [38336/60000 (64%)]	Loss: 5.376458
Train Epoch: 8 [44736/60000 (75%)]	Loss: 7.602215
Train Epoch: 8 [51136/60000 (85%)]	Loss: 6.385794
Train Epoch: 8 [57536/60000 (96%)]	Loss: 7.059563

Test set: Average loss: 6.4155, Accuracy: 3250/10000 (32%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 5.837697
Train Epoch: 9 [12736/60000 (21%)]	Loss: 5.634441
Train Epoch: 9 [19136/60000 (32%)]	Loss: 6.024106
Train Epoch: 9 [25536/60000 (43%)]	Loss: 5.826171
Train Epoch: 9 [31936/60000 (53%)]	Loss: 6.693305
Train Epoch: 9 [38336/60000 (64%)]	Loss: 7.740943
Train Epoch: 9 [44736/60000 (75%)]	Loss: 8.278258
Train Epoch: 9 [51136/60000 (85%)]	Loss: 7.850080
Train Epoch: 9 [57536/60000 (96%)]	Loss: 6.236931

Test set: Average loss: 8.0158, Accuracy: 2524/10000 (25%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 7.310275
Train Epoch: 10 [12736/60000 (21%)]	Loss: 5.907380
Train Epoch: 10 [19136/60000 (32%)]	Loss: 8.527465
Train Epoch: 10 [25536/60000 (43%)]	Loss: 6.665059
Train Epoch: 10 [31936/60000 (53%)]	Loss: 7.038000
Train Epoch: 10 [38336/60000 (64%)]	Loss: 8.478909
Train Epoch: 10 [44736/60000 (75%)]	Loss: 6.448552
Train Epoch: 10 [51136/60000 (85%)]	Loss: 8.537646
Train Epoch: 10 [57536/60000 (96%)]	Loss: 9.263287

Test set: Average loss: 7.2828, Accuracy: 2726/10000 (27%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 7.016576
Train Epoch: 11 [12736/60000 (21%)]	Loss: 6.475389
Train Epoch: 11 [19136/60000 (32%)]	Loss: 7.093090
Train Epoch: 11 [25536/60000 (43%)]	Loss: 8.141050
Train Epoch: 11 [31936/60000 (53%)]	Loss: 6.868334
Train Epoch: 11 [38336/60000 (64%)]	Loss: 8.100286
Train Epoch: 11 [44736/60000 (75%)]	Loss: 7.988205
Train Epoch: 11 [51136/60000 (85%)]	Loss: 6.655708
Train Epoch: 11 [57536/60000 (96%)]	Loss: 5.904532

Test set: Average loss: 7.6664, Accuracy: 2905/10000 (29%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 8.618198
Train Epoch: 12 [12736/60000 (21%)]	Loss: 8.972457
Train Epoch: 12 [19136/60000 (32%)]	Loss: 6.950522
Train Epoch: 12 [25536/60000 (43%)]	Loss: 6.755071
Train Epoch: 12 [31936/60000 (53%)]	Loss: 7.093714
Train Epoch: 12 [38336/60000 (64%)]	Loss: 9.153932
Train Epoch: 12 [44736/60000 (75%)]	Loss: 8.082328
Train Epoch: 12 [51136/60000 (85%)]	Loss: 7.464738
Train Epoch: 12 [57536/60000 (96%)]	Loss: 5.414840

Test set: Average loss: 7.9126, Accuracy: 2577/10000 (26%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 8.807742
Train Epoch: 13 [12736/60000 (21%)]	Loss: 8.607526
Train Epoch: 13 [19136/60000 (32%)]	Loss: 6.669888
Train Epoch: 13 [25536/60000 (43%)]	Loss: 7.864804
Train Epoch: 13 [31936/60000 (53%)]	Loss: 7.730587
Train Epoch: 13 [38336/60000 (64%)]	Loss: 7.744639
Train Epoch: 13 [44736/60000 (75%)]	Loss: 5.469817
Train Epoch: 13 [51136/60000 (85%)]	Loss: 8.217981
Train Epoch: 13 [57536/60000 (96%)]	Loss: 8.837873

Test set: Average loss: 8.2492, Accuracy: 2548/10000 (25%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 5.431154
Train Epoch: 14 [12736/60000 (21%)]	Loss: 7.534158
Train Epoch: 14 [19136/60000 (32%)]	Loss: 9.542220
Train Epoch: 14 [25536/60000 (43%)]	Loss: 5.317623
Train Epoch: 14 [31936/60000 (53%)]	Loss: 5.810156
Train Epoch: 14 [38336/60000 (64%)]	Loss: 11.233507
Train Epoch: 14 [44736/60000 (75%)]	Loss: 7.086872
Train Epoch: 14 [51136/60000 (85%)]	Loss: 7.820975
Train Epoch: 14 [57536/60000 (96%)]	Loss: 6.414890

Test set: Average loss: 7.1525, Accuracy: 2669/10000 (27%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 7.661588
Train Epoch: 15 [12736/60000 (21%)]	Loss: 6.463196
Train Epoch: 15 [19136/60000 (32%)]	Loss: 8.561947
Train Epoch: 15 [25536/60000 (43%)]	Loss: 6.735556
Train Epoch: 15 [31936/60000 (53%)]	Loss: 7.434746
Train Epoch: 15 [38336/60000 (64%)]	Loss: 9.393514
Train Epoch: 15 [44736/60000 (75%)]	Loss: 6.614489
Train Epoch: 15 [51136/60000 (85%)]	Loss: 7.434065
Train Epoch: 15 [57536/60000 (96%)]	Loss: 8.571105

Test set: Average loss: 7.6161, Accuracy: 3052/10000 (31%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 6.170500
Train Epoch: 16 [12736/60000 (21%)]	Loss: 6.547905
Train Epoch: 16 [19136/60000 (32%)]	Loss: 5.617976
Train Epoch: 16 [25536/60000 (43%)]	Loss: 7.518711
Train Epoch: 16 [31936/60000 (53%)]	Loss: 7.900994
Train Epoch: 16 [38336/60000 (64%)]	Loss: 8.592870
Train Epoch: 16 [44736/60000 (75%)]	Loss: 9.159924
Train Epoch: 16 [51136/60000 (85%)]	Loss: 6.219320
Train Epoch: 16 [57536/60000 (96%)]	Loss: 7.919488

Test set: Average loss: 7.1729, Accuracy: 2687/10000 (27%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 7.950305
Train Epoch: 17 [12736/60000 (21%)]	Loss: 8.057796
Train Epoch: 17 [19136/60000 (32%)]	Loss: 7.006068
Train Epoch: 17 [25536/60000 (43%)]	Loss: 7.573899
Train Epoch: 17 [31936/60000 (53%)]	Loss: 7.379977
Train Epoch: 17 [38336/60000 (64%)]	Loss: 6.793642
Train Epoch: 17 [44736/60000 (75%)]	Loss: 7.626451
Train Epoch: 17 [51136/60000 (85%)]	Loss: 6.949830
Train Epoch: 17 [57536/60000 (96%)]	Loss: 8.526020

Test set: Average loss: 7.5391, Accuracy: 2592/10000 (26%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.05, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.77 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1891849
