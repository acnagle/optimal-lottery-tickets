Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=True, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.466836
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.572155
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.525000
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.386608
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.340176
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.254994
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.222446
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.171231
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.297344

Test set: Average loss: 0.2921, Accuracy: 9085/10000 (91%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.240297
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.309161
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.125059
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.209879
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.185786
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.297691
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.274835
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.247227
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.359599

Test set: Average loss: 0.2212, Accuracy: 9320/10000 (93%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.152787
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.118608
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.265893
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.222015
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.417306
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.276965
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.231893
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.284782
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.463430

Test set: Average loss: 0.2663, Accuracy: 9175/10000 (92%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.155890
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.466693
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.195063
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.294424
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.419027
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.416748
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.257197
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.185723
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.339393

Test set: Average loss: 0.2664, Accuracy: 9146/10000 (91%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.329658
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.229240
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.303315
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.276777
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.210839
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.343165
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.181382
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.352339
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.391755

Test set: Average loss: 0.2565, Accuracy: 9194/10000 (92%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.294115
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.231140
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.162994
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.159225
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.222226
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.253183
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.140024
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.257065
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.328422

Test set: Average loss: 0.3233, Accuracy: 8970/10000 (90%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.233540
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.288954
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.252926
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.293156
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.151413
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.255039
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.386618
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.269341
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.318999

Test set: Average loss: 0.3286, Accuracy: 8935/10000 (89%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.440372
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.189294
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.414832
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.384605
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.381849
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.197596
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.569800
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.282210
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.419613

Test set: Average loss: 0.3039, Accuracy: 9014/10000 (90%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.254823
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.236891
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.292781
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.301829
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.280594
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.253036
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.255110
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.768231
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.295732

Test set: Average loss: 0.3573, Accuracy: 8911/10000 (89%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.313352
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.316009
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.151635
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.241995
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.288361
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.316272
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.271002
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.394630
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.440446

Test set: Average loss: 0.2884, Accuracy: 9134/10000 (91%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.199130
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.262511
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.100096
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.294247
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.307670
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.184328
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.237317
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.264903
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.204735

Test set: Average loss: 0.2459, Accuracy: 9221/10000 (92%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.153838
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.168077
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.193415
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.079260
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.122388
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.159976
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.241253
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.144105
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.131132

Test set: Average loss: 0.1826, Accuracy: 9437/10000 (94%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.057058
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.125803
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.236925
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.092284
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.153190
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.272684
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.048055
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.185270
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.063046

Test set: Average loss: 0.1257, Accuracy: 9592/10000 (96%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=13, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.43 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1792278
