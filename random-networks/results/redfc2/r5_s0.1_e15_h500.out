Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.714665
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.521458
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.961602
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.457438
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.356019
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.245949
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.198593
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.100592
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.192516

Test set: Average loss: 0.2620, Accuracy: 9226/10000 (92%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.108918
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.442845
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.124052
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.242528
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.259596
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.330055
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.245099
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.291627
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.421045

Test set: Average loss: 0.2759, Accuracy: 9219/10000 (92%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.153910
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.315826
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.507435
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.381959
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.509253
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.254926
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.649123
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.336426
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.574192

Test set: Average loss: 0.3220, Accuracy: 9034/10000 (90%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.217985
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.608878
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.196045
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.447056
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.358920
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.463598
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.305048
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.429278
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.302056

Test set: Average loss: 0.4265, Accuracy: 8759/10000 (88%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.522142
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.275727
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.298369
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.550322
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.408530
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.441558
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.122575
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.679070
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.353646

Test set: Average loss: 0.4303, Accuracy: 8672/10000 (87%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.496770
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.403021
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.350511
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.177728
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.492472
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.556701
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.821109
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.649914
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.450065

Test set: Average loss: 0.7250, Accuracy: 7978/10000 (80%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.729243
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.088577
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.901092
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.637036
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.993934
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.790165
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.743501
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.692916
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.720368

Test set: Average loss: 1.2833, Accuracy: 7194/10000 (72%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.214265
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.144496
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.586937
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.404228
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.910154
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.515422
Train Epoch: 8 [44736/60000 (75%)]	Loss: 2.019635
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.712181
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.805924

Test set: Average loss: 1.6470, Accuracy: 7148/10000 (71%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.643210
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.725470
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.813607
Train Epoch: 9 [25536/60000 (43%)]	Loss: 2.103569
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.439288
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.877391
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.303393
Train Epoch: 9 [51136/60000 (85%)]	Loss: 2.408338
Train Epoch: 9 [57536/60000 (96%)]	Loss: 2.241342

Test set: Average loss: 2.0635, Accuracy: 6454/10000 (65%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 2.310774
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.153086
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.558958
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.965544
Train Epoch: 10 [31936/60000 (53%)]	Loss: 2.347016
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.549255
Train Epoch: 10 [44736/60000 (75%)]	Loss: 2.005012
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.394110
Train Epoch: 10 [57536/60000 (96%)]	Loss: 2.709692

Test set: Average loss: 1.8818, Accuracy: 6924/10000 (69%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.408060
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.575659
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.909166
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.902796
Train Epoch: 11 [31936/60000 (53%)]	Loss: 2.392641
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.387520
Train Epoch: 11 [44736/60000 (75%)]	Loss: 2.892481
Train Epoch: 11 [51136/60000 (85%)]	Loss: 2.388771
Train Epoch: 11 [57536/60000 (96%)]	Loss: 2.400856

Test set: Average loss: 1.6098, Accuracy: 7217/10000 (72%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 2.520583
Train Epoch: 12 [12736/60000 (21%)]	Loss: 2.086073
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.981278
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.531407
Train Epoch: 12 [31936/60000 (53%)]	Loss: 2.156910
Train Epoch: 12 [38336/60000 (64%)]	Loss: 3.259525
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.431380
Train Epoch: 12 [51136/60000 (85%)]	Loss: 2.144649
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.766006

Test set: Average loss: 1.8744, Accuracy: 6914/10000 (69%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.358665
Train Epoch: 13 [12736/60000 (21%)]	Loss: 2.417916
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.805830
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.447502
Train Epoch: 13 [31936/60000 (53%)]	Loss: 2.052880
Train Epoch: 13 [38336/60000 (64%)]	Loss: 2.329673
Train Epoch: 13 [44736/60000 (75%)]	Loss: 1.195378
Train Epoch: 13 [51136/60000 (85%)]	Loss: 2.581918
Train Epoch: 13 [57536/60000 (96%)]	Loss: 2.565040

Test set: Average loss: 2.1227, Accuracy: 6507/10000 (65%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.122025
Train Epoch: 14 [12736/60000 (21%)]	Loss: 2.484551
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.674875
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.219380
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.690654
Train Epoch: 14 [38336/60000 (64%)]	Loss: 2.189651
Train Epoch: 14 [44736/60000 (75%)]	Loss: 2.318660
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.776674
Train Epoch: 14 [57536/60000 (96%)]	Loss: 2.163353

Test set: Average loss: 1.5970, Accuracy: 7303/10000 (73%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.417138
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.770396
Train Epoch: 15 [19136/60000 (32%)]	Loss: 1.227338
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.671269
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.584209
Train Epoch: 15 [38336/60000 (64%)]	Loss: 2.760457
Train Epoch: 15 [44736/60000 (75%)]	Loss: 1.841286
Train Epoch: 15 [51136/60000 (85%)]	Loss: 3.328057
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.049466

Test set: Average loss: 2.5109, Accuracy: 6273/10000 (63%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=15, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.62 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 1792278
