Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.95, use_relu=False, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.688149
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.259782
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.977365
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.930581
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.803980
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.693814
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.697378
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.529352
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.710539

Test set: Average loss: 0.5731, Accuracy: 8420/10000 (84%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.558187
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.576064
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.543837
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.640408
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.592809
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.486137
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.521475
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.586815
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.567282

Test set: Average loss: 0.4886, Accuracy: 8635/10000 (86%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.399557
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.546072
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.578759
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.574496
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.510115
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.505916
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.629342
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.510789
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.639802

Test set: Average loss: 0.4758, Accuracy: 8666/10000 (87%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.431529
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.619099
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.421511
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.561528
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.611584
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.580141
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.547562
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.339954
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.635574

Test set: Average loss: 0.5066, Accuracy: 8553/10000 (86%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.616942
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.527019
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.352206
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.529715
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.400984
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.579129
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.495399
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.583204
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.505908

Test set: Average loss: 0.4882, Accuracy: 8596/10000 (86%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.560160
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.518347
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.479593
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.402212
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.406592
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.484727
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.397945
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.421676
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.573148

Test set: Average loss: 0.5122, Accuracy: 8466/10000 (85%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.417731
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.469998
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.436751
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.456726
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.418853
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.594065
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.540921
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.616568
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.454424

Test set: Average loss: 0.5432, Accuracy: 8411/10000 (84%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.758916
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.486145
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.634428
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.621399
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.641964
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.409715
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.863358
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.689653
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.514948

Test set: Average loss: 0.4965, Accuracy: 8603/10000 (86%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.435467
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.542940
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.513352
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.633853
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.391526
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.554516
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.456450
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.745936
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.565865

Test set: Average loss: 0.4930, Accuracy: 8572/10000 (86%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.644120
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.528355
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.457297
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.518881
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.430988
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.481171
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.610167
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.512873
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.586031

Test set: Average loss: 0.4739, Accuracy: 8726/10000 (87%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.475873
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.451242
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.428499
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.493092
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.588470
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.465538
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.418347
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.426447
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.446861

Test set: Average loss: 0.4767, Accuracy: 8612/10000 (86%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.396542
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.480428
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.494811
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.379086
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.414574
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.598451
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.408662
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.441624
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.315585

Test set: Average loss: 0.4386, Accuracy: 8768/10000 (88%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.377113
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.366395
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.433387
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.445613
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.535760
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.543041
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.243135
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.457553
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.409573

Test set: Average loss: 0.3904, Accuracy: 8928/10000 (89%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.297455
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.499191
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.348353
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.273570
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.242944
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.383021
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.399649
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.424236
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.466744

Test set: Average loss: 0.3813, Accuracy: 8941/10000 (89%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.95, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.52 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 99571
