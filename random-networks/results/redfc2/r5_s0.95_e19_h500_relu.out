Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.95, use_relu=True, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.172361
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.119385
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.997468
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.983955
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.959943
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.908838
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.930964
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.874552
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.870148

Test set: Average loss: 1.8692, Accuracy: 5038/10000 (50%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.933042
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.842583
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.890503
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.952568
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.878803
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.910185
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.825011
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.882255
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.819729

Test set: Average loss: 1.8370, Accuracy: 5322/10000 (53%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.807551
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.809113
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.932768
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.751219
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.815686
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.838566
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.904278
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.805338
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.818294

Test set: Average loss: 1.8267, Accuracy: 5722/10000 (57%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.826255
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.803540
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.839186
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.860088
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.811394
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.855070
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.812428
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.772490
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.914371

Test set: Average loss: 1.8402, Accuracy: 5310/10000 (53%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.832459
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.842750
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.763879
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.878083
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.806154
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.884256
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.851642
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.795123
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.875569

Test set: Average loss: 1.8313, Accuracy: 5470/10000 (55%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.799688
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.851306
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.840298
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.785113
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.795078
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.807461
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.836961
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.827451
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.760603

Test set: Average loss: 1.8317, Accuracy: 5481/10000 (55%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.819592
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.878604
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.849381
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.931659
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.762913
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.864400
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.881947
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.886377
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.831880

Test set: Average loss: 1.8613, Accuracy: 5311/10000 (53%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.916958
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.946664
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.872957
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.882838
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.898766
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.813031
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.885977
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.908253
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.892819

Test set: Average loss: 1.8701, Accuracy: 4971/10000 (50%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.858640
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.869795
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.871629
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.912922
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.834473
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.916863
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.905379
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.945871
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.858615

Test set: Average loss: 1.8809, Accuracy: 4931/10000 (49%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.855144
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.852441
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.932350
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.950046
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.914939
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.936017
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.900787
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.861080
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.965530

Test set: Average loss: 1.8646, Accuracy: 4782/10000 (48%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.918464
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.825366
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.851336
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.911902
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.925458
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.857666
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.948413
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.839923
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.862179

Test set: Average loss: 1.8946, Accuracy: 4926/10000 (49%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 1.916242
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.911107
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.919226
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.834985
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.901631
Train Epoch: 12 [38336/60000 (64%)]	Loss: 1.915352
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.837307
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.903366
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.857083

Test set: Average loss: 1.8506, Accuracy: 5059/10000 (51%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.965939
Train Epoch: 13 [12736/60000 (21%)]	Loss: 1.896535
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.809740
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.828161
Train Epoch: 13 [31936/60000 (53%)]	Loss: 1.899382
Train Epoch: 13 [38336/60000 (64%)]	Loss: 1.874121
Train Epoch: 13 [44736/60000 (75%)]	Loss: 1.804147
Train Epoch: 13 [51136/60000 (85%)]	Loss: 1.854177
Train Epoch: 13 [57536/60000 (96%)]	Loss: 1.876550

Test set: Average loss: 1.8808, Accuracy: 4852/10000 (49%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.845636
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.881832
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.870862
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.785759
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.832323
Train Epoch: 14 [38336/60000 (64%)]	Loss: 1.845084
Train Epoch: 14 [44736/60000 (75%)]	Loss: 1.909386
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.905251
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.919893

Test set: Average loss: 1.8514, Accuracy: 5166/10000 (52%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 1.852850
Train Epoch: 15 [12736/60000 (21%)]	Loss: 1.824874
Train Epoch: 15 [19136/60000 (32%)]	Loss: 1.738341
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.824944
Train Epoch: 15 [31936/60000 (53%)]	Loss: 1.799782
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.842355
Train Epoch: 15 [44736/60000 (75%)]	Loss: 1.810838
Train Epoch: 15 [51136/60000 (85%)]	Loss: 1.894962
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.834045

Test set: Average loss: 1.8177, Accuracy: 5097/10000 (51%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 1.818652
Train Epoch: 16 [12736/60000 (21%)]	Loss: 1.815125
Train Epoch: 16 [19136/60000 (32%)]	Loss: 1.786692
Train Epoch: 16 [25536/60000 (43%)]	Loss: 1.817435
Train Epoch: 16 [31936/60000 (53%)]	Loss: 1.798421
Train Epoch: 16 [38336/60000 (64%)]	Loss: 1.837626
Train Epoch: 16 [44736/60000 (75%)]	Loss: 1.787149
Train Epoch: 16 [51136/60000 (85%)]	Loss: 1.768119
Train Epoch: 16 [57536/60000 (96%)]	Loss: 1.805326

Test set: Average loss: 1.7999, Accuracy: 5610/10000 (56%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 1.781790
Train Epoch: 17 [12736/60000 (21%)]	Loss: 1.823974
Train Epoch: 17 [19136/60000 (32%)]	Loss: 1.770576
Train Epoch: 17 [25536/60000 (43%)]	Loss: 1.761055
Train Epoch: 17 [31936/60000 (53%)]	Loss: 1.805018
Train Epoch: 17 [38336/60000 (64%)]	Loss: 1.758905
Train Epoch: 17 [44736/60000 (75%)]	Loss: 1.781646
Train Epoch: 17 [51136/60000 (85%)]	Loss: 1.785180
Train Epoch: 17 [57536/60000 (96%)]	Loss: 1.897486

Test set: Average loss: 1.7880, Accuracy: 5196/10000 (52%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 1.743556
Train Epoch: 18 [12736/60000 (21%)]	Loss: 1.715808
Train Epoch: 18 [19136/60000 (32%)]	Loss: 1.763439
Train Epoch: 18 [25536/60000 (43%)]	Loss: 1.744472
Train Epoch: 18 [31936/60000 (53%)]	Loss: 1.694705
Train Epoch: 18 [38336/60000 (64%)]	Loss: 1.783974
Train Epoch: 18 [44736/60000 (75%)]	Loss: 1.752011
Train Epoch: 18 [51136/60000 (85%)]	Loss: 1.780301
Train Epoch: 18 [57536/60000 (96%)]	Loss: 1.701938

Test set: Average loss: 1.7611, Accuracy: 5614/10000 (56%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 1.678533
Train Epoch: 19 [12736/60000 (21%)]	Loss: 1.698474
Train Epoch: 19 [19136/60000 (32%)]	Loss: 1.788327
Train Epoch: 19 [25536/60000 (43%)]	Loss: 1.727101
Train Epoch: 19 [31936/60000 (53%)]	Loss: 1.705336
Train Epoch: 19 [38336/60000 (64%)]	Loss: 1.727575
Train Epoch: 19 [44736/60000 (75%)]	Loss: 1.729458
Train Epoch: 19 [51136/60000 (85%)]	Loss: 1.819672
Train Epoch: 19 [57536/60000 (96%)]	Loss: 1.732802

Test set: Average loss: 1.7595, Accuracy: 5864/10000 (59%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.95, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.99 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 99571
