Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=11, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=True, wd=0.0005) 

Pruning a Two-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.659353
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.427297
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.388729
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.330133
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.270936
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.301834
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.206731
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.221573
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.199756

Test set: Average loss: 1.1385, Accuracy: 7013/10000 (70%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.102908
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.091951
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.170099
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.295442
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.100664
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.111832
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.053529
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.157879
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.096638

Test set: Average loss: 1.0187, Accuracy: 7563/10000 (76%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.010304
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.958192
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.103825
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.021118
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.976291
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.018799
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.106452
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.039109
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.079278

Test set: Average loss: 1.0195, Accuracy: 7744/10000 (77%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.967324
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.067957
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.053649
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.112400
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.185451
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.095721
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.058841
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.951447
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.171063

Test set: Average loss: 1.0337, Accuracy: 7520/10000 (75%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.072923
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.018334
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.976885
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.130460
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.949266
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.152570
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.009859
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.166657
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.090116

Test set: Average loss: 1.0588, Accuracy: 7125/10000 (71%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.082555
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.109187
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.158190
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.972702
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.925779
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.975436
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.939782
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.962467
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.992003

Test set: Average loss: 1.0681, Accuracy: 7231/10000 (72%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.026433
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.025488
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.002881
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.099067
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.943412
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.093938
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.221397
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.053559
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.959797

Test set: Average loss: 1.0135, Accuracy: 7499/10000 (75%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.217304
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.983355
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.093164
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.043137
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.148218
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.863986
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.173116
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.036697
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.066990

Test set: Average loss: 0.9954, Accuracy: 7648/10000 (76%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.975234
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.065311
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.992471
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.990703
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.947881
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.054639
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.047884
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.219506
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.004625

Test set: Average loss: 0.9731, Accuracy: 7808/10000 (78%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.022046
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.972013
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.938889
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.060167
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.046209
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.073999
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.074618
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.907012
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.115575

Test set: Average loss: 0.9604, Accuracy: 7881/10000 (79%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.944535
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.900839
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.948064
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.972556
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.213215
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.905762
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.958506
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.910453
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.916054

Test set: Average loss: 0.9533, Accuracy: 7930/10000 (79%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=11, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.21 minutes
Total number of parameters in model: 1991420
Number of parameters in pruned model: 199141
