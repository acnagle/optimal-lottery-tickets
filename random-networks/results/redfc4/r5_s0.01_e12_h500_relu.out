Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 4.100196
Train Epoch: 1 [12736/60000 (21%)]	Loss: 6.280535
Train Epoch: 1 [19136/60000 (32%)]	Loss: 8.182125
Train Epoch: 1 [25536/60000 (43%)]	Loss: 11.816093
Train Epoch: 1 [31936/60000 (53%)]	Loss: 9.195341
Train Epoch: 1 [38336/60000 (64%)]	Loss: 10.442177
Train Epoch: 1 [44736/60000 (75%)]	Loss: 14.871454
Train Epoch: 1 [51136/60000 (85%)]	Loss: 17.012016
Train Epoch: 1 [57536/60000 (96%)]	Loss: 19.724110

Test set: Average loss: 18.5289, Accuracy: 2239/10000 (22%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 18.174192
Train Epoch: 2 [12736/60000 (21%)]	Loss: 21.794338
Train Epoch: 2 [19136/60000 (32%)]	Loss: 23.977961
Train Epoch: 2 [25536/60000 (43%)]	Loss: 22.181154
Train Epoch: 2 [31936/60000 (53%)]	Loss: 22.001268
Train Epoch: 2 [38336/60000 (64%)]	Loss: 23.238478
Train Epoch: 2 [44736/60000 (75%)]	Loss: 26.675982
Train Epoch: 2 [51136/60000 (85%)]	Loss: 25.564312
Train Epoch: 2 [57536/60000 (96%)]	Loss: 25.048798

Test set: Average loss: 26.7085, Accuracy: 1693/10000 (17%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 21.441067
Train Epoch: 3 [12736/60000 (21%)]	Loss: 26.190798
Train Epoch: 3 [19136/60000 (32%)]	Loss: 24.115152
Train Epoch: 3 [25536/60000 (43%)]	Loss: 24.532156
Train Epoch: 3 [31936/60000 (53%)]	Loss: 28.744267
Train Epoch: 3 [38336/60000 (64%)]	Loss: 30.964472
Train Epoch: 3 [44736/60000 (75%)]	Loss: 26.914288
Train Epoch: 3 [51136/60000 (85%)]	Loss: 23.471260
Train Epoch: 3 [57536/60000 (96%)]	Loss: 28.934544

Test set: Average loss: 30.0486, Accuracy: 1507/10000 (15%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 26.619953
Train Epoch: 4 [12736/60000 (21%)]	Loss: 32.523872
Train Epoch: 4 [19136/60000 (32%)]	Loss: 33.312862
Train Epoch: 4 [25536/60000 (43%)]	Loss: 32.026722
Train Epoch: 4 [31936/60000 (53%)]	Loss: 32.890423
Train Epoch: 4 [38336/60000 (64%)]	Loss: 27.655548
Train Epoch: 4 [44736/60000 (75%)]	Loss: 30.692184
Train Epoch: 4 [51136/60000 (85%)]	Loss: 25.736881
Train Epoch: 4 [57536/60000 (96%)]	Loss: 22.697859

Test set: Average loss: 31.1423, Accuracy: 1532/10000 (15%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 32.510826
Train Epoch: 5 [12736/60000 (21%)]	Loss: 27.942451
Train Epoch: 5 [19136/60000 (32%)]	Loss: 28.931461
Train Epoch: 5 [25536/60000 (43%)]	Loss: 29.452417
Train Epoch: 5 [31936/60000 (53%)]	Loss: 31.416721
Train Epoch: 5 [38336/60000 (64%)]	Loss: 28.967939
Train Epoch: 5 [44736/60000 (75%)]	Loss: 33.685184
Train Epoch: 5 [51136/60000 (85%)]	Loss: 30.770702
Train Epoch: 5 [57536/60000 (96%)]	Loss: 35.336979

Test set: Average loss: 31.9553, Accuracy: 1463/10000 (15%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 31.218725
Train Epoch: 6 [12736/60000 (21%)]	Loss: 34.084110
Train Epoch: 6 [19136/60000 (32%)]	Loss: 33.684212
Train Epoch: 6 [25536/60000 (43%)]	Loss: 28.364357
Train Epoch: 6 [31936/60000 (53%)]	Loss: 31.943310
Train Epoch: 6 [38336/60000 (64%)]	Loss: 30.762594
Train Epoch: 6 [44736/60000 (75%)]	Loss: 36.478008
Train Epoch: 6 [51136/60000 (85%)]	Loss: 35.002499
Train Epoch: 6 [57536/60000 (96%)]	Loss: 36.045338

Test set: Average loss: 32.9317, Accuracy: 1461/10000 (15%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 31.295567
Train Epoch: 7 [12736/60000 (21%)]	Loss: 26.786575
Train Epoch: 7 [19136/60000 (32%)]	Loss: 30.209599
Train Epoch: 7 [25536/60000 (43%)]	Loss: 32.990650
Train Epoch: 7 [31936/60000 (53%)]	Loss: 39.118477
Train Epoch: 7 [38336/60000 (64%)]	Loss: 30.700264
Train Epoch: 7 [44736/60000 (75%)]	Loss: 34.521523
Train Epoch: 7 [51136/60000 (85%)]	Loss: 31.298853
Train Epoch: 7 [57536/60000 (96%)]	Loss: 32.778828

Test set: Average loss: 32.7094, Accuracy: 1430/10000 (14%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 35.970833
Train Epoch: 8 [12736/60000 (21%)]	Loss: 25.639585
Train Epoch: 8 [19136/60000 (32%)]	Loss: 34.569366
Train Epoch: 8 [25536/60000 (43%)]	Loss: 31.388359
Train Epoch: 8 [31936/60000 (53%)]	Loss: 28.051825
Train Epoch: 8 [38336/60000 (64%)]	Loss: 36.549446
Train Epoch: 8 [44736/60000 (75%)]	Loss: 32.365337
Train Epoch: 8 [51136/60000 (85%)]	Loss: 33.453861
Train Epoch: 8 [57536/60000 (96%)]	Loss: 33.068707

Test set: Average loss: 32.9265, Accuracy: 1464/10000 (15%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 34.573696
Train Epoch: 9 [12736/60000 (21%)]	Loss: 32.139565
Train Epoch: 9 [19136/60000 (32%)]	Loss: 37.518570
Train Epoch: 9 [25536/60000 (43%)]	Loss: 27.918152
Train Epoch: 9 [31936/60000 (53%)]	Loss: 30.569048
Train Epoch: 9 [38336/60000 (64%)]	Loss: 33.063599
Train Epoch: 9 [44736/60000 (75%)]	Loss: 30.960936
Train Epoch: 9 [51136/60000 (85%)]	Loss: 29.986704
Train Epoch: 9 [57536/60000 (96%)]	Loss: 37.603050

Test set: Average loss: 33.5744, Accuracy: 1455/10000 (15%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 34.592201
Train Epoch: 10 [12736/60000 (21%)]	Loss: 33.698814
Train Epoch: 10 [19136/60000 (32%)]	Loss: 34.608860
Train Epoch: 10 [25536/60000 (43%)]	Loss: 29.583059
Train Epoch: 10 [31936/60000 (53%)]	Loss: 36.397175
Train Epoch: 10 [38336/60000 (64%)]	Loss: 33.113361
Train Epoch: 10 [44736/60000 (75%)]	Loss: 37.924076
Train Epoch: 10 [51136/60000 (85%)]	Loss: 35.574760
Train Epoch: 10 [57536/60000 (96%)]	Loss: 31.086382

Test set: Average loss: 33.3424, Accuracy: 1446/10000 (14%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 33.935894
Train Epoch: 11 [12736/60000 (21%)]	Loss: 37.054585
Train Epoch: 11 [19136/60000 (32%)]	Loss: 32.364864
Train Epoch: 11 [25536/60000 (43%)]	Loss: 33.285591
Train Epoch: 11 [31936/60000 (53%)]	Loss: 31.141195
Train Epoch: 11 [38336/60000 (64%)]	Loss: 32.459690
Train Epoch: 11 [44736/60000 (75%)]	Loss: 34.712322
Train Epoch: 11 [51136/60000 (85%)]	Loss: 33.634670
Train Epoch: 11 [57536/60000 (96%)]	Loss: 37.864456

Test set: Average loss: 33.6392, Accuracy: 1403/10000 (14%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 33.245586
Train Epoch: 12 [12736/60000 (21%)]	Loss: 27.108854
Train Epoch: 12 [19136/60000 (32%)]	Loss: 34.822678
Train Epoch: 12 [25536/60000 (43%)]	Loss: 33.681511
Train Epoch: 12 [31936/60000 (53%)]	Loss: 30.777056
Train Epoch: 12 [38336/60000 (64%)]	Loss: 34.045658
Train Epoch: 12 [44736/60000 (75%)]	Loss: 34.728859
Train Epoch: 12 [51136/60000 (85%)]	Loss: 32.518719
Train Epoch: 12 [57536/60000 (96%)]	Loss: 33.850212

Test set: Average loss: 32.0108, Accuracy: 1420/10000 (14%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.01, use_relu=True, wd=0.0005)


Total time spent pruning/training: 2.42 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4451455
