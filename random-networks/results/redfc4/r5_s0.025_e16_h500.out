Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=16, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 11.195581
Train Epoch: 1 [12736/60000 (21%)]	Loss: 11.993148
Train Epoch: 1 [19136/60000 (32%)]	Loss: 18.973293
Train Epoch: 1 [25536/60000 (43%)]	Loss: 13.737168
Train Epoch: 1 [31936/60000 (53%)]	Loss: 21.636826
Train Epoch: 1 [38336/60000 (64%)]	Loss: 23.369637
Train Epoch: 1 [44736/60000 (75%)]	Loss: 18.424709
Train Epoch: 1 [51136/60000 (85%)]	Loss: 25.789642
Train Epoch: 1 [57536/60000 (96%)]	Loss: 34.440708

Test set: Average loss: 33.2640, Accuracy: 5096/10000 (51%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 40.766300
Train Epoch: 2 [12736/60000 (21%)]	Loss: 28.510582
Train Epoch: 2 [19136/60000 (32%)]	Loss: 44.589272
Train Epoch: 2 [25536/60000 (43%)]	Loss: 34.140442
Train Epoch: 2 [31936/60000 (53%)]	Loss: 28.915091
Train Epoch: 2 [38336/60000 (64%)]	Loss: 43.678059
Train Epoch: 2 [44736/60000 (75%)]	Loss: 43.448849
Train Epoch: 2 [51136/60000 (85%)]	Loss: 44.506458
Train Epoch: 2 [57536/60000 (96%)]	Loss: 38.855961

Test set: Average loss: 55.1358, Accuracy: 3590/10000 (36%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 43.597019
Train Epoch: 3 [12736/60000 (21%)]	Loss: 49.140007
Train Epoch: 3 [19136/60000 (32%)]	Loss: 56.310757
Train Epoch: 3 [25536/60000 (43%)]	Loss: 60.159481
Train Epoch: 3 [31936/60000 (53%)]	Loss: 44.006264
Train Epoch: 3 [38336/60000 (64%)]	Loss: 50.738022
Train Epoch: 3 [44736/60000 (75%)]	Loss: 65.323608
Train Epoch: 3 [51136/60000 (85%)]	Loss: 50.709167
Train Epoch: 3 [57536/60000 (96%)]	Loss: 57.987885

Test set: Average loss: 55.2315, Accuracy: 3330/10000 (33%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 46.825340
Train Epoch: 4 [12736/60000 (21%)]	Loss: 80.746826
Train Epoch: 4 [19136/60000 (32%)]	Loss: 46.235291
Train Epoch: 4 [25536/60000 (43%)]	Loss: 60.260296
Train Epoch: 4 [31936/60000 (53%)]	Loss: 65.799805
Train Epoch: 4 [38336/60000 (64%)]	Loss: 60.421268
Train Epoch: 4 [44736/60000 (75%)]	Loss: 60.948437
Train Epoch: 4 [51136/60000 (85%)]	Loss: 62.244797
Train Epoch: 4 [57536/60000 (96%)]	Loss: 44.354668

Test set: Average loss: 62.3347, Accuracy: 2929/10000 (29%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 69.163712
Train Epoch: 5 [12736/60000 (21%)]	Loss: 65.291367
Train Epoch: 5 [19136/60000 (32%)]	Loss: 71.508789
Train Epoch: 5 [25536/60000 (43%)]	Loss: 56.853397
Train Epoch: 5 [31936/60000 (53%)]	Loss: 66.848900
Train Epoch: 5 [38336/60000 (64%)]	Loss: 61.498936
Train Epoch: 5 [44736/60000 (75%)]	Loss: 69.851257
Train Epoch: 5 [51136/60000 (85%)]	Loss: 62.601700
Train Epoch: 5 [57536/60000 (96%)]	Loss: 76.550507

Test set: Average loss: 63.8248, Accuracy: 2499/10000 (25%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 61.134808
Train Epoch: 6 [12736/60000 (21%)]	Loss: 66.262993
Train Epoch: 6 [19136/60000 (32%)]	Loss: 83.499496
Train Epoch: 6 [25536/60000 (43%)]	Loss: 77.072350
Train Epoch: 6 [31936/60000 (53%)]	Loss: 92.930801
Train Epoch: 6 [38336/60000 (64%)]	Loss: 69.860046
Train Epoch: 6 [44736/60000 (75%)]	Loss: 74.196091
Train Epoch: 6 [51136/60000 (85%)]	Loss: 61.355293
Train Epoch: 6 [57536/60000 (96%)]	Loss: 69.495049

Test set: Average loss: 71.8109, Accuracy: 2385/10000 (24%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 65.826843
Train Epoch: 7 [12736/60000 (21%)]	Loss: 73.405365
Train Epoch: 7 [19136/60000 (32%)]	Loss: 79.361801
Train Epoch: 7 [25536/60000 (43%)]	Loss: 67.667946
Train Epoch: 7 [31936/60000 (53%)]	Loss: 58.745979
Train Epoch: 7 [38336/60000 (64%)]	Loss: 72.782829
Train Epoch: 7 [44736/60000 (75%)]	Loss: 68.719826
Train Epoch: 7 [51136/60000 (85%)]	Loss: 60.975636
Train Epoch: 7 [57536/60000 (96%)]	Loss: 82.058411

Test set: Average loss: 68.6893, Accuracy: 2470/10000 (25%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 75.496674
Train Epoch: 8 [12736/60000 (21%)]	Loss: 59.237362
Train Epoch: 8 [19136/60000 (32%)]	Loss: 63.467621
Train Epoch: 8 [25536/60000 (43%)]	Loss: 74.068871
Train Epoch: 8 [31936/60000 (53%)]	Loss: 70.352676
Train Epoch: 8 [38336/60000 (64%)]	Loss: 71.932022
Train Epoch: 8 [44736/60000 (75%)]	Loss: 78.222549
Train Epoch: 8 [51136/60000 (85%)]	Loss: 76.946136
Train Epoch: 8 [57536/60000 (96%)]	Loss: 63.799671

Test set: Average loss: 70.4634, Accuracy: 2592/10000 (26%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 71.741722
Train Epoch: 9 [12736/60000 (21%)]	Loss: 70.832909
Train Epoch: 9 [19136/60000 (32%)]	Loss: 79.487267
Train Epoch: 9 [25536/60000 (43%)]	Loss: 66.962280
Train Epoch: 9 [31936/60000 (53%)]	Loss: 62.849358
Train Epoch: 9 [38336/60000 (64%)]	Loss: 73.568748
Train Epoch: 9 [44736/60000 (75%)]	Loss: 76.570190
Train Epoch: 9 [51136/60000 (85%)]	Loss: 77.363449
Train Epoch: 9 [57536/60000 (96%)]	Loss: 74.560287

Test set: Average loss: 74.4571, Accuracy: 1905/10000 (19%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 77.936333
Train Epoch: 10 [12736/60000 (21%)]	Loss: 71.503998
Train Epoch: 10 [19136/60000 (32%)]	Loss: 66.911713
Train Epoch: 10 [25536/60000 (43%)]	Loss: 83.546577
Train Epoch: 10 [31936/60000 (53%)]	Loss: 94.730339
Train Epoch: 10 [38336/60000 (64%)]	Loss: 73.404190
Train Epoch: 10 [44736/60000 (75%)]	Loss: 76.977982
Train Epoch: 10 [51136/60000 (85%)]	Loss: 92.494995
Train Epoch: 10 [57536/60000 (96%)]	Loss: 66.483978

Test set: Average loss: 73.4441, Accuracy: 2068/10000 (21%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 64.208176
Train Epoch: 11 [12736/60000 (21%)]	Loss: 72.379021
Train Epoch: 11 [19136/60000 (32%)]	Loss: 79.635612
Train Epoch: 11 [25536/60000 (43%)]	Loss: 66.508804
Train Epoch: 11 [31936/60000 (53%)]	Loss: 64.925652
Train Epoch: 11 [38336/60000 (64%)]	Loss: 62.794945
Train Epoch: 11 [44736/60000 (75%)]	Loss: 65.463036
Train Epoch: 11 [51136/60000 (85%)]	Loss: 76.765770
Train Epoch: 11 [57536/60000 (96%)]	Loss: 76.331909

Test set: Average loss: 75.7935, Accuracy: 1878/10000 (19%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 72.498840
Train Epoch: 12 [12736/60000 (21%)]	Loss: 75.200005
Train Epoch: 12 [19136/60000 (32%)]	Loss: 93.611771
Train Epoch: 12 [25536/60000 (43%)]	Loss: 74.085129
Train Epoch: 12 [31936/60000 (53%)]	Loss: 66.269081
Train Epoch: 12 [38336/60000 (64%)]	Loss: 69.527573
Train Epoch: 12 [44736/60000 (75%)]	Loss: 74.904701
Train Epoch: 12 [51136/60000 (85%)]	Loss: 86.933884
Train Epoch: 12 [57536/60000 (96%)]	Loss: 65.540939

Test set: Average loss: 72.4460, Accuracy: 2091/10000 (21%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 73.161690
Train Epoch: 13 [12736/60000 (21%)]	Loss: 64.328484
Train Epoch: 13 [19136/60000 (32%)]	Loss: 106.448074
Train Epoch: 13 [25536/60000 (43%)]	Loss: 69.585464
Train Epoch: 13 [31936/60000 (53%)]	Loss: 84.638931
Train Epoch: 13 [38336/60000 (64%)]	Loss: 68.483490
Train Epoch: 13 [44736/60000 (75%)]	Loss: 68.246964
Train Epoch: 13 [51136/60000 (85%)]	Loss: 57.862934
Train Epoch: 13 [57536/60000 (96%)]	Loss: 74.016411

Test set: Average loss: 71.6433, Accuracy: 2532/10000 (25%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 76.616005
Train Epoch: 14 [12736/60000 (21%)]	Loss: 64.146263
Train Epoch: 14 [19136/60000 (32%)]	Loss: 85.501045
Train Epoch: 14 [25536/60000 (43%)]	Loss: 69.197662
Train Epoch: 14 [31936/60000 (53%)]	Loss: 83.779633
Train Epoch: 14 [38336/60000 (64%)]	Loss: 64.490929
Train Epoch: 14 [44736/60000 (75%)]	Loss: 64.511162
Train Epoch: 14 [51136/60000 (85%)]	Loss: 83.132843
Train Epoch: 14 [57536/60000 (96%)]	Loss: 67.349571

Test set: Average loss: 76.8733, Accuracy: 2312/10000 (23%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 83.800720
Train Epoch: 15 [12736/60000 (21%)]	Loss: 57.210567
Train Epoch: 15 [19136/60000 (32%)]	Loss: 77.146049
Train Epoch: 15 [25536/60000 (43%)]	Loss: 71.419701
Train Epoch: 15 [31936/60000 (53%)]	Loss: 90.112251
Train Epoch: 15 [38336/60000 (64%)]	Loss: 82.282967
Train Epoch: 15 [44736/60000 (75%)]	Loss: 94.302528
Train Epoch: 15 [51136/60000 (85%)]	Loss: 71.412247
Train Epoch: 15 [57536/60000 (96%)]	Loss: 60.306751

Test set: Average loss: 72.0016, Accuracy: 2467/10000 (25%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 59.147678
Train Epoch: 16 [12736/60000 (21%)]	Loss: 65.125488
Train Epoch: 16 [19136/60000 (32%)]	Loss: 65.404648
Train Epoch: 16 [25536/60000 (43%)]	Loss: 77.719559
Train Epoch: 16 [31936/60000 (53%)]	Loss: 55.670574
Train Epoch: 16 [38336/60000 (64%)]	Loss: 79.907387
Train Epoch: 16 [44736/60000 (75%)]	Loss: 62.738335
Train Epoch: 16 [51136/60000 (85%)]	Loss: 68.646667
Train Epoch: 16 [57536/60000 (96%)]	Loss: 63.550114

Test set: Average loss: 69.4565, Accuracy: 2240/10000 (22%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=16, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.17 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4384009
