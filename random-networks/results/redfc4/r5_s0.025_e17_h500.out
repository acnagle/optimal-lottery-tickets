Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 11.195581
Train Epoch: 1 [12736/60000 (21%)]	Loss: 11.993148
Train Epoch: 1 [19136/60000 (32%)]	Loss: 18.973293
Train Epoch: 1 [25536/60000 (43%)]	Loss: 13.737168
Train Epoch: 1 [31936/60000 (53%)]	Loss: 21.636826
Train Epoch: 1 [38336/60000 (64%)]	Loss: 23.369637
Train Epoch: 1 [44736/60000 (75%)]	Loss: 18.424709
Train Epoch: 1 [51136/60000 (85%)]	Loss: 25.789642
Train Epoch: 1 [57536/60000 (96%)]	Loss: 34.440708

Test set: Average loss: 33.2640, Accuracy: 5096/10000 (51%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 47.274952
Train Epoch: 2 [12736/60000 (21%)]	Loss: 29.809921
Train Epoch: 2 [19136/60000 (32%)]	Loss: 55.459553
Train Epoch: 2 [25536/60000 (43%)]	Loss: 34.314610
Train Epoch: 2 [31936/60000 (53%)]	Loss: 24.097029
Train Epoch: 2 [38336/60000 (64%)]	Loss: 45.216473
Train Epoch: 2 [44736/60000 (75%)]	Loss: 47.480938
Train Epoch: 2 [51136/60000 (85%)]	Loss: 38.550133
Train Epoch: 2 [57536/60000 (96%)]	Loss: 40.776627

Test set: Average loss: 52.7351, Accuracy: 3360/10000 (34%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 50.350277
Train Epoch: 3 [12736/60000 (21%)]	Loss: 52.585186
Train Epoch: 3 [19136/60000 (32%)]	Loss: 55.056969
Train Epoch: 3 [25536/60000 (43%)]	Loss: 58.071884
Train Epoch: 3 [31936/60000 (53%)]	Loss: 41.143448
Train Epoch: 3 [38336/60000 (64%)]	Loss: 47.963589
Train Epoch: 3 [44736/60000 (75%)]	Loss: 53.104095
Train Epoch: 3 [51136/60000 (85%)]	Loss: 53.019474
Train Epoch: 3 [57536/60000 (96%)]	Loss: 57.783134

Test set: Average loss: 51.2255, Accuracy: 3253/10000 (33%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 47.454300
Train Epoch: 4 [12736/60000 (21%)]	Loss: 77.700531
Train Epoch: 4 [19136/60000 (32%)]	Loss: 43.904251
Train Epoch: 4 [25536/60000 (43%)]	Loss: 63.403667
Train Epoch: 4 [31936/60000 (53%)]	Loss: 60.581852
Train Epoch: 4 [38336/60000 (64%)]	Loss: 61.987610
Train Epoch: 4 [44736/60000 (75%)]	Loss: 57.360664
Train Epoch: 4 [51136/60000 (85%)]	Loss: 63.129124
Train Epoch: 4 [57536/60000 (96%)]	Loss: 42.162067

Test set: Average loss: 59.3567, Accuracy: 3074/10000 (31%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 66.859215
Train Epoch: 5 [12736/60000 (21%)]	Loss: 64.773796
Train Epoch: 5 [19136/60000 (32%)]	Loss: 68.574158
Train Epoch: 5 [25536/60000 (43%)]	Loss: 61.068966
Train Epoch: 5 [31936/60000 (53%)]	Loss: 63.549988
Train Epoch: 5 [38336/60000 (64%)]	Loss: 57.656689
Train Epoch: 5 [44736/60000 (75%)]	Loss: 54.602936
Train Epoch: 5 [51136/60000 (85%)]	Loss: 60.570007
Train Epoch: 5 [57536/60000 (96%)]	Loss: 69.338776

Test set: Average loss: 68.1762, Accuracy: 2501/10000 (25%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 56.090405
Train Epoch: 6 [12736/60000 (21%)]	Loss: 64.283264
Train Epoch: 6 [19136/60000 (32%)]	Loss: 85.621376
Train Epoch: 6 [25536/60000 (43%)]	Loss: 69.294846
Train Epoch: 6 [31936/60000 (53%)]	Loss: 81.828865
Train Epoch: 6 [38336/60000 (64%)]	Loss: 67.431435
Train Epoch: 6 [44736/60000 (75%)]	Loss: 65.418060
Train Epoch: 6 [51136/60000 (85%)]	Loss: 65.895813
Train Epoch: 6 [57536/60000 (96%)]	Loss: 73.432106

Test set: Average loss: 70.1750, Accuracy: 2581/10000 (26%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 60.481483
Train Epoch: 7 [12736/60000 (21%)]	Loss: 70.489006
Train Epoch: 7 [19136/60000 (32%)]	Loss: 78.207954
Train Epoch: 7 [25536/60000 (43%)]	Loss: 62.343781
Train Epoch: 7 [31936/60000 (53%)]	Loss: 71.203133
Train Epoch: 7 [38336/60000 (64%)]	Loss: 75.096413
Train Epoch: 7 [44736/60000 (75%)]	Loss: 74.192749
Train Epoch: 7 [51136/60000 (85%)]	Loss: 66.267822
Train Epoch: 7 [57536/60000 (96%)]	Loss: 79.550117

Test set: Average loss: 71.7650, Accuracy: 2416/10000 (24%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 68.579834
Train Epoch: 8 [12736/60000 (21%)]	Loss: 54.877689
Train Epoch: 8 [19136/60000 (32%)]	Loss: 67.695320
Train Epoch: 8 [25536/60000 (43%)]	Loss: 73.101501
Train Epoch: 8 [31936/60000 (53%)]	Loss: 66.659355
Train Epoch: 8 [38336/60000 (64%)]	Loss: 64.235825
Train Epoch: 8 [44736/60000 (75%)]	Loss: 77.332672
Train Epoch: 8 [51136/60000 (85%)]	Loss: 76.853943
Train Epoch: 8 [57536/60000 (96%)]	Loss: 65.252586

Test set: Average loss: 70.6401, Accuracy: 2210/10000 (22%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 66.631355
Train Epoch: 9 [12736/60000 (21%)]	Loss: 66.974686
Train Epoch: 9 [19136/60000 (32%)]	Loss: 79.545738
Train Epoch: 9 [25536/60000 (43%)]	Loss: 68.965500
Train Epoch: 9 [31936/60000 (53%)]	Loss: 60.662888
Train Epoch: 9 [38336/60000 (64%)]	Loss: 71.561790
Train Epoch: 9 [44736/60000 (75%)]	Loss: 69.800568
Train Epoch: 9 [51136/60000 (85%)]	Loss: 69.348289
Train Epoch: 9 [57536/60000 (96%)]	Loss: 80.371841

Test set: Average loss: 70.7237, Accuracy: 2332/10000 (23%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 80.436134
Train Epoch: 10 [12736/60000 (21%)]	Loss: 66.990700
Train Epoch: 10 [19136/60000 (32%)]	Loss: 60.736832
Train Epoch: 10 [25536/60000 (43%)]	Loss: 86.272240
Train Epoch: 10 [31936/60000 (53%)]	Loss: 84.593605
Train Epoch: 10 [38336/60000 (64%)]	Loss: 67.146202
Train Epoch: 10 [44736/60000 (75%)]	Loss: 76.474365
Train Epoch: 10 [51136/60000 (85%)]	Loss: 88.556030
Train Epoch: 10 [57536/60000 (96%)]	Loss: 73.974197

Test set: Average loss: 72.3522, Accuracy: 2052/10000 (21%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 63.366436
Train Epoch: 11 [12736/60000 (21%)]	Loss: 73.769363
Train Epoch: 11 [19136/60000 (32%)]	Loss: 80.413170
Train Epoch: 11 [25536/60000 (43%)]	Loss: 71.052818
Train Epoch: 11 [31936/60000 (53%)]	Loss: 62.281498
Train Epoch: 11 [38336/60000 (64%)]	Loss: 61.692238
Train Epoch: 11 [44736/60000 (75%)]	Loss: 62.380363
Train Epoch: 11 [51136/60000 (85%)]	Loss: 75.702362
Train Epoch: 11 [57536/60000 (96%)]	Loss: 78.369530

Test set: Average loss: 76.4573, Accuracy: 1927/10000 (19%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 75.605499
Train Epoch: 12 [12736/60000 (21%)]	Loss: 78.144157
Train Epoch: 12 [19136/60000 (32%)]	Loss: 92.886993
Train Epoch: 12 [25536/60000 (43%)]	Loss: 73.191696
Train Epoch: 12 [31936/60000 (53%)]	Loss: 67.391014
Train Epoch: 12 [38336/60000 (64%)]	Loss: 79.232559
Train Epoch: 12 [44736/60000 (75%)]	Loss: 75.148125
Train Epoch: 12 [51136/60000 (85%)]	Loss: 89.227142
Train Epoch: 12 [57536/60000 (96%)]	Loss: 69.013535

Test set: Average loss: 73.1525, Accuracy: 2211/10000 (22%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 74.606171
Train Epoch: 13 [12736/60000 (21%)]	Loss: 64.336304
Train Epoch: 13 [19136/60000 (32%)]	Loss: 116.023003
Train Epoch: 13 [25536/60000 (43%)]	Loss: 65.715668
Train Epoch: 13 [31936/60000 (53%)]	Loss: 72.662689
Train Epoch: 13 [38336/60000 (64%)]	Loss: 67.134102
Train Epoch: 13 [44736/60000 (75%)]	Loss: 71.851509
Train Epoch: 13 [51136/60000 (85%)]	Loss: 58.190468
Train Epoch: 13 [57536/60000 (96%)]	Loss: 75.689255

Test set: Average loss: 74.5313, Accuracy: 2567/10000 (26%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 75.702507
Train Epoch: 14 [12736/60000 (21%)]	Loss: 72.934929
Train Epoch: 14 [19136/60000 (32%)]	Loss: 84.335899
Train Epoch: 14 [25536/60000 (43%)]	Loss: 66.399651
Train Epoch: 14 [31936/60000 (53%)]	Loss: 81.148590
Train Epoch: 14 [38336/60000 (64%)]	Loss: 68.198509
Train Epoch: 14 [44736/60000 (75%)]	Loss: 70.093575
Train Epoch: 14 [51136/60000 (85%)]	Loss: 83.338577
Train Epoch: 14 [57536/60000 (96%)]	Loss: 63.688736

Test set: Average loss: 75.1331, Accuracy: 2236/10000 (22%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 85.840515
Train Epoch: 15 [12736/60000 (21%)]	Loss: 59.748215
Train Epoch: 15 [19136/60000 (32%)]	Loss: 77.205917
Train Epoch: 15 [25536/60000 (43%)]	Loss: 70.697800
Train Epoch: 15 [31936/60000 (53%)]	Loss: 104.184258
Train Epoch: 15 [38336/60000 (64%)]	Loss: 87.127426
Train Epoch: 15 [44736/60000 (75%)]	Loss: 89.728500
Train Epoch: 15 [51136/60000 (85%)]	Loss: 76.961586
Train Epoch: 15 [57536/60000 (96%)]	Loss: 60.098202

Test set: Average loss: 82.8312, Accuracy: 2176/10000 (22%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 56.461899
Train Epoch: 16 [12736/60000 (21%)]	Loss: 78.147728
Train Epoch: 16 [19136/60000 (32%)]	Loss: 72.948708
Train Epoch: 16 [25536/60000 (43%)]	Loss: 78.591774
Train Epoch: 16 [31936/60000 (53%)]	Loss: 67.579056
Train Epoch: 16 [38336/60000 (64%)]	Loss: 75.880623
Train Epoch: 16 [44736/60000 (75%)]	Loss: 72.282761
Train Epoch: 16 [51136/60000 (85%)]	Loss: 78.864685
Train Epoch: 16 [57536/60000 (96%)]	Loss: 63.615078

Test set: Average loss: 70.6222, Accuracy: 2027/10000 (20%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 84.413445
Train Epoch: 17 [12736/60000 (21%)]	Loss: 61.232285
Train Epoch: 17 [19136/60000 (32%)]	Loss: 80.702995
Train Epoch: 17 [25536/60000 (43%)]	Loss: 70.448753
Train Epoch: 17 [31936/60000 (53%)]	Loss: 79.596382
Train Epoch: 17 [38336/60000 (64%)]	Loss: 75.342010
Train Epoch: 17 [44736/60000 (75%)]	Loss: 63.928474
Train Epoch: 17 [51136/60000 (85%)]	Loss: 76.304840
Train Epoch: 17 [57536/60000 (96%)]	Loss: 90.757080

Test set: Average loss: 68.1994, Accuracy: 2414/10000 (24%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.38 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4384009
