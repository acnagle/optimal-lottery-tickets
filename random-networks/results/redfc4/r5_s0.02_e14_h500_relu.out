Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.904168
Train Epoch: 1 [12736/60000 (21%)]	Loss: 3.295049
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.552685
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.573287
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.663903
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.334898
Train Epoch: 1 [44736/60000 (75%)]	Loss: 4.441846
Train Epoch: 1 [51136/60000 (85%)]	Loss: 3.991321
Train Epoch: 1 [57536/60000 (96%)]	Loss: 3.708132

Test set: Average loss: 4.7151, Accuracy: 5944/10000 (59%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 8.990964
Train Epoch: 2 [12736/60000 (21%)]	Loss: 3.043561
Train Epoch: 2 [19136/60000 (32%)]	Loss: 6.739666
Train Epoch: 2 [25536/60000 (43%)]	Loss: 4.120669
Train Epoch: 2 [31936/60000 (53%)]	Loss: 6.523003
Train Epoch: 2 [38336/60000 (64%)]	Loss: 9.359446
Train Epoch: 2 [44736/60000 (75%)]	Loss: 7.568425
Train Epoch: 2 [51136/60000 (85%)]	Loss: 6.051487
Train Epoch: 2 [57536/60000 (96%)]	Loss: 5.864675

Test set: Average loss: 8.3002, Accuracy: 4556/10000 (46%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 7.449852
Train Epoch: 3 [12736/60000 (21%)]	Loss: 7.459176
Train Epoch: 3 [19136/60000 (32%)]	Loss: 5.609714
Train Epoch: 3 [25536/60000 (43%)]	Loss: 6.368096
Train Epoch: 3 [31936/60000 (53%)]	Loss: 7.038014
Train Epoch: 3 [38336/60000 (64%)]	Loss: 9.905601
Train Epoch: 3 [44736/60000 (75%)]	Loss: 7.882167
Train Epoch: 3 [51136/60000 (85%)]	Loss: 8.787648
Train Epoch: 3 [57536/60000 (96%)]	Loss: 11.665517

Test set: Average loss: 12.0326, Accuracy: 3328/10000 (33%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 10.776785
Train Epoch: 4 [12736/60000 (21%)]	Loss: 15.011936
Train Epoch: 4 [19136/60000 (32%)]	Loss: 12.445588
Train Epoch: 4 [25536/60000 (43%)]	Loss: 15.401615
Train Epoch: 4 [31936/60000 (53%)]	Loss: 15.719203
Train Epoch: 4 [38336/60000 (64%)]	Loss: 12.874968
Train Epoch: 4 [44736/60000 (75%)]	Loss: 15.923101
Train Epoch: 4 [51136/60000 (85%)]	Loss: 15.272830
Train Epoch: 4 [57536/60000 (96%)]	Loss: 9.782445

Test set: Average loss: 14.9687, Accuracy: 2579/10000 (26%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 16.225380
Train Epoch: 5 [12736/60000 (21%)]	Loss: 12.965197
Train Epoch: 5 [19136/60000 (32%)]	Loss: 15.332413
Train Epoch: 5 [25536/60000 (43%)]	Loss: 15.772870
Train Epoch: 5 [31936/60000 (53%)]	Loss: 18.986242
Train Epoch: 5 [38336/60000 (64%)]	Loss: 17.239546
Train Epoch: 5 [44736/60000 (75%)]	Loss: 19.317329
Train Epoch: 5 [51136/60000 (85%)]	Loss: 19.585590
Train Epoch: 5 [57536/60000 (96%)]	Loss: 22.278624

Test set: Average loss: 18.3773, Accuracy: 2130/10000 (21%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 16.162151
Train Epoch: 6 [12736/60000 (21%)]	Loss: 20.248558
Train Epoch: 6 [19136/60000 (32%)]	Loss: 22.008644
Train Epoch: 6 [25536/60000 (43%)]	Loss: 17.451181
Train Epoch: 6 [31936/60000 (53%)]	Loss: 17.170959
Train Epoch: 6 [38336/60000 (64%)]	Loss: 18.798592
Train Epoch: 6 [44736/60000 (75%)]	Loss: 23.254475
Train Epoch: 6 [51136/60000 (85%)]	Loss: 21.343515
Train Epoch: 6 [57536/60000 (96%)]	Loss: 22.274620

Test set: Average loss: 19.4882, Accuracy: 2084/10000 (21%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 19.201462
Train Epoch: 7 [12736/60000 (21%)]	Loss: 17.292812
Train Epoch: 7 [19136/60000 (32%)]	Loss: 19.247288
Train Epoch: 7 [25536/60000 (43%)]	Loss: 20.870020
Train Epoch: 7 [31936/60000 (53%)]	Loss: 23.329428
Train Epoch: 7 [38336/60000 (64%)]	Loss: 21.173290
Train Epoch: 7 [44736/60000 (75%)]	Loss: 21.613728
Train Epoch: 7 [51136/60000 (85%)]	Loss: 20.804655
Train Epoch: 7 [57536/60000 (96%)]	Loss: 21.781967

Test set: Average loss: 21.0065, Accuracy: 1756/10000 (18%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 22.347408
Train Epoch: 8 [12736/60000 (21%)]	Loss: 14.189074
Train Epoch: 8 [19136/60000 (32%)]	Loss: 22.152393
Train Epoch: 8 [25536/60000 (43%)]	Loss: 19.982534
Train Epoch: 8 [31936/60000 (53%)]	Loss: 19.424171
Train Epoch: 8 [38336/60000 (64%)]	Loss: 24.937927
Train Epoch: 8 [44736/60000 (75%)]	Loss: 21.359386
Train Epoch: 8 [51136/60000 (85%)]	Loss: 21.469540
Train Epoch: 8 [57536/60000 (96%)]	Loss: 23.241375

Test set: Average loss: 22.1521, Accuracy: 1887/10000 (19%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 24.246805
Train Epoch: 9 [12736/60000 (21%)]	Loss: 21.088829
Train Epoch: 9 [19136/60000 (32%)]	Loss: 23.783150
Train Epoch: 9 [25536/60000 (43%)]	Loss: 16.828447
Train Epoch: 9 [31936/60000 (53%)]	Loss: 19.787588
Train Epoch: 9 [38336/60000 (64%)]	Loss: 22.625782
Train Epoch: 9 [44736/60000 (75%)]	Loss: 21.526039
Train Epoch: 9 [51136/60000 (85%)]	Loss: 18.064606
Train Epoch: 9 [57536/60000 (96%)]	Loss: 23.153851

Test set: Average loss: 22.4410, Accuracy: 1766/10000 (18%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 23.824116
Train Epoch: 10 [12736/60000 (21%)]	Loss: 20.844482
Train Epoch: 10 [19136/60000 (32%)]	Loss: 23.150394
Train Epoch: 10 [25536/60000 (43%)]	Loss: 17.981380
Train Epoch: 10 [31936/60000 (53%)]	Loss: 24.036867
Train Epoch: 10 [38336/60000 (64%)]	Loss: 22.289673
Train Epoch: 10 [44736/60000 (75%)]	Loss: 24.883509
Train Epoch: 10 [51136/60000 (85%)]	Loss: 22.581802
Train Epoch: 10 [57536/60000 (96%)]	Loss: 20.836651

Test set: Average loss: 22.5931, Accuracy: 1819/10000 (18%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 20.024393
Train Epoch: 11 [12736/60000 (21%)]	Loss: 23.248516
Train Epoch: 11 [19136/60000 (32%)]	Loss: 18.790537
Train Epoch: 11 [25536/60000 (43%)]	Loss: 23.410519
Train Epoch: 11 [31936/60000 (53%)]	Loss: 18.754112
Train Epoch: 11 [38336/60000 (64%)]	Loss: 21.344198
Train Epoch: 11 [44736/60000 (75%)]	Loss: 21.568647
Train Epoch: 11 [51136/60000 (85%)]	Loss: 22.123920
Train Epoch: 11 [57536/60000 (96%)]	Loss: 25.654942

Test set: Average loss: 22.2307, Accuracy: 1809/10000 (18%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 21.523891
Train Epoch: 12 [12736/60000 (21%)]	Loss: 17.808870
Train Epoch: 12 [19136/60000 (32%)]	Loss: 21.663671
Train Epoch: 12 [25536/60000 (43%)]	Loss: 24.158346
Train Epoch: 12 [31936/60000 (53%)]	Loss: 19.850037
Train Epoch: 12 [38336/60000 (64%)]	Loss: 21.371626
Train Epoch: 12 [44736/60000 (75%)]	Loss: 23.387297
Train Epoch: 12 [51136/60000 (85%)]	Loss: 20.848866
Train Epoch: 12 [57536/60000 (96%)]	Loss: 23.262142

Test set: Average loss: 21.0370, Accuracy: 1899/10000 (19%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 19.994759
Train Epoch: 13 [12736/60000 (21%)]	Loss: 23.933397
Train Epoch: 13 [19136/60000 (32%)]	Loss: 21.937134
Train Epoch: 13 [25536/60000 (43%)]	Loss: 25.305408
Train Epoch: 13 [31936/60000 (53%)]	Loss: 21.604759
Train Epoch: 13 [38336/60000 (64%)]	Loss: 23.248400
Train Epoch: 13 [44736/60000 (75%)]	Loss: 19.607153
Train Epoch: 13 [51136/60000 (85%)]	Loss: 21.371170
Train Epoch: 13 [57536/60000 (96%)]	Loss: 21.844227

Test set: Average loss: 22.0769, Accuracy: 1891/10000 (19%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 18.056126
Train Epoch: 14 [12736/60000 (21%)]	Loss: 18.938570
Train Epoch: 14 [19136/60000 (32%)]	Loss: 19.193516
Train Epoch: 14 [25536/60000 (43%)]	Loss: 17.418867
Train Epoch: 14 [31936/60000 (53%)]	Loss: 22.754995
Train Epoch: 14 [38336/60000 (64%)]	Loss: 18.207424
Train Epoch: 14 [44736/60000 (75%)]	Loss: 21.823561
Train Epoch: 14 [51136/60000 (85%)]	Loss: 20.643724
Train Epoch: 14 [57536/60000 (96%)]	Loss: 22.171230

Test set: Average loss: 20.7046, Accuracy: 1973/10000 (20%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=True, wd=0.0005)


Total time spent pruning/training: 2.82 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4406491
