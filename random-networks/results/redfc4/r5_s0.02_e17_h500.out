Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 7.253252
Train Epoch: 1 [12736/60000 (21%)]	Loss: 25.429331
Train Epoch: 1 [19136/60000 (32%)]	Loss: 34.917747
Train Epoch: 1 [25536/60000 (43%)]	Loss: 38.026100
Train Epoch: 1 [31936/60000 (53%)]	Loss: 29.555229
Train Epoch: 1 [38336/60000 (64%)]	Loss: 27.226795
Train Epoch: 1 [44736/60000 (75%)]	Loss: 33.277142
Train Epoch: 1 [51136/60000 (85%)]	Loss: 45.097240
Train Epoch: 1 [57536/60000 (96%)]	Loss: 48.676105

Test set: Average loss: 47.5576, Accuracy: 3854/10000 (39%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 58.823952
Train Epoch: 2 [12736/60000 (21%)]	Loss: 45.297050
Train Epoch: 2 [19136/60000 (32%)]	Loss: 61.167267
Train Epoch: 2 [25536/60000 (43%)]	Loss: 53.851032
Train Epoch: 2 [31936/60000 (53%)]	Loss: 51.088001
Train Epoch: 2 [38336/60000 (64%)]	Loss: 66.386520
Train Epoch: 2 [44736/60000 (75%)]	Loss: 62.514099
Train Epoch: 2 [51136/60000 (85%)]	Loss: 63.966545
Train Epoch: 2 [57536/60000 (96%)]	Loss: 68.847893

Test set: Average loss: 76.9020, Accuracy: 2139/10000 (21%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 63.869556
Train Epoch: 3 [12736/60000 (21%)]	Loss: 69.740685
Train Epoch: 3 [19136/60000 (32%)]	Loss: 79.002029
Train Epoch: 3 [25536/60000 (43%)]	Loss: 82.443893
Train Epoch: 3 [31936/60000 (53%)]	Loss: 70.168854
Train Epoch: 3 [38336/60000 (64%)]	Loss: 73.723663
Train Epoch: 3 [44736/60000 (75%)]	Loss: 76.961250
Train Epoch: 3 [51136/60000 (85%)]	Loss: 84.986679
Train Epoch: 3 [57536/60000 (96%)]	Loss: 80.272987

Test set: Average loss: 77.6646, Accuracy: 1890/10000 (19%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 70.539764
Train Epoch: 4 [12736/60000 (21%)]	Loss: 102.336441
Train Epoch: 4 [19136/60000 (32%)]	Loss: 76.330055
Train Epoch: 4 [25536/60000 (43%)]	Loss: 95.680305
Train Epoch: 4 [31936/60000 (53%)]	Loss: 92.443489
Train Epoch: 4 [38336/60000 (64%)]	Loss: 93.931160
Train Epoch: 4 [44736/60000 (75%)]	Loss: 79.674004
Train Epoch: 4 [51136/60000 (85%)]	Loss: 85.651077
Train Epoch: 4 [57536/60000 (96%)]	Loss: 69.807724

Test set: Average loss: 81.9908, Accuracy: 2244/10000 (22%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 89.584251
Train Epoch: 5 [12736/60000 (21%)]	Loss: 84.767731
Train Epoch: 5 [19136/60000 (32%)]	Loss: 94.086563
Train Epoch: 5 [25536/60000 (43%)]	Loss: 93.058342
Train Epoch: 5 [31936/60000 (53%)]	Loss: 94.943085
Train Epoch: 5 [38336/60000 (64%)]	Loss: 81.855659
Train Epoch: 5 [44736/60000 (75%)]	Loss: 90.293175
Train Epoch: 5 [51136/60000 (85%)]	Loss: 87.122345
Train Epoch: 5 [57536/60000 (96%)]	Loss: 99.800545

Test set: Average loss: 96.6939, Accuracy: 1726/10000 (17%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 84.052040
Train Epoch: 6 [12736/60000 (21%)]	Loss: 87.815689
Train Epoch: 6 [19136/60000 (32%)]	Loss: 108.906914
Train Epoch: 6 [25536/60000 (43%)]	Loss: 94.550507
Train Epoch: 6 [31936/60000 (53%)]	Loss: 107.906212
Train Epoch: 6 [38336/60000 (64%)]	Loss: 91.747650
Train Epoch: 6 [44736/60000 (75%)]	Loss: 93.947060
Train Epoch: 6 [51136/60000 (85%)]	Loss: 97.261940
Train Epoch: 6 [57536/60000 (96%)]	Loss: 94.875595

Test set: Average loss: 93.5015, Accuracy: 1739/10000 (17%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 98.483070
Train Epoch: 7 [12736/60000 (21%)]	Loss: 97.793907
Train Epoch: 7 [19136/60000 (32%)]	Loss: 105.955658
Train Epoch: 7 [25536/60000 (43%)]	Loss: 82.798187
Train Epoch: 7 [31936/60000 (53%)]	Loss: 95.386719
Train Epoch: 7 [38336/60000 (64%)]	Loss: 97.709709
Train Epoch: 7 [44736/60000 (75%)]	Loss: 86.011391
Train Epoch: 7 [51136/60000 (85%)]	Loss: 88.238182
Train Epoch: 7 [57536/60000 (96%)]	Loss: 108.031700

Test set: Average loss: 93.4554, Accuracy: 1700/10000 (17%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 86.385307
Train Epoch: 8 [12736/60000 (21%)]	Loss: 80.657967
Train Epoch: 8 [19136/60000 (32%)]	Loss: 92.518097
Train Epoch: 8 [25536/60000 (43%)]	Loss: 98.430267
Train Epoch: 8 [31936/60000 (53%)]	Loss: 91.794273
Train Epoch: 8 [38336/60000 (64%)]	Loss: 92.518272
Train Epoch: 8 [44736/60000 (75%)]	Loss: 96.995941
Train Epoch: 8 [51136/60000 (85%)]	Loss: 100.100410
Train Epoch: 8 [57536/60000 (96%)]	Loss: 83.961052

Test set: Average loss: 98.2937, Accuracy: 1593/10000 (16%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 94.943558
Train Epoch: 9 [12736/60000 (21%)]	Loss: 91.191643
Train Epoch: 9 [19136/60000 (32%)]	Loss: 103.315979
Train Epoch: 9 [25536/60000 (43%)]	Loss: 86.785774
Train Epoch: 9 [31936/60000 (53%)]	Loss: 100.437981
Train Epoch: 9 [38336/60000 (64%)]	Loss: 99.535164
Train Epoch: 9 [44736/60000 (75%)]	Loss: 97.893929
Train Epoch: 9 [51136/60000 (85%)]	Loss: 103.011406
Train Epoch: 9 [57536/60000 (96%)]	Loss: 96.877541

Test set: Average loss: 96.2327, Accuracy: 1515/10000 (15%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 98.634773
Train Epoch: 10 [12736/60000 (21%)]	Loss: 91.226990
Train Epoch: 10 [19136/60000 (32%)]	Loss: 95.815552
Train Epoch: 10 [25536/60000 (43%)]	Loss: 104.035637
Train Epoch: 10 [31936/60000 (53%)]	Loss: 124.890335
Train Epoch: 10 [38336/60000 (64%)]	Loss: 94.064812
Train Epoch: 10 [44736/60000 (75%)]	Loss: 102.123672
Train Epoch: 10 [51136/60000 (85%)]	Loss: 113.325684
Train Epoch: 10 [57536/60000 (96%)]	Loss: 89.873825

Test set: Average loss: 97.0934, Accuracy: 1502/10000 (15%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 98.097343
Train Epoch: 11 [12736/60000 (21%)]	Loss: 95.650238
Train Epoch: 11 [19136/60000 (32%)]	Loss: 110.639893
Train Epoch: 11 [25536/60000 (43%)]	Loss: 88.743744
Train Epoch: 11 [31936/60000 (53%)]	Loss: 90.835190
Train Epoch: 11 [38336/60000 (64%)]	Loss: 81.919151
Train Epoch: 11 [44736/60000 (75%)]	Loss: 95.262444
Train Epoch: 11 [51136/60000 (85%)]	Loss: 105.378502
Train Epoch: 11 [57536/60000 (96%)]	Loss: 109.520790

Test set: Average loss: 98.6057, Accuracy: 1452/10000 (15%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 97.626930
Train Epoch: 12 [12736/60000 (21%)]	Loss: 103.932465
Train Epoch: 12 [19136/60000 (32%)]	Loss: 113.470451
Train Epoch: 12 [25536/60000 (43%)]	Loss: 108.654068
Train Epoch: 12 [31936/60000 (53%)]	Loss: 86.302780
Train Epoch: 12 [38336/60000 (64%)]	Loss: 98.907860
Train Epoch: 12 [44736/60000 (75%)]	Loss: 91.890587
Train Epoch: 12 [51136/60000 (85%)]	Loss: 112.208900
Train Epoch: 12 [57536/60000 (96%)]	Loss: 103.839088

Test set: Average loss: 95.3393, Accuracy: 1643/10000 (16%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 103.771614
Train Epoch: 13 [12736/60000 (21%)]	Loss: 91.056702
Train Epoch: 13 [19136/60000 (32%)]	Loss: 134.187988
Train Epoch: 13 [25536/60000 (43%)]	Loss: 89.668327
Train Epoch: 13 [31936/60000 (53%)]	Loss: 103.430649
Train Epoch: 13 [38336/60000 (64%)]	Loss: 87.455704
Train Epoch: 13 [44736/60000 (75%)]	Loss: 99.783051
Train Epoch: 13 [51136/60000 (85%)]	Loss: 79.901978
Train Epoch: 13 [57536/60000 (96%)]	Loss: 97.439148

Test set: Average loss: 99.6987, Accuracy: 1641/10000 (16%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 109.426163
Train Epoch: 14 [12736/60000 (21%)]	Loss: 89.070404
Train Epoch: 14 [19136/60000 (32%)]	Loss: 112.964203
Train Epoch: 14 [25536/60000 (43%)]	Loss: 93.116875
Train Epoch: 14 [31936/60000 (53%)]	Loss: 103.738068
Train Epoch: 14 [38336/60000 (64%)]	Loss: 89.527122
Train Epoch: 14 [44736/60000 (75%)]	Loss: 103.551086
Train Epoch: 14 [51136/60000 (85%)]	Loss: 117.206245
Train Epoch: 14 [57536/60000 (96%)]	Loss: 95.969238

Test set: Average loss: 97.8519, Accuracy: 1597/10000 (16%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 108.674637
Train Epoch: 15 [12736/60000 (21%)]	Loss: 85.953430
Train Epoch: 15 [19136/60000 (32%)]	Loss: 110.393860
Train Epoch: 15 [25536/60000 (43%)]	Loss: 96.129684
Train Epoch: 15 [31936/60000 (53%)]	Loss: 123.349007
Train Epoch: 15 [38336/60000 (64%)]	Loss: 111.303940
Train Epoch: 15 [44736/60000 (75%)]	Loss: 119.075371
Train Epoch: 15 [51136/60000 (85%)]	Loss: 90.346451
Train Epoch: 15 [57536/60000 (96%)]	Loss: 73.507553

Test set: Average loss: 100.4977, Accuracy: 1752/10000 (18%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 88.613220
Train Epoch: 16 [12736/60000 (21%)]	Loss: 102.454803
Train Epoch: 16 [19136/60000 (32%)]	Loss: 106.158630
Train Epoch: 16 [25536/60000 (43%)]	Loss: 97.697380
Train Epoch: 16 [31936/60000 (53%)]	Loss: 103.471092
Train Epoch: 16 [38336/60000 (64%)]	Loss: 93.454613
Train Epoch: 16 [44736/60000 (75%)]	Loss: 89.822746
Train Epoch: 16 [51136/60000 (85%)]	Loss: 99.632744
Train Epoch: 16 [57536/60000 (96%)]	Loss: 86.317726

Test set: Average loss: 95.5668, Accuracy: 1517/10000 (15%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 105.232819
Train Epoch: 17 [12736/60000 (21%)]	Loss: 78.158882
Train Epoch: 17 [19136/60000 (32%)]	Loss: 103.954643
Train Epoch: 17 [25536/60000 (43%)]	Loss: 93.267220
Train Epoch: 17 [31936/60000 (53%)]	Loss: 101.608887
Train Epoch: 17 [38336/60000 (64%)]	Loss: 103.021782
Train Epoch: 17 [44736/60000 (75%)]	Loss: 99.725395
Train Epoch: 17 [51136/60000 (85%)]	Loss: 100.450813
Train Epoch: 17 [57536/60000 (96%)]	Loss: 123.122192

Test set: Average loss: 96.8183, Accuracy: 1552/10000 (16%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.37 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4406491
