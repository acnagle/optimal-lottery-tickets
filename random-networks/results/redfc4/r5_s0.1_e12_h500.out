Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.223536
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.354595
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.591434
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.734150
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.232104
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.433798
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.372117
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.605690
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.426766

Test set: Average loss: 0.4709, Accuracy: 8678/10000 (87%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.866076
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.437657
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.430036
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.596023
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.305228
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.950491
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.701254
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.738625
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.236270

Test set: Average loss: 0.5452, Accuracy: 8615/10000 (86%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.751034
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.272251
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.130954
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.475664
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.578903
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.570119
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.761649
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.546795
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.668908

Test set: Average loss: 0.7195, Accuracy: 7981/10000 (80%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.501094
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.818117
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.641720
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.620014
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.587460
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.630394
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.008671
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.209538
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.600032

Test set: Average loss: 0.9763, Accuracy: 7660/10000 (77%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.843825
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.696259
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.632651
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.888700
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.095767
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.366266
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.283749
Train Epoch: 5 [51136/60000 (85%)]	Loss: 4.032856
Train Epoch: 5 [57536/60000 (96%)]	Loss: 4.216980

Test set: Average loss: 4.3552, Accuracy: 6749/10000 (67%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 3.886505
Train Epoch: 6 [12736/60000 (21%)]	Loss: 4.353273
Train Epoch: 6 [19136/60000 (32%)]	Loss: 8.807114
Train Epoch: 6 [25536/60000 (43%)]	Loss: 8.213277
Train Epoch: 6 [31936/60000 (53%)]	Loss: 14.088934
Train Epoch: 6 [38336/60000 (64%)]	Loss: 3.359578
Train Epoch: 6 [44736/60000 (75%)]	Loss: 7.693441
Train Epoch: 6 [51136/60000 (85%)]	Loss: 4.994507
Train Epoch: 6 [57536/60000 (96%)]	Loss: 4.145238

Test set: Average loss: 6.3551, Accuracy: 7301/10000 (73%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 7.223925
Train Epoch: 7 [12736/60000 (21%)]	Loss: 7.819317
Train Epoch: 7 [19136/60000 (32%)]	Loss: 8.083775
Train Epoch: 7 [25536/60000 (43%)]	Loss: 5.179796
Train Epoch: 7 [31936/60000 (53%)]	Loss: 5.860287
Train Epoch: 7 [38336/60000 (64%)]	Loss: 5.473680
Train Epoch: 7 [44736/60000 (75%)]	Loss: 4.828029
Train Epoch: 7 [51136/60000 (85%)]	Loss: 2.288685
Train Epoch: 7 [57536/60000 (96%)]	Loss: 8.708085

Test set: Average loss: 9.0355, Accuracy: 7070/10000 (71%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 3.736417
Train Epoch: 8 [12736/60000 (21%)]	Loss: 2.686056
Train Epoch: 8 [19136/60000 (32%)]	Loss: 5.917776
Train Epoch: 8 [25536/60000 (43%)]	Loss: 4.213281
Train Epoch: 8 [31936/60000 (53%)]	Loss: 5.924226
Train Epoch: 8 [38336/60000 (64%)]	Loss: 7.857557
Train Epoch: 8 [44736/60000 (75%)]	Loss: 7.480582
Train Epoch: 8 [51136/60000 (85%)]	Loss: 5.568089
Train Epoch: 8 [57536/60000 (96%)]	Loss: 3.537895

Test set: Average loss: 8.3760, Accuracy: 6746/10000 (67%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 5.350368
Train Epoch: 9 [12736/60000 (21%)]	Loss: 5.268571
Train Epoch: 9 [19136/60000 (32%)]	Loss: 4.902068
Train Epoch: 9 [25536/60000 (43%)]	Loss: 10.077217
Train Epoch: 9 [31936/60000 (53%)]	Loss: 3.614233
Train Epoch: 9 [38336/60000 (64%)]	Loss: 6.895516
Train Epoch: 9 [44736/60000 (75%)]	Loss: 4.276020
Train Epoch: 9 [51136/60000 (85%)]	Loss: 6.428099
Train Epoch: 9 [57536/60000 (96%)]	Loss: 9.289873

Test set: Average loss: 10.0333, Accuracy: 6688/10000 (67%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.968034
Train Epoch: 10 [12736/60000 (21%)]	Loss: 2.951173
Train Epoch: 10 [19136/60000 (32%)]	Loss: 2.424385
Train Epoch: 10 [25536/60000 (43%)]	Loss: 4.420706
Train Epoch: 10 [31936/60000 (53%)]	Loss: 2.623614
Train Epoch: 10 [38336/60000 (64%)]	Loss: 3.878481
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.565285
Train Epoch: 10 [51136/60000 (85%)]	Loss: 5.178199
Train Epoch: 10 [57536/60000 (96%)]	Loss: 4.480571

Test set: Average loss: 4.3809, Accuracy: 7736/10000 (77%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 2.197085
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.643493
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.987561
Train Epoch: 11 [25536/60000 (43%)]	Loss: 2.596006
Train Epoch: 11 [31936/60000 (53%)]	Loss: 2.439755
Train Epoch: 11 [38336/60000 (64%)]	Loss: 2.987150
Train Epoch: 11 [44736/60000 (75%)]	Loss: 2.612311
Train Epoch: 11 [51136/60000 (85%)]	Loss: 2.622182
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.551363

Test set: Average loss: 3.4186, Accuracy: 7772/10000 (78%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.868440
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.891447
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.772383
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.282020
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.851964
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.617489
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.636329
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.269798
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.619070

Test set: Average loss: 0.4828, Accuracy: 8794/10000 (88%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.40 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4046778
