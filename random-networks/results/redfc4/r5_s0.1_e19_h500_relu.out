Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.513897
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.426654
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.389319
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.504161
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.208077
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.357248
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.254479
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.572163
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.447524

Test set: Average loss: 0.3221, Accuracy: 8920/10000 (89%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.273748
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.197166
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.342693
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.155332
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.204719
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.593086
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.278673
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.398750
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.203375

Test set: Average loss: 0.2980, Accuracy: 9090/10000 (91%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.135777
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.202600
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.039090
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.261719
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.297327
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.213330
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.320322
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.228019
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.316222

Test set: Average loss: 0.2846, Accuracy: 9094/10000 (91%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.376409
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.366626
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.446679
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.315295
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.269861
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.175486
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.347311
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.151794
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.236975

Test set: Average loss: 0.3439, Accuracy: 8875/10000 (89%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.531488
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.201057
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.420602
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.174218
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.371520
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.499300
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.382584
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.319865
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.271806

Test set: Average loss: 0.4495, Accuracy: 8580/10000 (86%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.246420
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.275251
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.447373
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.402031
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.516209
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.255987
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.567529
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.327654
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.234228

Test set: Average loss: 0.3924, Accuracy: 8739/10000 (87%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.454382
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.499587
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.294000
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.479302
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.347122
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.442601
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.351062
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.867390
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.424787

Test set: Average loss: 0.3890, Accuracy: 8789/10000 (88%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.315135
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.363606
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.452773
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.377812
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.349541
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.353680
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.355013
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.299511
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.147581

Test set: Average loss: 0.6072, Accuracy: 7976/10000 (80%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.212231
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.493245
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.391016
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.597310
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.426565
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.807145
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.332003
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.303949
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.299762

Test set: Average loss: 0.5105, Accuracy: 8444/10000 (84%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.330570
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.422248
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.711161
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.648794
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.402365
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.576708
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.529294
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.882779
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.696676

Test set: Average loss: 0.5833, Accuracy: 8115/10000 (81%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.552160
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.436994
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.762353
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.538755
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.899627
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.368562
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.722596
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.629448
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.490154

Test set: Average loss: 1.0732, Accuracy: 7093/10000 (71%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.565739
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.628949
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.635808
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.550373
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.435056
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.318923
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.570598
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.831420
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.426528

Test set: Average loss: 1.2849, Accuracy: 7048/10000 (70%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.679376
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.618398
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.965659
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.800896
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.935653
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.555903
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.428555
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.787119
Train Epoch: 13 [57536/60000 (96%)]	Loss: 1.676309

Test set: Average loss: 1.0119, Accuracy: 7410/10000 (74%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.922510
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.908585
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.237029
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.420930
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.930439
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.747297
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.656521
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.945120
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.790835

Test set: Average loss: 0.8096, Accuracy: 7902/10000 (79%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.711107
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.662951
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.582835
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.769954
Train Epoch: 15 [31936/60000 (53%)]	Loss: 1.292409
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.154746
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.783598
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.980711
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.033198

Test set: Average loss: 1.7485, Accuracy: 6364/10000 (64%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.463926
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.391124
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.685478
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.437688
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.471467
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.440348
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.596550
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.683588
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.769141

Test set: Average loss: 0.7377, Accuracy: 8084/10000 (81%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.378171
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.567529
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.323069
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.618034
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.537330
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.305206
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.284133
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.350174
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.232762

Test set: Average loss: 0.4204, Accuracy: 8781/10000 (88%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.295171
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.329426
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.339012
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.326140
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.279352
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.202352
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.522899
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.347239
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.186290

Test set: Average loss: 0.3210, Accuracy: 8963/10000 (90%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.462282
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.184492
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.205263
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.290941
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.166449
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.302718
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.172593
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.174073
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.118374

Test set: Average loss: 0.2039, Accuracy: 9332/10000 (93%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=True, wd=0.0005)


Total time spent pruning/training: 3.80 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4046778
