Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.302585
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.302585
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.302585
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.302585
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.302585
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.302585
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.302585
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.302585
Train Epoch: 1 [57536/60000 (96%)]	Loss: 2.302585

Test set: Average loss: 2.3026, Accuracy: 1100/10000 (11%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.302585
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.302585
Train Epoch: 2 [19136/60000 (32%)]	Loss: 2.302585
Train Epoch: 2 [25536/60000 (43%)]	Loss: 2.302585
Train Epoch: 2 [31936/60000 (53%)]	Loss: 2.302585
Train Epoch: 2 [38336/60000 (64%)]	Loss: 2.302585
Train Epoch: 2 [44736/60000 (75%)]	Loss: 2.302585
Train Epoch: 2 [51136/60000 (85%)]	Loss: 2.302585
Train Epoch: 2 [57536/60000 (96%)]	Loss: 2.302585

Test set: Average loss: 2.3026, Accuracy: 1100/10000 (11%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 2.302585
Train Epoch: 3 [12736/60000 (21%)]	Loss: 2.302585
Train Epoch: 3 [19136/60000 (32%)]	Loss: 2.302585
Train Epoch: 3 [25536/60000 (43%)]	Loss: 2.302585
Train Epoch: 3 [31936/60000 (53%)]	Loss: 2.302585
Train Epoch: 3 [38336/60000 (64%)]	Loss: 2.302586
Train Epoch: 3 [44736/60000 (75%)]	Loss: 2.302585
Train Epoch: 3 [51136/60000 (85%)]	Loss: 2.302585
Train Epoch: 3 [57536/60000 (96%)]	Loss: 2.302585

Test set: Average loss: 2.3026, Accuracy: 1100/10000 (11%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 2.302585
Train Epoch: 4 [12736/60000 (21%)]	Loss: 2.302585
Train Epoch: 4 [19136/60000 (32%)]	Loss: 2.302585
Train Epoch: 4 [25536/60000 (43%)]	Loss: 2.302585
Train Epoch: 4 [31936/60000 (53%)]	Loss: 2.302585
Train Epoch: 4 [38336/60000 (64%)]	Loss: 2.302585
Train Epoch: 4 [44736/60000 (75%)]	Loss: 2.302569
Train Epoch: 4 [51136/60000 (85%)]	Loss: 2.302509
Train Epoch: 4 [57536/60000 (96%)]	Loss: 2.302471

Test set: Average loss: 2.3024, Accuracy: 1065/10000 (11%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 2.302509
Train Epoch: 5 [12736/60000 (21%)]	Loss: 2.302562
Train Epoch: 5 [19136/60000 (32%)]	Loss: 2.302186
Train Epoch: 5 [25536/60000 (43%)]	Loss: 2.302410
Train Epoch: 5 [31936/60000 (53%)]	Loss: 2.302016
Train Epoch: 5 [38336/60000 (64%)]	Loss: 2.302278
Train Epoch: 5 [44736/60000 (75%)]	Loss: 2.302260
Train Epoch: 5 [51136/60000 (85%)]	Loss: 2.302241
Train Epoch: 5 [57536/60000 (96%)]	Loss: 2.302387

Test set: Average loss: 2.3010, Accuracy: 1018/10000 (10%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 2.299024
Train Epoch: 6 [12736/60000 (21%)]	Loss: 2.303140
Train Epoch: 6 [19136/60000 (32%)]	Loss: 2.293498
Train Epoch: 6 [25536/60000 (43%)]	Loss: 2.290111
Train Epoch: 6 [31936/60000 (53%)]	Loss: 2.279460
Train Epoch: 6 [38336/60000 (64%)]	Loss: 2.259200
Train Epoch: 6 [44736/60000 (75%)]	Loss: 2.261101
Train Epoch: 6 [51136/60000 (85%)]	Loss: 2.139047
Train Epoch: 6 [57536/60000 (96%)]	Loss: 2.053945

Test set: Average loss: 1.9175, Accuracy: 3023/10000 (30%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.867373
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.663652
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.719711
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.506767
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.407394
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.660739
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.330084
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.385991
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.519814

Test set: Average loss: 1.3853, Accuracy: 5948/10000 (59%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.356418
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.296085
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.233619
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.331458
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.309170
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.352092
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.249114
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.327333
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.340669

Test set: Average loss: 1.3062, Accuracy: 6348/10000 (63%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.256740
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.268954
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.365636
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.346588
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.324654
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.373211
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.427283
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.229603
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.392819

Test set: Average loss: 1.3314, Accuracy: 5756/10000 (58%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.282722
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.283667
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.305936
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.435109
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.408366
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.347499
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.312050
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.396562
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.312672

Test set: Average loss: 1.3666, Accuracy: 6244/10000 (62%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.309940
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.280393
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.371260
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.419934
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.382338
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.290921
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.281365
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.368810
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.343964

Test set: Average loss: 1.4694, Accuracy: 5741/10000 (57%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 1.448657
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.437516
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.275090
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.361902
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.309602
Train Epoch: 12 [38336/60000 (64%)]	Loss: 1.073432
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.358943
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.269628
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.493169

Test set: Average loss: 1.3220, Accuracy: 5829/10000 (58%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.319762
Train Epoch: 13 [12736/60000 (21%)]	Loss: 1.286677
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.361579
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.331447
Train Epoch: 13 [31936/60000 (53%)]	Loss: 1.406166
Train Epoch: 13 [38336/60000 (64%)]	Loss: 1.302967
Train Epoch: 13 [44736/60000 (75%)]	Loss: 1.272348
Train Epoch: 13 [51136/60000 (85%)]	Loss: 1.206582
Train Epoch: 13 [57536/60000 (96%)]	Loss: 1.279529

Test set: Average loss: 1.2777, Accuracy: 6389/10000 (64%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.317107
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.369265
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.267068
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.311083
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.303448
Train Epoch: 14 [38336/60000 (64%)]	Loss: 1.386281
Train Epoch: 14 [44736/60000 (75%)]	Loss: 1.216812
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.266402
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.342695

Test set: Average loss: 1.2421, Accuracy: 6426/10000 (64%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 1.411897
Train Epoch: 15 [12736/60000 (21%)]	Loss: 1.123732
Train Epoch: 15 [19136/60000 (32%)]	Loss: 1.342325
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.202747
Train Epoch: 15 [31936/60000 (53%)]	Loss: 1.339755
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.232408
Train Epoch: 15 [44736/60000 (75%)]	Loss: 1.295699
Train Epoch: 15 [51136/60000 (85%)]	Loss: 1.176218
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.183963

Test set: Average loss: 1.1779, Accuracy: 6855/10000 (69%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.954588
Train Epoch: 16 [12736/60000 (21%)]	Loss: 1.102484
Train Epoch: 16 [19136/60000 (32%)]	Loss: 1.132801
Train Epoch: 16 [25536/60000 (43%)]	Loss: 1.109394
Train Epoch: 16 [31936/60000 (53%)]	Loss: 1.207763
Train Epoch: 16 [38336/60000 (64%)]	Loss: 1.123579
Train Epoch: 16 [44736/60000 (75%)]	Loss: 1.055964
Train Epoch: 16 [51136/60000 (85%)]	Loss: 1.262360
Train Epoch: 16 [57536/60000 (96%)]	Loss: 1.222786

Test set: Average loss: 1.1538, Accuracy: 7122/10000 (71%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 1.180629
Train Epoch: 17 [12736/60000 (21%)]	Loss: 1.174424
Train Epoch: 17 [19136/60000 (32%)]	Loss: 1.107287
Train Epoch: 17 [25536/60000 (43%)]	Loss: 1.114433
Train Epoch: 17 [31936/60000 (53%)]	Loss: 1.025687
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.950991
Train Epoch: 17 [44736/60000 (75%)]	Loss: 1.089213
Train Epoch: 17 [51136/60000 (85%)]	Loss: 1.195273
Train Epoch: 17 [57536/60000 (96%)]	Loss: 1.101862

Test set: Average loss: 1.0360, Accuracy: 7234/10000 (72%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 1.000680
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.937421
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.948114
Train Epoch: 18 [25536/60000 (43%)]	Loss: 1.009122
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.852436
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.895533
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.976334
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.974730
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.853068

Test set: Average loss: 0.9710, Accuracy: 7268/10000 (73%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 1.094863
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.962546
Train Epoch: 19 [19136/60000 (32%)]	Loss: 1.061977
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.997288
Train Epoch: 19 [31936/60000 (53%)]	Loss: 1.001012
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.850425
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.905134
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.852247
Train Epoch: 19 [57536/60000 (96%)]	Loss: 1.032909

Test set: Average loss: 0.9371, Accuracy: 7461/10000 (75%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.78 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 112410
