Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.289122
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.147004
Train Epoch: 1 [19136/60000 (32%)]	Loss: 1.863841
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.630867
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.389572
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.312210
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.253644
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.326354
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.322239

Test set: Average loss: 1.1150, Accuracy: 6762/10000 (68%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.179913
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.948602
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.152154
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.839428
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.918811
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.959205
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.024782
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.865066
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.889312

Test set: Average loss: 0.8929, Accuracy: 7595/10000 (76%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.093402
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.879378
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.676188
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.943701
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.722507
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.877305
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.805258
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.745795
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.827651

Test set: Average loss: 0.9152, Accuracy: 7140/10000 (71%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.947626
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.955368
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.936095
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.986151
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.014459
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.879779
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.916242
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.984700
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.676757

Test set: Average loss: 0.8678, Accuracy: 7644/10000 (76%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.102590
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.996015
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.757604
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.763910
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.860349
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.060268
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.798501
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.848537
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.945243

Test set: Average loss: 0.9463, Accuracy: 7086/10000 (71%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.854647
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.897781
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.924002
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.990641
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.897435
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.762928
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.790579
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.836246
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.744257

Test set: Average loss: 0.8569, Accuracy: 7424/10000 (74%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.905991
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.724055
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.996831
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.834853
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.734611
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.050258
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.867408
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.805082
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.936134

Test set: Average loss: 0.8753, Accuracy: 7396/10000 (74%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.800328
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.746364
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.777845
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.720503
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.985121
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.733211
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.830381
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.829080
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.770139

Test set: Average loss: 0.8004, Accuracy: 7842/10000 (78%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.693809
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.800884
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.847415
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.908914
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.762957
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.840369
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.797524
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.749241
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.690890

Test set: Average loss: 0.7799, Accuracy: 7754/10000 (78%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.665345
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.712212
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.661046
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.919310
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.701274
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.850931
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.768122
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.816913
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.609782

Test set: Average loss: 0.7179, Accuracy: 7891/10000 (79%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.759583
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.604614
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.573565
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.791466
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.888862
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.627824
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.686811
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.735013
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.613040

Test set: Average loss: 0.6851, Accuracy: 8086/10000 (81%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.775428
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.735089
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.597458
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.483925
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.615975
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.541778
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.770845
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.495182
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.924049

Test set: Average loss: 0.6819, Accuracy: 8014/10000 (80%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=12, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=True, wd=0.0005)


Total time spent pruning/training: 2.42 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 449641
