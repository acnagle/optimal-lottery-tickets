Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.913958
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.817320
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.377304
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.623030
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.357349
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.364885
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.281615
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.378537
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.531738

Test set: Average loss: 0.3071, Accuracy: 9072/10000 (91%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.338604
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.184329
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.269295
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.152153
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.306040
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.308295
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.345071
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.205282
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.250313

Test set: Average loss: 0.2583, Accuracy: 9155/10000 (92%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.196987
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.206782
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.044867
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.193644
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.140007
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.208057
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.391302
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.098646
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.175043

Test set: Average loss: 0.2150, Accuracy: 9303/10000 (93%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.144248
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.234987
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.308323
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.460795
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.279096
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.365372
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.196534
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.140222
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.144854

Test set: Average loss: 0.2173, Accuracy: 9321/10000 (93%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.557213
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.178653
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.215720
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.093381
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.238467
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.306884
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.213672
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.305633
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.309226

Test set: Average loss: 0.3054, Accuracy: 9019/10000 (90%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.120215
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.154339
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.335753
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.375449
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.540900
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.152365
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.309601
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.254586
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.261126

Test set: Average loss: 0.2586, Accuracy: 9189/10000 (92%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.142020
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.145582
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.176976
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.305570
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.234441
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.241164
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.190718
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.202785
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.234720

Test set: Average loss: 0.2298, Accuracy: 9278/10000 (93%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.111533
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.163491
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.286426
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.211069
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.220959
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.265044
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.181493
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.168436
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.154375

Test set: Average loss: 0.1888, Accuracy: 9418/10000 (94%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.212259
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.192102
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.249558
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.238481
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.110929
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.233999
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.184381
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.136924
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.170493

Test set: Average loss: 0.2273, Accuracy: 9252/10000 (93%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.163861
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.168040
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.143569
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.335640
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.142497
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.106868
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.248207
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.248353
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.194552

Test set: Average loss: 0.2000, Accuracy: 9324/10000 (93%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.117518
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.119136
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.068804
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.082942
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.338236
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.188400
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.173502
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.180991
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.064251

Test set: Average loss: 0.1579, Accuracy: 9530/10000 (95%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.241091
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.092235
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.131475
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.028641
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.240908
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.161558
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.254670
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.048502
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.473423

Test set: Average loss: 0.1361, Accuracy: 9597/10000 (96%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.068351
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.193399
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.046660
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.053562
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.102694
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.093546
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.057491
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.071122
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.104514

Test set: Average loss: 0.1120, Accuracy: 9652/10000 (97%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.103379
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.095628
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.148098
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.120626
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.087607
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.067287
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.098579
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.049363
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.111914

Test set: Average loss: 0.0898, Accuracy: 9708/10000 (97%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=14, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.80 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 449641
