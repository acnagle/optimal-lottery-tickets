Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=3, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.0, use_relu=True, wd=0.0005) 

Pruning a Four-Layer Fully Connected Redundant Network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 38.691383
Train Epoch: 1 [12736/60000 (21%)]	Loss: 47.710945
Train Epoch: 1 [19136/60000 (32%)]	Loss: 43.611263
Train Epoch: 1 [25536/60000 (43%)]	Loss: 41.637352
Train Epoch: 1 [31936/60000 (53%)]	Loss: 39.589924
Train Epoch: 1 [38336/60000 (64%)]	Loss: 45.375179
Train Epoch: 1 [44736/60000 (75%)]	Loss: 43.226616
Train Epoch: 1 [51136/60000 (85%)]	Loss: 37.791367
Train Epoch: 1 [57536/60000 (96%)]	Loss: 40.037407

Test set: Average loss: 41.6253, Accuracy: 1340/10000 (13%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 30.151495
Train Epoch: 2 [12736/60000 (21%)]	Loss: 44.133835
Train Epoch: 2 [19136/60000 (32%)]	Loss: 45.287285
Train Epoch: 2 [25536/60000 (43%)]	Loss: 39.701027
Train Epoch: 2 [31936/60000 (53%)]	Loss: 42.230289
Train Epoch: 2 [38336/60000 (64%)]	Loss: 37.854401
Train Epoch: 2 [44736/60000 (75%)]	Loss: 46.130058
Train Epoch: 2 [51136/60000 (85%)]	Loss: 40.037510
Train Epoch: 2 [57536/60000 (96%)]	Loss: 42.865688

Test set: Average loss: 41.5690, Accuracy: 1340/10000 (13%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 32.218151
Train Epoch: 3 [12736/60000 (21%)]	Loss: 37.723251
Train Epoch: 3 [19136/60000 (32%)]	Loss: 37.545769
Train Epoch: 3 [25536/60000 (43%)]	Loss: 38.415375
Train Epoch: 3 [31936/60000 (53%)]	Loss: 41.311199
Train Epoch: 3 [38336/60000 (64%)]	Loss: 46.224094
Train Epoch: 3 [44736/60000 (75%)]	Loss: 39.438995
Train Epoch: 3 [51136/60000 (85%)]	Loss: 32.623119
Train Epoch: 3 [57536/60000 (96%)]	Loss: 39.728981

Test set: Average loss: 41.6480, Accuracy: 1340/10000 (13%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=3, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='redfc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.0, use_relu=True, wd=0.0005)


Total time spent pruning/training: 0.66 minutes
Total number of parameters in model: 4496420
Number of parameters in pruned model: 4496420
