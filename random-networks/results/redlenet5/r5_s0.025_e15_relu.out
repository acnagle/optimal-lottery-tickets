Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=15, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=True, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.121334
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.106087
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.776698
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.472237
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.802008
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.781766
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.677500
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.612609
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.618207

Test set: Average loss: 0.5544, Accuracy: 8327/10000 (83%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.717131
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.427219
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.526468
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.571960
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.685958
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.785212
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.395576
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.542467
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.550085

Test set: Average loss: 0.5252, Accuracy: 8240/10000 (82%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.488152
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.539466
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.367781
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.350270
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.517515
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.474717
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.615391
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.497501
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.609490

Test set: Average loss: 0.4555, Accuracy: 8482/10000 (85%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.779148
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.565468
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.808668
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.637901
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.449225
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.486399
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.466989
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.340903
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.676912

Test set: Average loss: 0.5855, Accuracy: 8043/10000 (80%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.304435
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.568926
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.508630
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.666786
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.679652
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.653909
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.520937
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.549397
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.623128

Test set: Average loss: 0.5675, Accuracy: 8117/10000 (81%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.447225
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.394733
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.675187
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.711329
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.614811
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.547978
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.566518
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.509980
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.393690

Test set: Average loss: 0.5444, Accuracy: 8304/10000 (83%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.609510
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.584338
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.721339
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.541526
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.672025
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.395213
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.884516
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.729570
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.613916

Test set: Average loss: 1.0697, Accuracy: 6851/10000 (69%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.395715
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.635284
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.516081
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.715930
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.531099
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.625126
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.838415
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.662921
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.426538

Test set: Average loss: 0.6494, Accuracy: 7907/10000 (79%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.517464
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.799165
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.513696
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.473913
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.349511
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.591291
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.579667
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.831319
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.602946

Test set: Average loss: 0.7229, Accuracy: 7488/10000 (75%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.476752
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.703976
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.686209
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.894424
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.620458
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.650808
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.576331
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.538184
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.672070

Test set: Average loss: 0.8234, Accuracy: 7334/10000 (73%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.634646
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.483610
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.559053
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.462707
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.725824
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.569263
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.614744
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.776744
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.930466

Test set: Average loss: 0.7255, Accuracy: 7612/10000 (76%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.595493
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.589802
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.739266
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.811231
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.645630
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.416487
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.779642
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.532636
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.628801

Test set: Average loss: 0.6834, Accuracy: 7910/10000 (79%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.081702
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.653345
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.892626
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.826230
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.743229
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.583009
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.798059
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.812326
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.703383

Test set: Average loss: 0.7411, Accuracy: 7519/10000 (75%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.501807
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.650100
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.812217
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.679219
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.104167
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.510207
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.338654
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.643343
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.849050

Test set: Average loss: 0.5818, Accuracy: 8172/10000 (82%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.375915
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.502198
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.729094
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.761111
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.737220
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.720524
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.578278
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.933473
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.601133

Test set: Average loss: 0.7181, Accuracy: 7575/10000 (76%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=15, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.025, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.65 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 292730
