Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=8, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.589047
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.203286
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.767450
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.981925
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.849517
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.697098
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.336214
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.568365
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.212293

Test set: Average loss: 1.8664, Accuracy: 5650/10000 (56%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.938280
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.340025
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.689135
Train Epoch: 2 [25536/60000 (43%)]	Loss: 2.902697
Train Epoch: 2 [31936/60000 (53%)]	Loss: 3.651831
Train Epoch: 2 [38336/60000 (64%)]	Loss: 3.930672
Train Epoch: 2 [44736/60000 (75%)]	Loss: 2.436728
Train Epoch: 2 [51136/60000 (85%)]	Loss: 3.336519
Train Epoch: 2 [57536/60000 (96%)]	Loss: 2.621023

Test set: Average loss: 3.1456, Accuracy: 4587/10000 (46%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 3.721899
Train Epoch: 3 [12736/60000 (21%)]	Loss: 3.681054
Train Epoch: 3 [19136/60000 (32%)]	Loss: 4.738140
Train Epoch: 3 [25536/60000 (43%)]	Loss: 4.496629
Train Epoch: 3 [31936/60000 (53%)]	Loss: 4.070882
Train Epoch: 3 [38336/60000 (64%)]	Loss: 4.644704
Train Epoch: 3 [44736/60000 (75%)]	Loss: 4.337997
Train Epoch: 3 [51136/60000 (85%)]	Loss: 3.926986
Train Epoch: 3 [57536/60000 (96%)]	Loss: 4.306954

Test set: Average loss: 4.9686, Accuracy: 2913/10000 (29%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 5.416668
Train Epoch: 4 [12736/60000 (21%)]	Loss: 6.584045
Train Epoch: 4 [19136/60000 (32%)]	Loss: 4.775598
Train Epoch: 4 [25536/60000 (43%)]	Loss: 4.965688
Train Epoch: 4 [31936/60000 (53%)]	Loss: 4.974969
Train Epoch: 4 [38336/60000 (64%)]	Loss: 4.699109
Train Epoch: 4 [44736/60000 (75%)]	Loss: 6.525899
Train Epoch: 4 [51136/60000 (85%)]	Loss: 5.317861
Train Epoch: 4 [57536/60000 (96%)]	Loss: 5.469068

Test set: Average loss: 6.3382, Accuracy: 2165/10000 (22%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 6.345523
Train Epoch: 5 [12736/60000 (21%)]	Loss: 5.746537
Train Epoch: 5 [19136/60000 (32%)]	Loss: 6.145173
Train Epoch: 5 [25536/60000 (43%)]	Loss: 6.491093
Train Epoch: 5 [31936/60000 (53%)]	Loss: 6.592914
Train Epoch: 5 [38336/60000 (64%)]	Loss: 6.644892
Train Epoch: 5 [44736/60000 (75%)]	Loss: 6.443943
Train Epoch: 5 [51136/60000 (85%)]	Loss: 7.031828
Train Epoch: 5 [57536/60000 (96%)]	Loss: 6.219269

Test set: Average loss: 7.5469, Accuracy: 2536/10000 (25%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 7.084211
Train Epoch: 6 [12736/60000 (21%)]	Loss: 6.411640
Train Epoch: 6 [19136/60000 (32%)]	Loss: 7.428519
Train Epoch: 6 [25536/60000 (43%)]	Loss: 7.953483
Train Epoch: 6 [31936/60000 (53%)]	Loss: 5.982699
Train Epoch: 6 [38336/60000 (64%)]	Loss: 7.943942
Train Epoch: 6 [44736/60000 (75%)]	Loss: 7.133303
Train Epoch: 6 [51136/60000 (85%)]	Loss: 7.266660
Train Epoch: 6 [57536/60000 (96%)]	Loss: 7.330535

Test set: Average loss: 6.8972, Accuracy: 2515/10000 (25%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 6.709961
Train Epoch: 7 [12736/60000 (21%)]	Loss: 7.887193
Train Epoch: 7 [19136/60000 (32%)]	Loss: 7.813305
Train Epoch: 7 [25536/60000 (43%)]	Loss: 6.650131
Train Epoch: 7 [31936/60000 (53%)]	Loss: 6.307583
Train Epoch: 7 [38336/60000 (64%)]	Loss: 7.702439
Train Epoch: 7 [44736/60000 (75%)]	Loss: 8.185510
Train Epoch: 7 [51136/60000 (85%)]	Loss: 8.361146
Train Epoch: 7 [57536/60000 (96%)]	Loss: 7.510768

Test set: Average loss: 7.3799, Accuracy: 2103/10000 (21%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 6.424797
Train Epoch: 8 [12736/60000 (21%)]	Loss: 5.899275
Train Epoch: 8 [19136/60000 (32%)]	Loss: 6.701409
Train Epoch: 8 [25536/60000 (43%)]	Loss: 7.261532
Train Epoch: 8 [31936/60000 (53%)]	Loss: 6.081715
Train Epoch: 8 [38336/60000 (64%)]	Loss: 7.061098
Train Epoch: 8 [44736/60000 (75%)]	Loss: 6.483221
Train Epoch: 8 [51136/60000 (85%)]	Loss: 6.278054
Train Epoch: 8 [57536/60000 (96%)]	Loss: 7.680274

Test set: Average loss: 8.3227, Accuracy: 1472/10000 (15%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=8, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.02, use_relu=False, wd=0.0005)


Total time spent pruning/training: 0.87 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 294218
