Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=13, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=True, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.186467
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.967764
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.472087
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.512141
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.611271
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.665722
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.427091
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.373887
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.407097

Test set: Average loss: 0.3480, Accuracy: 8962/10000 (90%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.493788
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.226163
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.315148
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.324220
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.559537
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.472207
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.236777
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.384358
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.328898

Test set: Average loss: 0.3030, Accuracy: 9059/10000 (91%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.398007
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.369214
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.223165
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.146618
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.266486
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.228161
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.207376
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.200942
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.302279

Test set: Average loss: 0.2480, Accuracy: 9246/10000 (92%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.452267
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.228674
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.383408
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.321156
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.239361
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.279108
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.257255
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.232739
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.295090

Test set: Average loss: 0.2294, Accuracy: 9300/10000 (93%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.131158
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.254805
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.170730
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.207043
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.174843
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.104784
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.170299
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.145986
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.278813

Test set: Average loss: 0.2107, Accuracy: 9329/10000 (93%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.190204
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.139199
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.274368
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.284998
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.203202
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.245348
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.099016
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.204074
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.225691

Test set: Average loss: 0.1945, Accuracy: 9411/10000 (94%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.293127
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.109971
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.298216
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.159692
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.179378
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.051354
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.251074
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.240968
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.114823

Test set: Average loss: 0.1683, Accuracy: 9493/10000 (95%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.180648
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.375433
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.249645
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.171510
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.077159
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.171595
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.058320
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.186793
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.183179

Test set: Average loss: 0.1602, Accuracy: 9531/10000 (95%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.176857
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.147183
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.161186
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.123733
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.064222
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.087216
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.316286
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.224057
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.185771

Test set: Average loss: 0.1670, Accuracy: 9496/10000 (95%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.056601
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.273175
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.167857
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.171694
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.258130
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.207689
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.186336
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.169780
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.083533

Test set: Average loss: 0.1732, Accuracy: 9483/10000 (95%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.071825
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.083279
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.199649
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.106153
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.118474
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.114409
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.082421
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.151201
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.219488

Test set: Average loss: 0.1537, Accuracy: 9535/10000 (95%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.095209
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.154693
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.220475
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.151851
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.104345
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.109373
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.220003
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.166245
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.211032

Test set: Average loss: 0.1548, Accuracy: 9559/10000 (96%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.091723
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.116895
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.115193
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.150678
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.337147
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.066154
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.169528
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.200434
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.183234

Test set: Average loss: 0.1501, Accuracy: 9550/10000 (96%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=13, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.41 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 270408
