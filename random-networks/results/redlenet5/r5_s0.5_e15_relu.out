Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=15, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=True, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 1.928482
Train Epoch: 1 [12736/60000 (21%)]	Loss: 1.544259
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.911311
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.696201
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.851145
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.988208
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.712000
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.769431
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.587024

Test set: Average loss: 0.5910, Accuracy: 8313/10000 (83%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.577629
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.453274
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.500839
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.570108
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.618023
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.639530
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.287061
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.440739
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.431882

Test set: Average loss: 0.4390, Accuracy: 8892/10000 (89%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.508976
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.481233
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.418644
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.325405
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.419453
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.563453
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.366296
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.356393
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.517290

Test set: Average loss: 0.4449, Accuracy: 8619/10000 (86%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.535681
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.454505
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.481118
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.465972
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.471694
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.421135
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.352692
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.412264
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.453365

Test set: Average loss: 0.3823, Accuracy: 8918/10000 (89%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.350925
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.440755
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.377057
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.386426
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.463158
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.199317
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.417198
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.292558
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.400263

Test set: Average loss: 0.3280, Accuracy: 9124/10000 (91%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.276541
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.282895
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.395442
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.323606
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.464431
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.425063
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.284981
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.391979
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.351321

Test set: Average loss: 0.3174, Accuracy: 9168/10000 (92%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.421072
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.346538
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.507170
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.292412
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.413757
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.199238
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.306046
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.346742
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.251783

Test set: Average loss: 0.3176, Accuracy: 9114/10000 (91%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.266040
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.572167
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.416474
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.363582
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.178972
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.310803
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.179400
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.353125
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.303705

Test set: Average loss: 0.3342, Accuracy: 9067/10000 (91%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.348311
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.325462
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.425522
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.280677
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.182153
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.212812
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.473284
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.424965
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.269487

Test set: Average loss: 0.2914, Accuracy: 9232/10000 (92%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.165104
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.388059
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.250010
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.341385
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.415136
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.368684
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.386444
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.263549
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.222950

Test set: Average loss: 0.2956, Accuracy: 9226/10000 (92%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.222753
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.225968
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.327088
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.232158
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.297771
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.258074
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.214851
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.309681
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.388689

Test set: Average loss: 0.3060, Accuracy: 9136/10000 (91%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.360008
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.301430
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.415951
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.280655
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.292404
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.238120
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.341526
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.327520
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.290093

Test set: Average loss: 0.3012, Accuracy: 9170/10000 (92%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.309089
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.314942
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.266573
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.293635
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.443571
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.161420
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.428023
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.397449
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.338921

Test set: Average loss: 0.2936, Accuracy: 9233/10000 (92%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.214572
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.194466
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.377575
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.264372
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.401974
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.388545
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.149882
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.184703
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.373230

Test set: Average loss: 0.2892, Accuracy: 9216/10000 (92%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.296143
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.245028
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.341146
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.409255
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.305185
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.309109
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.289481
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.363935
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.235278

Test set: Average loss: 0.2906, Accuracy: 9216/10000 (92%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=15, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.5, use_relu=True, wd=0.0005)


Total time spent pruning/training: 1.64 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 151360
