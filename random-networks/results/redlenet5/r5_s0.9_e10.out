Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=10, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005) 

Training a RedLeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.301238
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.294530
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.290821
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.258794
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.265475
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.273849
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.245946
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.204273
Train Epoch: 1 [57536/60000 (96%)]	Loss: 2.089131

Test set: Average loss: 2.0859, Accuracy: 2683/10000 (27%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.021154
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.037421
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.958701
Train Epoch: 2 [25536/60000 (43%)]	Loss: 2.025899
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.897294
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.819045
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.685517
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.762985
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.693117

Test set: Average loss: 1.6600, Accuracy: 5074/10000 (51%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.739278
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.550526
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.625376
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.560979
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.423273
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.534062
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.448138
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.457542
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.449020

Test set: Average loss: 1.3974, Accuracy: 5485/10000 (55%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.598411
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.426604
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.452731
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.297344
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.328780
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.278601
Train Epoch: 4 [44736/60000 (75%)]	Loss: 1.297035
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.331892
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.303402

Test set: Average loss: 1.2102, Accuracy: 6665/10000 (67%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 1.160765
Train Epoch: 5 [12736/60000 (21%)]	Loss: 1.186389
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.010806
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.127467
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.400160
Train Epoch: 5 [38336/60000 (64%)]	Loss: 1.052408
Train Epoch: 5 [44736/60000 (75%)]	Loss: 1.145977
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.065511
Train Epoch: 5 [57536/60000 (96%)]	Loss: 1.166278

Test set: Average loss: 1.2044, Accuracy: 6044/10000 (60%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.039076
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.023988
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.061100
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.162676
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.170082
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.015617
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.145078
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.982613
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.140124

Test set: Average loss: 1.0686, Accuracy: 6753/10000 (68%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.164149
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.071053
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.975024
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.017893
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.196370
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.987993
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.117953
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.902425
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.914589

Test set: Average loss: 1.0239, Accuracy: 6819/10000 (68%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.964891
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.122821
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.036646
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.887620
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.885127
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.984525
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.822884
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.002064
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.900955

Test set: Average loss: 0.9635, Accuracy: 7065/10000 (71%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.941085
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.046504
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.989186
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.039984
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.798331
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.948638
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.088062
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.075209
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.946979

Test set: Average loss: 0.9539, Accuracy: 7219/10000 (72%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.764557
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.980397
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.862985
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.049556
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.015772
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.994625
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.952388
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.946621
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.001668

Test set: Average loss: 0.9349, Accuracy: 7222/10000 (72%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=10, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='redlenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.09 minutes
Total number of parameters in model: 300170
Number of parameters in pruned model: 32312
