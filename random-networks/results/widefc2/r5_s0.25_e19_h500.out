Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.25, use_relu=False, wd=0.0005) 

Pruning a Wide Two-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.434021
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.374906
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.285321
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.288763
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.218542
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.137963
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.246978
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.281482
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.156065

Test set: Average loss: 0.1634, Accuracy: 9536/10000 (95%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.156769
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.114878
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.101667
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.197274
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.164963
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.121263
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.149817
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.104077
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.060743

Test set: Average loss: 0.1258, Accuracy: 9629/10000 (96%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.103898
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.051459
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.043370
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.076916
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.169074
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.063406
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.091285
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.276924
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.051923

Test set: Average loss: 0.1129, Accuracy: 9654/10000 (97%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.064047
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.173243
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.052310
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.079247
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.110068
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.122336
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.120299
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.082306
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.051612

Test set: Average loss: 0.1219, Accuracy: 9620/10000 (96%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.027485
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.016885
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.038662
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.126814
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.149396
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.140822
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.053461
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.046537
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.045736

Test set: Average loss: 0.1236, Accuracy: 9628/10000 (96%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.134627
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.043920
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.084971
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.167446
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.058730
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.144047
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.127343
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.143307
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.078083

Test set: Average loss: 0.1316, Accuracy: 9595/10000 (96%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.045655
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.067048
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.199246
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.111540
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.179592
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.180432
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.168262
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.081140
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.081599

Test set: Average loss: 0.1472, Accuracy: 9520/10000 (95%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.180914
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.117030
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.039980
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.181359
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.201738
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.085966
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.101471
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.117027
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.237439

Test set: Average loss: 0.1719, Accuracy: 9444/10000 (94%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.159915
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.115867
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.089568
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.092131
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.133268
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.061998
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.099909
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.195633
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.321301

Test set: Average loss: 0.1664, Accuracy: 9457/10000 (95%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.163855
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.126280
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.104971
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.099902
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.287335
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.062579
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.174811
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.092777
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.242909

Test set: Average loss: 0.1845, Accuracy: 9387/10000 (94%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.120090
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.071599
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.051545
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.057688
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.167653
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.137464
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.079198
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.082896
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.088627

Test set: Average loss: 0.2081, Accuracy: 9303/10000 (93%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.059788
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.135201
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.254829
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.062770
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.110160
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.182020
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.057768
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.198957
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.213982

Test set: Average loss: 0.1911, Accuracy: 9372/10000 (94%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.274965
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.074236
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.132218
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.190751
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.167826
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.456307
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.081053
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.273095
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.259008

Test set: Average loss: 0.1602, Accuracy: 9486/10000 (95%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.142504
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.063188
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.098067
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.091000
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.126485
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.063873
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.103421
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.149439
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.156611

Test set: Average loss: 0.1178, Accuracy: 9655/10000 (97%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.167242
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.097446
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.061712
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.066398
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.211293
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.095267
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.041041
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.092588
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.091009

Test set: Average loss: 0.1432, Accuracy: 9519/10000 (95%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.053449
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.142483
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.050658
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.048245
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.043912
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.030773
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.033983
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.093378
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.047403

Test set: Average loss: 0.0911, Accuracy: 9733/10000 (97%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.038736
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.097453
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.008117
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.014596
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.035000
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.038052
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.046273
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.064595
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.029954

Test set: Average loss: 0.0853, Accuracy: 9744/10000 (97%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.042820
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.019808
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.014364
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.018843
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.020282
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.057994
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.028762
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.016063
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.023891

Test set: Average loss: 0.0676, Accuracy: 9793/10000 (98%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.017868
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.019940
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.016422
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.008822
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.017376
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.017675
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.012685
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.008461
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.016400

Test set: Average loss: 0.0640, Accuracy: 9806/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.25, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.02 minutes
Total number of parameters in model: 1991352
Number of parameters in pruned model: 1493514
