Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=18, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005) 

Pruning a Wide Two-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.459534
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.404926
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.302269
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.323539
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.278083
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.173084
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.316158
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.315274
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.173689

Test set: Average loss: 0.1899, Accuracy: 9467/10000 (95%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.229568
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.116090
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.147347
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.226815
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.236932
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.104474
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.163575
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.118317
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.088576

Test set: Average loss: 0.1501, Accuracy: 9575/10000 (96%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.140693
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.053653
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.064717
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.095805
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.190389
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.075150
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.125184
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.298977
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.082472

Test set: Average loss: 0.1212, Accuracy: 9638/10000 (96%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.102462
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.195184
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.092213
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.113425
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.133811
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.127112
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.133081
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.104667
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.073515

Test set: Average loss: 0.1249, Accuracy: 9628/10000 (96%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.042375
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.032244
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.049075
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.133032
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.133651
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.127085
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.068172
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.031899
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.054152

Test set: Average loss: 0.1124, Accuracy: 9683/10000 (97%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.156801
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.056313
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.076180
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.132150
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.050687
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.100182
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.059687
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.127725
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.060890

Test set: Average loss: 0.1031, Accuracy: 9694/10000 (97%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.034371
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.060098
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.108911
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.085678
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.135114
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.134676
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.147809
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.029454
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.047195

Test set: Average loss: 0.0959, Accuracy: 9722/10000 (97%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.105471
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.066836
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.047866
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.119361
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.187480
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.083420
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.068648
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.042603
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.142423

Test set: Average loss: 0.0990, Accuracy: 9697/10000 (97%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.069358
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.037669
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.036162
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.071405
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.057910
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.032772
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.052722
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.089451
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.114167

Test set: Average loss: 0.0980, Accuracy: 9710/10000 (97%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.114244
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.070200
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.066975
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.064483
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.179046
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.047118
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.080786
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.030680
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.080205

Test set: Average loss: 0.0990, Accuracy: 9692/10000 (97%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.037938
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.017937
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.029192
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.032831
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.052386
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.090967
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.047934
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.034720
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.028518

Test set: Average loss: 0.0897, Accuracy: 9745/10000 (97%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.044282
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.060915
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.063246
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.020850
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.035170
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.096238
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.046451
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.090460
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.092677

Test set: Average loss: 0.0964, Accuracy: 9704/10000 (97%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.101832
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.026621
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.077915
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.067059
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.037980
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.145424
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.025660
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.100736
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.113875

Test set: Average loss: 0.0816, Accuracy: 9773/10000 (98%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.054065
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.036619
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.057219
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.043468
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.050316
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.024906
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.025011
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.091903
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.080513

Test set: Average loss: 0.0804, Accuracy: 9757/10000 (98%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.047557
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.038542
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.033421
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.043936
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.101575
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.042290
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.024583
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.032149
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.036722

Test set: Average loss: 0.0759, Accuracy: 9785/10000 (98%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.036621
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.069833
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.022859
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.023548
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.035885
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.025182
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.017857
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.062776
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.028695

Test set: Average loss: 0.0720, Accuracy: 9796/10000 (98%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.048095
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.054902
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.012064
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.014290
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.034948
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.026932
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.029508
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.047017
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.016720

Test set: Average loss: 0.0738, Accuracy: 9794/10000 (98%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.038660
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.022725
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.019904
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.013727
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.015495
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.056436
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.028684
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.019455
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.023195

Test set: Average loss: 0.0705, Accuracy: 9794/10000 (98%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=18, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.91 minutes
Total number of parameters in model: 1991352
Number of parameters in pruned model: 497838
