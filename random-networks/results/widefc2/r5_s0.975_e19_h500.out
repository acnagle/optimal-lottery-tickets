Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005) 

Pruning a Wide Two-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.905182
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.724479
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.568863
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.556393
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.468835
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.412400
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.494015
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.489236
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.449041

Test set: Average loss: 0.4002, Accuracy: 8998/10000 (90%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.436058
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.325737
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.410380
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.464892
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.455023
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.266911
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.328017
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.278618
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.371706

Test set: Average loss: 0.3524, Accuracy: 9089/10000 (91%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.274116
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.211950
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.249776
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.335045
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.339880
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.270128
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.364766
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.495177
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.283339

Test set: Average loss: 0.3335, Accuracy: 9157/10000 (92%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.413957
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.397683
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.429747
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.372312
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.372126
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.361119
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.305995
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.307170
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.320783

Test set: Average loss: 0.3254, Accuracy: 9173/10000 (92%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.220886
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.248189
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.301553
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.346309
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.348633
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.549836
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.290639
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.275421
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.291657

Test set: Average loss: 0.3223, Accuracy: 9184/10000 (92%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.370051
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.338088
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.353354
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.339045
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.332235
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.279448
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.245255
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.336407
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.282231

Test set: Average loss: 0.3226, Accuracy: 9168/10000 (92%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.231310
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.276912
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.377053
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.234253
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.357046
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.329680
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.353879
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.272973
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.362233

Test set: Average loss: 0.3170, Accuracy: 9193/10000 (92%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.597887
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.298447
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.231258
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.370016
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.399763
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.210306
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.262653
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.293586
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.378404

Test set: Average loss: 0.3135, Accuracy: 9197/10000 (92%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.258067
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.266730
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.243542
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.209442
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.332174
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.297950
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.345226
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.413442
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.457713

Test set: Average loss: 0.3137, Accuracy: 9186/10000 (92%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.307668
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.303154
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.248176
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.293506
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.412835
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.225097
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.387770
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.249181
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.365883

Test set: Average loss: 0.3112, Accuracy: 9217/10000 (92%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.328486
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.217854
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.202933
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.276006
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.396276
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.288945
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.217354
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.269680
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.262834

Test set: Average loss: 0.3106, Accuracy: 9212/10000 (92%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.286101
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.318824
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.373155
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.220111
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.339125
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.415742
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.257485
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.333356
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.347816

Test set: Average loss: 0.3110, Accuracy: 9209/10000 (92%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.336875
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.218662
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.278779
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.338876
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.362694
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.508119
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.205528
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.353713
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.341349

Test set: Average loss: 0.3114, Accuracy: 9221/10000 (92%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.338093
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.357997
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.336149
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.341032
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.401022
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.317990
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.273949
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.315953
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.332987

Test set: Average loss: 0.3106, Accuracy: 9222/10000 (92%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.374660
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.310369
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.378864
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.231634
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.429133
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.373629
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.268075
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.315701
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.341459

Test set: Average loss: 0.3128, Accuracy: 9213/10000 (92%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.356762
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.435613
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.244382
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.324417
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.309245
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.245713
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.214670
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.356210
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.353488

Test set: Average loss: 0.3093, Accuracy: 9219/10000 (92%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.377416
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.246769
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.196824
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.183338
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.370949
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.376177
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.331961
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.332590
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.280326

Test set: Average loss: 0.3118, Accuracy: 9225/10000 (92%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.294786
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.270873
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.283798
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.176446
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.192723
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.263895
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.387729
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.274973
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.267674

Test set: Average loss: 0.3090, Accuracy: 9227/10000 (92%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.221416
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.225210
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.279526
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.202844
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.244877
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.286893
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.273423
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.270145
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.298670

Test set: Average loss: 0.3077, Accuracy: 9227/10000 (92%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.01 minutes
Total number of parameters in model: 1991352
Number of parameters in pruned model: 49783
