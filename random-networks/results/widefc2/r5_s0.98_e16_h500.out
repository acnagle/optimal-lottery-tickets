Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=16, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.98, use_relu=False, wd=0.0005) 

Pruning a Wide Two-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.976493
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.779079
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.632973
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.596070
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.507519
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.468656
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.522956
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.524211
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.491059

Test set: Average loss: 0.4384, Accuracy: 8946/10000 (89%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.476876
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.367535
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.445901
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.503770
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.488002
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.316007
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.372343
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.327498
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.419103

Test set: Average loss: 0.3929, Accuracy: 9039/10000 (90%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.314787
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.253585
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.288276
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.390926
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.388994
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.335612
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.402424
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.512357
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.350647

Test set: Average loss: 0.3787, Accuracy: 9087/10000 (91%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.474028
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.443545
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.480824
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.427189
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.416083
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.401616
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.355026
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.365496
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.370215

Test set: Average loss: 0.3724, Accuracy: 9092/10000 (91%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.269071
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.302423
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.377390
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.401717
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.389439
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.587938
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.332260
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.329924
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.349882

Test set: Average loss: 0.3709, Accuracy: 9109/10000 (91%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.418496
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.392312
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.421424
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.371448
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.386393
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.327194
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.300626
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.377055
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.350934

Test set: Average loss: 0.3713, Accuracy: 9095/10000 (91%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.269404
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.328261
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.435406
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.279378
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.401061
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.388336
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.406266
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.321404
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.436950

Test set: Average loss: 0.3684, Accuracy: 9113/10000 (91%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.663729
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.357252
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.286702
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.428541
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.456171
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.262322
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.309217
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.348854
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.409706

Test set: Average loss: 0.3655, Accuracy: 9119/10000 (91%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.311846
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.331025
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.288021
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.259272
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.390884
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.348954
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.408239
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.464701
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.494303

Test set: Average loss: 0.3659, Accuracy: 9090/10000 (91%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.380091
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.358094
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.307232
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.340568
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.462091
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.274036
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.439323
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.322832
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.436583

Test set: Average loss: 0.3642, Accuracy: 9129/10000 (91%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.409674
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.267479
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.252857
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.340737
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.473489
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.339248
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.272147
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.342510
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.329773

Test set: Average loss: 0.3645, Accuracy: 9138/10000 (91%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.338909
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.375124
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.416318
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.268118
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.395392
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.467050
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.319146
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.398642
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.410287

Test set: Average loss: 0.3651, Accuracy: 9114/10000 (91%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.400582
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.277574
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.337099
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.390561
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.414423
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.549343
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.263088
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.394679
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.396135

Test set: Average loss: 0.3639, Accuracy: 9126/10000 (91%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.403639
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.421021
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.400338
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.399344
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.470409
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.388174
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.343862
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.371558
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.389150

Test set: Average loss: 0.3645, Accuracy: 9131/10000 (91%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.420073
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.380725
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.447393
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.268548
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.456914
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.424693
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.344905
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.383724
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.407045

Test set: Average loss: 0.3662, Accuracy: 9117/10000 (91%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.423718
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.479726
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.316594
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.376772
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.367275
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.292669
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.272321
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.402643
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.394535

Test set: Average loss: 0.3642, Accuracy: 9126/10000 (91%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=16, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc2', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.98, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.69 minutes
Total number of parameters in model: 1991352
Number of parameters in pruned model: 39827
