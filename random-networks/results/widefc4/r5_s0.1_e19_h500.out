Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.394193
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.104627
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.351914
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.167223
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.212197
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.305658
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.063929
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.110521
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.073956

Test set: Average loss: 0.1394, Accuracy: 9546/10000 (95%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.055363
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.094828
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.132407
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.101245
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.169071
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.103868
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.270562
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.130280
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.034549

Test set: Average loss: 0.1231, Accuracy: 9603/10000 (96%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.105574
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.066885
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.143619
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.059806
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.129752
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.061221
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.032439
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.114588
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.095379

Test set: Average loss: 0.1263, Accuracy: 9611/10000 (96%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.066423
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.052300
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.028793
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.275811
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.075162
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.105890
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.204429
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.131937
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.100606

Test set: Average loss: 0.1389, Accuracy: 9553/10000 (96%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.181239
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.167422
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.071633
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.214552
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.154457
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.091126
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.159502
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.166812
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.393228

Test set: Average loss: 0.1500, Accuracy: 9528/10000 (95%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.127559
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.188145
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.257541
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.173515
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.158892
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.078649
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.150562
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.121098
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.120354

Test set: Average loss: 0.1742, Accuracy: 9471/10000 (95%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.232145
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.175046
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.103060
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.279843
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.151554
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.199034
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.151944
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.301585
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.211418

Test set: Average loss: 0.1922, Accuracy: 9381/10000 (94%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.226166
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.176614
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.225047
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.230934
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.224255
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.253041
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.324739
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.364366
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.250911

Test set: Average loss: 0.2689, Accuracy: 9074/10000 (91%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.192298
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.083757
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.170285
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.166487
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.458099
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.339908
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.121416
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.180794
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.232334

Test set: Average loss: 0.3449, Accuracy: 8882/10000 (89%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.132557
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.396045
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.139948
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.188355
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.306352
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.208531
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.150027
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.173067
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.306617

Test set: Average loss: 0.2475, Accuracy: 9207/10000 (92%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.175603
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.335788
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.178960
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.175974
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.179079
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.196280
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.133199
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.357370
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.182978

Test set: Average loss: 0.3121, Accuracy: 8919/10000 (89%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.272076
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.180002
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.192243
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.098094
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.223884
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.358644
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.248766
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.322588
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.334480

Test set: Average loss: 0.2628, Accuracy: 9150/10000 (92%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.340613
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.206175
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.199040
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.208657
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.216733
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.271568
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.166527
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.291697
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.228796

Test set: Average loss: 0.2510, Accuracy: 9199/10000 (92%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.169533
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.276145
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.297628
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.267027
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.223354
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.153186
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.311569
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.309113
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.371945

Test set: Average loss: 0.2442, Accuracy: 9257/10000 (93%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.228164
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.175125
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.196129
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.245450
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.357761
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.189826
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.159542
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.344188
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.255789

Test set: Average loss: 0.2328, Accuracy: 9256/10000 (93%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.184995
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.205831
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.130215
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.121001
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.208417
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.217155
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.197714
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.386394
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.164072

Test set: Average loss: 0.2916, Accuracy: 8995/10000 (90%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.238035
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.095572
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.177454
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.110442
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.222475
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.230725
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.249335
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.316495
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.263617

Test set: Average loss: 0.3240, Accuracy: 8977/10000 (90%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.137261
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.288867
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.060388
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.276939
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.115368
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.206056
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.265427
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.290857
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.301414

Test set: Average loss: 0.2195, Accuracy: 9297/10000 (93%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.194421
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.108299
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.277020
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.215400
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.062206
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.190579
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.103297
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.077502
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.040062

Test set: Average loss: 0.1203, Accuracy: 9640/10000 (96%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.1, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.38 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 4046857
