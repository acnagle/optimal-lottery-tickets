Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 0.662227
Train Epoch: 1 [12736/60000 (21%)]	Loss: 0.244081
Train Epoch: 1 [19136/60000 (32%)]	Loss: 0.465351
Train Epoch: 1 [25536/60000 (43%)]	Loss: 0.297347
Train Epoch: 1 [31936/60000 (53%)]	Loss: 0.352078
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.339849
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.126993
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.165762
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.133365

Test set: Average loss: 0.1552, Accuracy: 9540/10000 (95%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.064407
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.174999
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.134457
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.118164
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.208666
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.156601
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.239806
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.108658
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.027961

Test set: Average loss: 0.1471, Accuracy: 9520/10000 (95%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.094483
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.054063
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.214848
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.086567
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.083057
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.042813
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.039130
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.036689
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.050523

Test set: Average loss: 0.0869, Accuracy: 9711/10000 (97%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.040596
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.038800
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.024164
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.120303
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.075618
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.108204
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.136354
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.101266
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.068984

Test set: Average loss: 0.0875, Accuracy: 9734/10000 (97%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.101622
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.036964
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.027821
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.083391
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.035238
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.023540
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.213893
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.131787
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.331706

Test set: Average loss: 0.0994, Accuracy: 9711/10000 (97%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.026392
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.017699
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.103227
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.068900
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.158107
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.029514
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.062085
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.108060
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.070645

Test set: Average loss: 0.1039, Accuracy: 9669/10000 (97%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.032111
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.077989
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.064206
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.037966
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.067267
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.146942
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.068296
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.199291
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.087956

Test set: Average loss: 0.1334, Accuracy: 9566/10000 (96%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.107010
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.024556
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.135891
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.182361
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.034894
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.077774
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.013326
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.081543
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.107209

Test set: Average loss: 0.0999, Accuracy: 9688/10000 (97%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.089484
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.050877
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.124381
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.133726
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.152516
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.063537
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.055185
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.125558
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.143058

Test set: Average loss: 0.1206, Accuracy: 9624/10000 (96%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.019203
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.112038
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.014560
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.035916
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.223721
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.031221
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.027634
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.149326
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.133473

Test set: Average loss: 0.1386, Accuracy: 9521/10000 (95%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.014143
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.040192
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.031104
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.017911
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.101570
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.020931
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.073705
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.014399
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.018632

Test set: Average loss: 0.0872, Accuracy: 9723/10000 (97%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.060097
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.018356
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.036355
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.001706
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.012185
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.047383
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.063993
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.081902
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.069838

Test set: Average loss: 0.0692, Accuracy: 9780/10000 (98%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.016804
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.009405
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.036655
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.006924
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.057127
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.013940
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.002028
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.025073
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.010386

Test set: Average loss: 0.0685, Accuracy: 9814/10000 (98%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.001236
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.002190
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.003470
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.004916
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.006570
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.010413
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.039666
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.004191
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.007853

Test set: Average loss: 0.0562, Accuracy: 9836/10000 (98%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.000303
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.001116
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.001795
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.000966
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.003186
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.000294
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.002677
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.001469
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.032230

Test set: Average loss: 0.0480, Accuracy: 9863/10000 (99%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.000499
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.000329
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.000210
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.000559
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.000124
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.000493
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.001023
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.000542
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.001300

Test set: Average loss: 0.0498, Accuracy: 9867/10000 (99%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.000776
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.000763
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.001387
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.000239
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.000953
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.000879
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.000999
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.000900
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.000350

Test set: Average loss: 0.0495, Accuracy: 9864/10000 (99%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=17, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.02 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 1124127
