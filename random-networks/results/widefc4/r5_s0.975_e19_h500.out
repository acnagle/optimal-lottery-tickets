Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005) 

Pruning a Wide Four-Layer Fully Connected network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.300726
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.294286
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.269131
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.105799
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.245438
Train Epoch: 1 [38336/60000 (64%)]	Loss: 0.835581
Train Epoch: 1 [44736/60000 (75%)]	Loss: 0.665496
Train Epoch: 1 [51136/60000 (85%)]	Loss: 0.521482
Train Epoch: 1 [57536/60000 (96%)]	Loss: 0.588251

Test set: Average loss: 0.4587, Accuracy: 8701/10000 (87%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 0.354768
Train Epoch: 2 [12736/60000 (21%)]	Loss: 0.521714
Train Epoch: 2 [19136/60000 (32%)]	Loss: 0.495256
Train Epoch: 2 [25536/60000 (43%)]	Loss: 0.418503
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.488664
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.343904
Train Epoch: 2 [44736/60000 (75%)]	Loss: 0.504984
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.349699
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.316772

Test set: Average loss: 0.2900, Accuracy: 9194/10000 (92%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.347669
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.243844
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.289064
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.375565
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.251930
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.188658
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.162354
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.161839
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.253506

Test set: Average loss: 0.2205, Accuracy: 9406/10000 (94%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.214639
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.158782
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.164955
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.200745
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.163744
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.244286
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.275567
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.267831
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.120973

Test set: Average loss: 0.1910, Accuracy: 9465/10000 (95%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.179393
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.127453
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.143160
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.184571
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.171680
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.127101
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.253442
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.198618
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.378312

Test set: Average loss: 0.1689, Accuracy: 9539/10000 (95%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.143609
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.129245
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.215948
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.124698
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.175377
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.127567
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.226777
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.169325
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.202504

Test set: Average loss: 0.1553, Accuracy: 9580/10000 (96%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.133381
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.154708
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.173748
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.142148
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.111592
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.138813
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.106976
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.213690
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.124942

Test set: Average loss: 0.1515, Accuracy: 9563/10000 (96%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.140480
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.154659
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.200042
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.165546
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.143169
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.172703
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.141838
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.190550
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.197430

Test set: Average loss: 0.1330, Accuracy: 9637/10000 (96%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.133316
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.066440
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.114539
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.124023
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.231331
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.141199
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.089924
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.143203
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.147369

Test set: Average loss: 0.1295, Accuracy: 9658/10000 (97%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.092735
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.270400
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.055752
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.132859
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.221713
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.136393
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.070121
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.112831
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.146262

Test set: Average loss: 0.1458, Accuracy: 9580/10000 (96%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.044158
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.156543
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.112217
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.067925
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.122904
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.076260
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.108901
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.087589
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.092262

Test set: Average loss: 0.1298, Accuracy: 9642/10000 (96%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.214287
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.118068
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.060054
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.036953
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.078310
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.130203
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.100220
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.141174
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.093379

Test set: Average loss: 0.1300, Accuracy: 9626/10000 (96%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.080461
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.064873
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.104622
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.118937
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.072124
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.128442
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.042399
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.097502
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.126368

Test set: Average loss: 0.1208, Accuracy: 9677/10000 (97%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.077038
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.123700
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.083368
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.122051
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.060602
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.151518
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.106343
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.123884
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.083166

Test set: Average loss: 0.1231, Accuracy: 9675/10000 (97%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.088902
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.099820
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.090299
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.100620
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.137016
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.105018
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.108555
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.177732
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.186447

Test set: Average loss: 0.1194, Accuracy: 9674/10000 (97%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.114317
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.104234
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.033224
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.064131
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.094676
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.127362
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.168038
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.152450
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.072957

Test set: Average loss: 0.1164, Accuracy: 9682/10000 (97%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.109118
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.141252
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.095064
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.049905
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.148361
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.127939
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.134504
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.126059
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.110659

Test set: Average loss: 0.1142, Accuracy: 9693/10000 (97%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 0.164600
Train Epoch: 18 [12736/60000 (21%)]	Loss: 0.086474
Train Epoch: 18 [19136/60000 (32%)]	Loss: 0.084463
Train Epoch: 18 [25536/60000 (43%)]	Loss: 0.178643
Train Epoch: 18 [31936/60000 (53%)]	Loss: 0.128784
Train Epoch: 18 [38336/60000 (64%)]	Loss: 0.070917
Train Epoch: 18 [44736/60000 (75%)]	Loss: 0.142889
Train Epoch: 18 [51136/60000 (85%)]	Loss: 0.205662
Train Epoch: 18 [57536/60000 (96%)]	Loss: 0.201444

Test set: Average loss: 0.1142, Accuracy: 9687/10000 (97%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 0.139202
Train Epoch: 19 [12736/60000 (21%)]	Loss: 0.067286
Train Epoch: 19 [19136/60000 (32%)]	Loss: 0.116144
Train Epoch: 19 [25536/60000 (43%)]	Loss: 0.173660
Train Epoch: 19 [31936/60000 (53%)]	Loss: 0.082134
Train Epoch: 19 [38336/60000 (64%)]	Loss: 0.157747
Train Epoch: 19 [44736/60000 (75%)]	Loss: 0.065429
Train Epoch: 19 [51136/60000 (85%)]	Loss: 0.070650
Train Epoch: 19 [57536/60000 (96%)]	Loss: 0.026684

Test set: Average loss: 0.1154, Accuracy: 9694/10000 (97%)

Namespace(batch_size=64, bias=None, data='../data', device=1, epochs=19, hidden_size=500, load_weights=None, log_interval=100, lr=0.1, model='widefc4', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005)


Total time spent pruning/training: 3.37 minutes
Total number of parameters in model: 4496508
Number of parameters in pruned model: 112412
