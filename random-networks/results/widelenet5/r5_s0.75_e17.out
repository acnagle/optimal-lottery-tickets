Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=17, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005) 

Pruning a Wide LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.233687
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.172473
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.082763
Train Epoch: 1 [25536/60000 (43%)]	Loss: 1.847952
Train Epoch: 1 [31936/60000 (53%)]	Loss: 1.775533
Train Epoch: 1 [38336/60000 (64%)]	Loss: 1.576134
Train Epoch: 1 [44736/60000 (75%)]	Loss: 1.470195
Train Epoch: 1 [51136/60000 (85%)]	Loss: 1.322995
Train Epoch: 1 [57536/60000 (96%)]	Loss: 1.205847

Test set: Average loss: 1.2601, Accuracy: 7217/10000 (72%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 1.172858
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.019200
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.069552
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.041065
Train Epoch: 2 [31936/60000 (53%)]	Loss: 0.987167
Train Epoch: 2 [38336/60000 (64%)]	Loss: 0.855655
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.000211
Train Epoch: 2 [51136/60000 (85%)]	Loss: 0.702262
Train Epoch: 2 [57536/60000 (96%)]	Loss: 0.653075

Test set: Average loss: 0.7660, Accuracy: 8288/10000 (83%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 0.636352
Train Epoch: 3 [12736/60000 (21%)]	Loss: 0.705306
Train Epoch: 3 [19136/60000 (32%)]	Loss: 0.697489
Train Epoch: 3 [25536/60000 (43%)]	Loss: 0.683950
Train Epoch: 3 [31936/60000 (53%)]	Loss: 0.483043
Train Epoch: 3 [38336/60000 (64%)]	Loss: 0.633476
Train Epoch: 3 [44736/60000 (75%)]	Loss: 0.616607
Train Epoch: 3 [51136/60000 (85%)]	Loss: 0.475010
Train Epoch: 3 [57536/60000 (96%)]	Loss: 0.623180

Test set: Average loss: 0.5836, Accuracy: 8704/10000 (87%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 0.656772
Train Epoch: 4 [12736/60000 (21%)]	Loss: 0.555794
Train Epoch: 4 [19136/60000 (32%)]	Loss: 0.582820
Train Epoch: 4 [25536/60000 (43%)]	Loss: 0.481980
Train Epoch: 4 [31936/60000 (53%)]	Loss: 0.640406
Train Epoch: 4 [38336/60000 (64%)]	Loss: 0.518961
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.487721
Train Epoch: 4 [51136/60000 (85%)]	Loss: 0.586272
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.475449

Test set: Average loss: 0.4911, Accuracy: 8889/10000 (89%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.372443
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.479094
Train Epoch: 5 [19136/60000 (32%)]	Loss: 0.524671
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.340808
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.424122
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.465677
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.421100
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.463548
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.384699

Test set: Average loss: 0.4323, Accuracy: 9002/10000 (90%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.369304
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.511610
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.399733
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.428491
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.309179
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.616078
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.387577
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.363784
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.393844

Test set: Average loss: 0.3960, Accuracy: 9066/10000 (91%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.344048
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.510032
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.368830
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.584543
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.353976
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.329934
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.464209
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.300957
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.378405

Test set: Average loss: 0.3665, Accuracy: 9133/10000 (91%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.332436
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.445481
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.350633
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.411714
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.301395
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.347787
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.515392
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.378152
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.300110

Test set: Average loss: 0.3467, Accuracy: 9192/10000 (92%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.423028
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.423613
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.402087
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.413905
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.263905
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.474245
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.289462
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.349789
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.446356

Test set: Average loss: 0.3332, Accuracy: 9227/10000 (92%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.417720
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.359615
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.356380
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.333967
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.401008
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.285657
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.221677
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.323239
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.350250

Test set: Average loss: 0.3216, Accuracy: 9228/10000 (92%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.300440
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.307140
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.330817
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.376841
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.340569
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.291452
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.437585
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.371795
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.318573

Test set: Average loss: 0.3141, Accuracy: 9238/10000 (92%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.332417
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.255394
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.281269
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.267827
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.303230
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.358678
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.328977
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.347469
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.365148

Test set: Average loss: 0.3087, Accuracy: 9251/10000 (93%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.371768
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.275946
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.198988
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.220949
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.290419
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.327888
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.407823
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.248035
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.328088

Test set: Average loss: 0.3049, Accuracy: 9279/10000 (93%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.295840
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.405734
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.346946
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.345100
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.415017
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.312518
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.181314
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.328386
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.382326

Test set: Average loss: 0.3008, Accuracy: 9275/10000 (93%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.351193
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.273210
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.310825
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.344459
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.240043
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.344269
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.293925
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.278081
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.458136

Test set: Average loss: 0.3002, Accuracy: 9262/10000 (93%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.353773
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.303854
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.404614
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.162257
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.437736
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.204779
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.215735
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.269131
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.224216

Test set: Average loss: 0.3002, Accuracy: 9281/10000 (93%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 0.300249
Train Epoch: 17 [12736/60000 (21%)]	Loss: 0.284851
Train Epoch: 17 [19136/60000 (32%)]	Loss: 0.339960
Train Epoch: 17 [25536/60000 (43%)]	Loss: 0.211478
Train Epoch: 17 [31936/60000 (53%)]	Loss: 0.286346
Train Epoch: 17 [38336/60000 (64%)]	Loss: 0.338836
Train Epoch: 17 [44736/60000 (75%)]	Loss: 0.265375
Train Epoch: 17 [51136/60000 (85%)]	Loss: 0.491111
Train Epoch: 17 [57536/60000 (96%)]	Loss: 0.224444

Test set: Average loss: 0.2992, Accuracy: 9283/10000 (93%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=17, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.75, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.81 minutes
Total number of parameters in model: 300414
Number of parameters in pruned model: 77016
