Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=20, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005) 

Pruning a Wide LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.301938
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.301590
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.301120
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.298983
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.299002
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.298904
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.297332
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.291933
Train Epoch: 1 [57536/60000 (96%)]	Loss: 2.291145

Test set: Average loss: 2.2948, Accuracy: 2090/10000 (21%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.293648
Train Epoch: 2 [12736/60000 (21%)]	Loss: 2.287241
Train Epoch: 2 [19136/60000 (32%)]	Loss: 2.290750
Train Epoch: 2 [25536/60000 (43%)]	Loss: 2.284074
Train Epoch: 2 [31936/60000 (53%)]	Loss: 2.288512
Train Epoch: 2 [38336/60000 (64%)]	Loss: 2.273310
Train Epoch: 2 [44736/60000 (75%)]	Loss: 2.276921
Train Epoch: 2 [51136/60000 (85%)]	Loss: 2.266119
Train Epoch: 2 [57536/60000 (96%)]	Loss: 2.257604

Test set: Average loss: 2.2693, Accuracy: 1971/10000 (20%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 2.250614
Train Epoch: 3 [12736/60000 (21%)]	Loss: 2.251778
Train Epoch: 3 [19136/60000 (32%)]	Loss: 2.248236
Train Epoch: 3 [25536/60000 (43%)]	Loss: 2.257744
Train Epoch: 3 [31936/60000 (53%)]	Loss: 2.221735
Train Epoch: 3 [38336/60000 (64%)]	Loss: 2.250619
Train Epoch: 3 [44736/60000 (75%)]	Loss: 2.223778
Train Epoch: 3 [51136/60000 (85%)]	Loss: 2.204183
Train Epoch: 3 [57536/60000 (96%)]	Loss: 2.187684

Test set: Average loss: 2.1890, Accuracy: 2899/10000 (29%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 2.154317
Train Epoch: 4 [12736/60000 (21%)]	Loss: 2.103037
Train Epoch: 4 [19136/60000 (32%)]	Loss: 2.161820
Train Epoch: 4 [25536/60000 (43%)]	Loss: 2.097176
Train Epoch: 4 [31936/60000 (53%)]	Loss: 2.114876
Train Epoch: 4 [38336/60000 (64%)]	Loss: 2.124453
Train Epoch: 4 [44736/60000 (75%)]	Loss: 2.093557
Train Epoch: 4 [51136/60000 (85%)]	Loss: 2.061043
Train Epoch: 4 [57536/60000 (96%)]	Loss: 1.999616

Test set: Average loss: 2.0380, Accuracy: 3451/10000 (35%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 2.011838
Train Epoch: 5 [12736/60000 (21%)]	Loss: 2.017802
Train Epoch: 5 [19136/60000 (32%)]	Loss: 2.060189
Train Epoch: 5 [25536/60000 (43%)]	Loss: 1.918886
Train Epoch: 5 [31936/60000 (53%)]	Loss: 1.959579
Train Epoch: 5 [38336/60000 (64%)]	Loss: 2.048238
Train Epoch: 5 [44736/60000 (75%)]	Loss: 2.009322
Train Epoch: 5 [51136/60000 (85%)]	Loss: 1.994950
Train Epoch: 5 [57536/60000 (96%)]	Loss: 2.002468

Test set: Average loss: 1.8980, Accuracy: 3883/10000 (39%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 1.868553
Train Epoch: 6 [12736/60000 (21%)]	Loss: 1.942764
Train Epoch: 6 [19136/60000 (32%)]	Loss: 1.874243
Train Epoch: 6 [25536/60000 (43%)]	Loss: 1.850875
Train Epoch: 6 [31936/60000 (53%)]	Loss: 1.797634
Train Epoch: 6 [38336/60000 (64%)]	Loss: 1.919777
Train Epoch: 6 [44736/60000 (75%)]	Loss: 1.872138
Train Epoch: 6 [51136/60000 (85%)]	Loss: 1.732115
Train Epoch: 6 [57536/60000 (96%)]	Loss: 1.774229

Test set: Average loss: 1.8052, Accuracy: 4526/10000 (45%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 1.795377
Train Epoch: 7 [12736/60000 (21%)]	Loss: 1.828762
Train Epoch: 7 [19136/60000 (32%)]	Loss: 1.888747
Train Epoch: 7 [25536/60000 (43%)]	Loss: 1.739489
Train Epoch: 7 [31936/60000 (53%)]	Loss: 1.743439
Train Epoch: 7 [38336/60000 (64%)]	Loss: 1.822786
Train Epoch: 7 [44736/60000 (75%)]	Loss: 1.870821
Train Epoch: 7 [51136/60000 (85%)]	Loss: 1.808190
Train Epoch: 7 [57536/60000 (96%)]	Loss: 1.801439

Test set: Average loss: 1.7549, Accuracy: 4705/10000 (47%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 1.719628
Train Epoch: 8 [12736/60000 (21%)]	Loss: 1.799891
Train Epoch: 8 [19136/60000 (32%)]	Loss: 1.680421
Train Epoch: 8 [25536/60000 (43%)]	Loss: 1.839900
Train Epoch: 8 [31936/60000 (53%)]	Loss: 1.631067
Train Epoch: 8 [38336/60000 (64%)]	Loss: 1.778836
Train Epoch: 8 [44736/60000 (75%)]	Loss: 1.835158
Train Epoch: 8 [51136/60000 (85%)]	Loss: 1.651253
Train Epoch: 8 [57536/60000 (96%)]	Loss: 1.633939

Test set: Average loss: 1.7195, Accuracy: 4829/10000 (48%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 1.758903
Train Epoch: 9 [12736/60000 (21%)]	Loss: 1.648083
Train Epoch: 9 [19136/60000 (32%)]	Loss: 1.764131
Train Epoch: 9 [25536/60000 (43%)]	Loss: 1.708892
Train Epoch: 9 [31936/60000 (53%)]	Loss: 1.731556
Train Epoch: 9 [38336/60000 (64%)]	Loss: 1.819203
Train Epoch: 9 [44736/60000 (75%)]	Loss: 1.758905
Train Epoch: 9 [51136/60000 (85%)]	Loss: 1.736226
Train Epoch: 9 [57536/60000 (96%)]	Loss: 1.825176

Test set: Average loss: 1.6958, Accuracy: 4926/10000 (49%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 1.701183
Train Epoch: 10 [12736/60000 (21%)]	Loss: 1.791430
Train Epoch: 10 [19136/60000 (32%)]	Loss: 1.680079
Train Epoch: 10 [25536/60000 (43%)]	Loss: 1.692075
Train Epoch: 10 [31936/60000 (53%)]	Loss: 1.653029
Train Epoch: 10 [38336/60000 (64%)]	Loss: 1.547782
Train Epoch: 10 [44736/60000 (75%)]	Loss: 1.603898
Train Epoch: 10 [51136/60000 (85%)]	Loss: 1.702697
Train Epoch: 10 [57536/60000 (96%)]	Loss: 1.742803

Test set: Average loss: 1.6782, Accuracy: 5026/10000 (50%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 1.593474
Train Epoch: 11 [12736/60000 (21%)]	Loss: 1.752863
Train Epoch: 11 [19136/60000 (32%)]	Loss: 1.612880
Train Epoch: 11 [25536/60000 (43%)]	Loss: 1.663511
Train Epoch: 11 [31936/60000 (53%)]	Loss: 1.774921
Train Epoch: 11 [38336/60000 (64%)]	Loss: 1.717735
Train Epoch: 11 [44736/60000 (75%)]	Loss: 1.750142
Train Epoch: 11 [51136/60000 (85%)]	Loss: 1.685007
Train Epoch: 11 [57536/60000 (96%)]	Loss: 1.712940

Test set: Average loss: 1.6678, Accuracy: 5078/10000 (51%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 1.760224
Train Epoch: 12 [12736/60000 (21%)]	Loss: 1.619365
Train Epoch: 12 [19136/60000 (32%)]	Loss: 1.769355
Train Epoch: 12 [25536/60000 (43%)]	Loss: 1.667299
Train Epoch: 12 [31936/60000 (53%)]	Loss: 1.571206
Train Epoch: 12 [38336/60000 (64%)]	Loss: 1.830184
Train Epoch: 12 [44736/60000 (75%)]	Loss: 1.664890
Train Epoch: 12 [51136/60000 (85%)]	Loss: 1.693490
Train Epoch: 12 [57536/60000 (96%)]	Loss: 1.769718

Test set: Average loss: 1.6568, Accuracy: 5235/10000 (52%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 1.697120
Train Epoch: 13 [12736/60000 (21%)]	Loss: 1.676449
Train Epoch: 13 [19136/60000 (32%)]	Loss: 1.679137
Train Epoch: 13 [25536/60000 (43%)]	Loss: 1.587049
Train Epoch: 13 [31936/60000 (53%)]	Loss: 1.651678
Train Epoch: 13 [38336/60000 (64%)]	Loss: 1.679070
Train Epoch: 13 [44736/60000 (75%)]	Loss: 1.730360
Train Epoch: 13 [51136/60000 (85%)]	Loss: 1.667343
Train Epoch: 13 [57536/60000 (96%)]	Loss: 1.730222

Test set: Average loss: 1.6454, Accuracy: 5305/10000 (53%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 1.640543
Train Epoch: 14 [12736/60000 (21%)]	Loss: 1.635589
Train Epoch: 14 [19136/60000 (32%)]	Loss: 1.591189
Train Epoch: 14 [25536/60000 (43%)]	Loss: 1.510463
Train Epoch: 14 [31936/60000 (53%)]	Loss: 1.673618
Train Epoch: 14 [38336/60000 (64%)]	Loss: 1.730054
Train Epoch: 14 [44736/60000 (75%)]	Loss: 1.513949
Train Epoch: 14 [51136/60000 (85%)]	Loss: 1.597984
Train Epoch: 14 [57536/60000 (96%)]	Loss: 1.641021

Test set: Average loss: 1.6415, Accuracy: 5316/10000 (53%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 1.723226
Train Epoch: 15 [12736/60000 (21%)]	Loss: 1.700653
Train Epoch: 15 [19136/60000 (32%)]	Loss: 1.712729
Train Epoch: 15 [25536/60000 (43%)]	Loss: 1.703693
Train Epoch: 15 [31936/60000 (53%)]	Loss: 1.592295
Train Epoch: 15 [38336/60000 (64%)]	Loss: 1.567403
Train Epoch: 15 [44736/60000 (75%)]	Loss: 1.551425
Train Epoch: 15 [51136/60000 (85%)]	Loss: 1.656480
Train Epoch: 15 [57536/60000 (96%)]	Loss: 1.670291

Test set: Average loss: 1.6374, Accuracy: 5385/10000 (54%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 1.695330
Train Epoch: 16 [12736/60000 (21%)]	Loss: 1.656335
Train Epoch: 16 [19136/60000 (32%)]	Loss: 1.671904
Train Epoch: 16 [25536/60000 (43%)]	Loss: 1.474607
Train Epoch: 16 [31936/60000 (53%)]	Loss: 1.706202
Train Epoch: 16 [38336/60000 (64%)]	Loss: 1.576307
Train Epoch: 16 [44736/60000 (75%)]	Loss: 1.631837
Train Epoch: 16 [51136/60000 (85%)]	Loss: 1.667196
Train Epoch: 16 [57536/60000 (96%)]	Loss: 1.653786

Test set: Average loss: 1.6360, Accuracy: 5447/10000 (54%)

Train Epoch: 17 [6336/60000 (11%)]	Loss: 1.686127
Train Epoch: 17 [12736/60000 (21%)]	Loss: 1.638490
Train Epoch: 17 [19136/60000 (32%)]	Loss: 1.576070
Train Epoch: 17 [25536/60000 (43%)]	Loss: 1.630221
Train Epoch: 17 [31936/60000 (53%)]	Loss: 1.721500
Train Epoch: 17 [38336/60000 (64%)]	Loss: 1.613299
Train Epoch: 17 [44736/60000 (75%)]	Loss: 1.715478
Train Epoch: 17 [51136/60000 (85%)]	Loss: 1.719784
Train Epoch: 17 [57536/60000 (96%)]	Loss: 1.630563

Test set: Average loss: 1.6323, Accuracy: 5283/10000 (53%)

Train Epoch: 18 [6336/60000 (11%)]	Loss: 1.584334
Train Epoch: 18 [12736/60000 (21%)]	Loss: 1.637887
Train Epoch: 18 [19136/60000 (32%)]	Loss: 1.556205
Train Epoch: 18 [25536/60000 (43%)]	Loss: 1.562214
Train Epoch: 18 [31936/60000 (53%)]	Loss: 1.632470
Train Epoch: 18 [38336/60000 (64%)]	Loss: 1.569906
Train Epoch: 18 [44736/60000 (75%)]	Loss: 1.620540
Train Epoch: 18 [51136/60000 (85%)]	Loss: 1.550285
Train Epoch: 18 [57536/60000 (96%)]	Loss: 1.645921

Test set: Average loss: 1.6309, Accuracy: 5271/10000 (53%)

Train Epoch: 19 [6336/60000 (11%)]	Loss: 1.518325
Train Epoch: 19 [12736/60000 (21%)]	Loss: 1.539129
Train Epoch: 19 [19136/60000 (32%)]	Loss: 1.623026
Train Epoch: 19 [25536/60000 (43%)]	Loss: 1.634910
Train Epoch: 19 [31936/60000 (53%)]	Loss: 1.594028
Train Epoch: 19 [38336/60000 (64%)]	Loss: 1.677610
Train Epoch: 19 [44736/60000 (75%)]	Loss: 1.649919
Train Epoch: 19 [51136/60000 (85%)]	Loss: 1.757930
Train Epoch: 19 [57536/60000 (96%)]	Loss: 1.541726

Test set: Average loss: 1.6309, Accuracy: 5301/10000 (53%)

Train Epoch: 20 [6336/60000 (11%)]	Loss: 1.642467
Train Epoch: 20 [12736/60000 (21%)]	Loss: 1.726897
Train Epoch: 20 [19136/60000 (32%)]	Loss: 1.638849
Train Epoch: 20 [25536/60000 (43%)]	Loss: 1.671953
Train Epoch: 20 [31936/60000 (53%)]	Loss: 1.540261
Train Epoch: 20 [38336/60000 (64%)]	Loss: 1.650879
Train Epoch: 20 [44736/60000 (75%)]	Loss: 1.524522
Train Epoch: 20 [51136/60000 (85%)]	Loss: 1.716683
Train Epoch: 20 [57536/60000 (96%)]	Loss: 1.519562

Test set: Average loss: 1.6320, Accuracy: 5284/10000 (53%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=20, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.975, use_relu=False, wd=0.0005)


Total time spent pruning/training: 2.14 minutes
Total number of parameters in model: 300414
Number of parameters in pruned model: 9997
