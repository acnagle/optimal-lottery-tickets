Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=16, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005) 

Pruning a Wide LeNet5 network ...
Train Epoch: 1 [6336/60000 (11%)]	Loss: 2.291344
Train Epoch: 1 [12736/60000 (21%)]	Loss: 2.285773
Train Epoch: 1 [19136/60000 (32%)]	Loss: 2.274248
Train Epoch: 1 [25536/60000 (43%)]	Loss: 2.244282
Train Epoch: 1 [31936/60000 (53%)]	Loss: 2.238991
Train Epoch: 1 [38336/60000 (64%)]	Loss: 2.207306
Train Epoch: 1 [44736/60000 (75%)]	Loss: 2.171036
Train Epoch: 1 [51136/60000 (85%)]	Loss: 2.150077
Train Epoch: 1 [57536/60000 (96%)]	Loss: 2.069627

Test set: Average loss: 2.0883, Accuracy: 3540/10000 (35%)

Train Epoch: 2 [6336/60000 (11%)]	Loss: 2.032912
Train Epoch: 2 [12736/60000 (21%)]	Loss: 1.942119
Train Epoch: 2 [19136/60000 (32%)]	Loss: 1.913814
Train Epoch: 2 [25536/60000 (43%)]	Loss: 1.833844
Train Epoch: 2 [31936/60000 (53%)]	Loss: 1.857073
Train Epoch: 2 [38336/60000 (64%)]	Loss: 1.655922
Train Epoch: 2 [44736/60000 (75%)]	Loss: 1.721199
Train Epoch: 2 [51136/60000 (85%)]	Loss: 1.457201
Train Epoch: 2 [57536/60000 (96%)]	Loss: 1.391358

Test set: Average loss: 1.5325, Accuracy: 6263/10000 (63%)

Train Epoch: 3 [6336/60000 (11%)]	Loss: 1.476261
Train Epoch: 3 [12736/60000 (21%)]	Loss: 1.441641
Train Epoch: 3 [19136/60000 (32%)]	Loss: 1.427723
Train Epoch: 3 [25536/60000 (43%)]	Loss: 1.400017
Train Epoch: 3 [31936/60000 (53%)]	Loss: 1.210745
Train Epoch: 3 [38336/60000 (64%)]	Loss: 1.357491
Train Epoch: 3 [44736/60000 (75%)]	Loss: 1.260762
Train Epoch: 3 [51136/60000 (85%)]	Loss: 1.131467
Train Epoch: 3 [57536/60000 (96%)]	Loss: 1.206071

Test set: Average loss: 1.1697, Accuracy: 7325/10000 (73%)

Train Epoch: 4 [6336/60000 (11%)]	Loss: 1.175592
Train Epoch: 4 [12736/60000 (21%)]	Loss: 1.101889
Train Epoch: 4 [19136/60000 (32%)]	Loss: 1.144994
Train Epoch: 4 [25536/60000 (43%)]	Loss: 1.010691
Train Epoch: 4 [31936/60000 (53%)]	Loss: 1.119631
Train Epoch: 4 [38336/60000 (64%)]	Loss: 1.066299
Train Epoch: 4 [44736/60000 (75%)]	Loss: 0.984681
Train Epoch: 4 [51136/60000 (85%)]	Loss: 1.059386
Train Epoch: 4 [57536/60000 (96%)]	Loss: 0.993041

Test set: Average loss: 0.9692, Accuracy: 7794/10000 (78%)

Train Epoch: 5 [6336/60000 (11%)]	Loss: 0.860620
Train Epoch: 5 [12736/60000 (21%)]	Loss: 0.977208
Train Epoch: 5 [19136/60000 (32%)]	Loss: 1.006514
Train Epoch: 5 [25536/60000 (43%)]	Loss: 0.813752
Train Epoch: 5 [31936/60000 (53%)]	Loss: 0.866865
Train Epoch: 5 [38336/60000 (64%)]	Loss: 0.980258
Train Epoch: 5 [44736/60000 (75%)]	Loss: 0.916159
Train Epoch: 5 [51136/60000 (85%)]	Loss: 0.964049
Train Epoch: 5 [57536/60000 (96%)]	Loss: 0.830630

Test set: Average loss: 0.8488, Accuracy: 8084/10000 (81%)

Train Epoch: 6 [6336/60000 (11%)]	Loss: 0.790758
Train Epoch: 6 [12736/60000 (21%)]	Loss: 0.948596
Train Epoch: 6 [19136/60000 (32%)]	Loss: 0.848007
Train Epoch: 6 [25536/60000 (43%)]	Loss: 0.792902
Train Epoch: 6 [31936/60000 (53%)]	Loss: 0.684051
Train Epoch: 6 [38336/60000 (64%)]	Loss: 0.985782
Train Epoch: 6 [44736/60000 (75%)]	Loss: 0.746379
Train Epoch: 6 [51136/60000 (85%)]	Loss: 0.714891
Train Epoch: 6 [57536/60000 (96%)]	Loss: 0.770824

Test set: Average loss: 0.7708, Accuracy: 8168/10000 (82%)

Train Epoch: 7 [6336/60000 (11%)]	Loss: 0.738891
Train Epoch: 7 [12736/60000 (21%)]	Loss: 0.850580
Train Epoch: 7 [19136/60000 (32%)]	Loss: 0.818894
Train Epoch: 7 [25536/60000 (43%)]	Loss: 0.862517
Train Epoch: 7 [31936/60000 (53%)]	Loss: 0.720120
Train Epoch: 7 [38336/60000 (64%)]	Loss: 0.753918
Train Epoch: 7 [44736/60000 (75%)]	Loss: 0.799872
Train Epoch: 7 [51136/60000 (85%)]	Loss: 0.714485
Train Epoch: 7 [57536/60000 (96%)]	Loss: 0.751934

Test set: Average loss: 0.7146, Accuracy: 8414/10000 (84%)

Train Epoch: 8 [6336/60000 (11%)]	Loss: 0.680239
Train Epoch: 8 [12736/60000 (21%)]	Loss: 0.834658
Train Epoch: 8 [19136/60000 (32%)]	Loss: 0.646209
Train Epoch: 8 [25536/60000 (43%)]	Loss: 0.773687
Train Epoch: 8 [31936/60000 (53%)]	Loss: 0.622815
Train Epoch: 8 [38336/60000 (64%)]	Loss: 0.646109
Train Epoch: 8 [44736/60000 (75%)]	Loss: 0.885536
Train Epoch: 8 [51136/60000 (85%)]	Loss: 0.645750
Train Epoch: 8 [57536/60000 (96%)]	Loss: 0.641667

Test set: Average loss: 0.6796, Accuracy: 8445/10000 (84%)

Train Epoch: 9 [6336/60000 (11%)]	Loss: 0.771344
Train Epoch: 9 [12736/60000 (21%)]	Loss: 0.720131
Train Epoch: 9 [19136/60000 (32%)]	Loss: 0.734392
Train Epoch: 9 [25536/60000 (43%)]	Loss: 0.746593
Train Epoch: 9 [31936/60000 (53%)]	Loss: 0.634848
Train Epoch: 9 [38336/60000 (64%)]	Loss: 0.831537
Train Epoch: 9 [44736/60000 (75%)]	Loss: 0.618834
Train Epoch: 9 [51136/60000 (85%)]	Loss: 0.700299
Train Epoch: 9 [57536/60000 (96%)]	Loss: 0.830153

Test set: Average loss: 0.6531, Accuracy: 8498/10000 (85%)

Train Epoch: 10 [6336/60000 (11%)]	Loss: 0.715246
Train Epoch: 10 [12736/60000 (21%)]	Loss: 0.719798
Train Epoch: 10 [19136/60000 (32%)]	Loss: 0.676334
Train Epoch: 10 [25536/60000 (43%)]	Loss: 0.652244
Train Epoch: 10 [31936/60000 (53%)]	Loss: 0.723033
Train Epoch: 10 [38336/60000 (64%)]	Loss: 0.556475
Train Epoch: 10 [44736/60000 (75%)]	Loss: 0.494082
Train Epoch: 10 [51136/60000 (85%)]	Loss: 0.690001
Train Epoch: 10 [57536/60000 (96%)]	Loss: 0.662338

Test set: Average loss: 0.6307, Accuracy: 8585/10000 (86%)

Train Epoch: 11 [6336/60000 (11%)]	Loss: 0.597483
Train Epoch: 11 [12736/60000 (21%)]	Loss: 0.658506
Train Epoch: 11 [19136/60000 (32%)]	Loss: 0.648578
Train Epoch: 11 [25536/60000 (43%)]	Loss: 0.685199
Train Epoch: 11 [31936/60000 (53%)]	Loss: 0.688836
Train Epoch: 11 [38336/60000 (64%)]	Loss: 0.649335
Train Epoch: 11 [44736/60000 (75%)]	Loss: 0.740611
Train Epoch: 11 [51136/60000 (85%)]	Loss: 0.660155
Train Epoch: 11 [57536/60000 (96%)]	Loss: 0.633254

Test set: Average loss: 0.6181, Accuracy: 8619/10000 (86%)

Train Epoch: 12 [6336/60000 (11%)]	Loss: 0.699051
Train Epoch: 12 [12736/60000 (21%)]	Loss: 0.571882
Train Epoch: 12 [19136/60000 (32%)]	Loss: 0.605922
Train Epoch: 12 [25536/60000 (43%)]	Loss: 0.598706
Train Epoch: 12 [31936/60000 (53%)]	Loss: 0.576493
Train Epoch: 12 [38336/60000 (64%)]	Loss: 0.697153
Train Epoch: 12 [44736/60000 (75%)]	Loss: 0.604523
Train Epoch: 12 [51136/60000 (85%)]	Loss: 0.637617
Train Epoch: 12 [57536/60000 (96%)]	Loss: 0.702258

Test set: Average loss: 0.6085, Accuracy: 8628/10000 (86%)

Train Epoch: 13 [6336/60000 (11%)]	Loss: 0.641777
Train Epoch: 13 [12736/60000 (21%)]	Loss: 0.597470
Train Epoch: 13 [19136/60000 (32%)]	Loss: 0.503678
Train Epoch: 13 [25536/60000 (43%)]	Loss: 0.480945
Train Epoch: 13 [31936/60000 (53%)]	Loss: 0.610603
Train Epoch: 13 [38336/60000 (64%)]	Loss: 0.647323
Train Epoch: 13 [44736/60000 (75%)]	Loss: 0.721986
Train Epoch: 13 [51136/60000 (85%)]	Loss: 0.602598
Train Epoch: 13 [57536/60000 (96%)]	Loss: 0.696397

Test set: Average loss: 0.6023, Accuracy: 8647/10000 (86%)

Train Epoch: 14 [6336/60000 (11%)]	Loss: 0.591710
Train Epoch: 14 [12736/60000 (21%)]	Loss: 0.699849
Train Epoch: 14 [19136/60000 (32%)]	Loss: 0.636289
Train Epoch: 14 [25536/60000 (43%)]	Loss: 0.594599
Train Epoch: 14 [31936/60000 (53%)]	Loss: 0.756821
Train Epoch: 14 [38336/60000 (64%)]	Loss: 0.653877
Train Epoch: 14 [44736/60000 (75%)]	Loss: 0.424998
Train Epoch: 14 [51136/60000 (85%)]	Loss: 0.577074
Train Epoch: 14 [57536/60000 (96%)]	Loss: 0.729683

Test set: Average loss: 0.5990, Accuracy: 8656/10000 (87%)

Train Epoch: 15 [6336/60000 (11%)]	Loss: 0.762128
Train Epoch: 15 [12736/60000 (21%)]	Loss: 0.556403
Train Epoch: 15 [19136/60000 (32%)]	Loss: 0.619725
Train Epoch: 15 [25536/60000 (43%)]	Loss: 0.689419
Train Epoch: 15 [31936/60000 (53%)]	Loss: 0.547730
Train Epoch: 15 [38336/60000 (64%)]	Loss: 0.624601
Train Epoch: 15 [44736/60000 (75%)]	Loss: 0.572718
Train Epoch: 15 [51136/60000 (85%)]	Loss: 0.583519
Train Epoch: 15 [57536/60000 (96%)]	Loss: 0.764346

Test set: Average loss: 0.5977, Accuracy: 8654/10000 (87%)

Train Epoch: 16 [6336/60000 (11%)]	Loss: 0.638433
Train Epoch: 16 [12736/60000 (21%)]	Loss: 0.620551
Train Epoch: 16 [19136/60000 (32%)]	Loss: 0.677722
Train Epoch: 16 [25536/60000 (43%)]	Loss: 0.432762
Train Epoch: 16 [31936/60000 (53%)]	Loss: 0.713452
Train Epoch: 16 [38336/60000 (64%)]	Loss: 0.485557
Train Epoch: 16 [44736/60000 (75%)]	Loss: 0.521807
Train Epoch: 16 [51136/60000 (85%)]	Loss: 0.563204
Train Epoch: 16 [57536/60000 (96%)]	Loss: 0.535689

Test set: Average loss: 0.5979, Accuracy: 8653/10000 (87%)

Namespace(batch_size=64, bias=None, data='../data', device=0, epochs=16, hidden_size=500, load_weights='./paper/lenet5/lenet5_e50_h500.pt', log_interval=100, lr=0.01, model='widelenet5', momentum=0.9, no_cuda=False, r=5, save_model=None, save_results=True, seed=1, sparsity=0.9, use_relu=False, wd=0.0005)


Total time spent pruning/training: 1.76 minutes
Total number of parameters in model: 300414
Number of parameters in pruned model: 32337
